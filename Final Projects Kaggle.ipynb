{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22557592a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22557af72e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAE/CAYAAABxUrkUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXncblPZx7/XOSdDOCKKjJGkgYwJmZJUJCSROio0qDS86aXeiKJUMkZKlKRIRIMpQ4ZMxzyWCIVGwwnF4Xr/uNY+937uZ8/P85yzj37fz2d/nnvve6291r2fva+91rWuwdwdIYQQc55Jc7oDQgghAglkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9IQpbQpvsNXFcusTQoiWXHrWRtaknEbIQgjRE1qNkIUYZu+zd68tc9AWx9bWKyojxH8b1ia4kFQWQgjRHqkshBBiLkMCWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXrClDndATF3s/fZu9eWOWiLY2vrFZUR4r8Nc/fGhTfY6uLmhYUQQgBw6VkbWZNyUlkIIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvSEKXO6A2LuZu+zd68tc9AWx9bWKyojxH8b5u6NC2+w1cXNCwshhADg0rM2siblNEIWY0IjZCHGD42QhRBigmk6QtainhBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJyjrtBgTyjotxPihrNNCCDHBKOu0EELMZUggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ6g4EJiTCi4kBDjh4ILCSHEBKPgQkIIMZchgSyEED1BOmQxJqRDFmL8kA5ZCCEmGOmQhRBiLkMCWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5gypzsg5m72Pnv32jIHbXFsbb2iMkL8t2Hu3rjwBltd3LywEEIIAC49ayNrUk4qCyGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BdshiTMgOWYjxQ3bIQggxwcgOWQgh5jIkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNEX3L31Buw+O+o8W9tS/+aetvreP12Lueta1J6344++ZnbUeba2pf7NPW31vX+6FnPXtajbpLIQQoieIIEshBA9oatAPnY21Xm2tqX+zT1t9b1/s7OtvvdvdrbVtX+VWNKHCCGEmMNIZSGEED1BAlkIIXrClDndgWczZja16nt3f3R29eW/ETObBKzr7pfP6b4I0YTGOmQzWx+43t0fM7OdgTWAw9z9nnHtUDxEN7r7KzvUXQ5Yyd3PN7P5gSnuPmM8+9eyP/cBDhjwImBG+rwg8Gd3X7bBOfZ098Pqjo1Tf5cCliP3onb33zSo1/i6m9kCwGLD942ZvcLdbyko/yt3f1P6vJe7H9zyN/3W3V/bsOy67n5Fm/PPTZjZisCf3P0/ZrYxsCrwfXd/uKZep/tidtGmf2a2RtW53P3aBu3N6+7/advPJrQRyDcCqxH/xBOB44Bt3X2jijqLA58BXg7Mlx13901r2joJ2Nvd723UuaizG7A7sKi7r2hmKwHHuPvrC8q+Cvg2sBTwK+Az7v5Q+u4qd1+noM4MQriO+ip+kpeOhs3sm8DZ7n5m2t8K2NDdP93gd13r7msMHbvO3VevqNP6upvZV4AdgFuBpwdV/K01/Wtz3bcDjgT+QVzLadkDUPQ7h39rWZma/n0BuBH4qdfc7PnztxHkufrrA/sxEA7ZvbFCRZ15ge2A5RkpUPYvKX8T1ffhqhVtXQ+sldo6BzgTWNnd31xRp/F90aVvZnaCu++SPk9z9++V9WWs/UvlL6w4ndc8I+sQcm9hd1/WzFYDdnX3j7bpcxVtVBYz3d3NbGtiZHycmU2rqXMS8GPgLcAHgWnA3xq0tSRwi5ldBTyWHawRDnsA6wBXprK/N7MXlJQ9mnhwrgB2BS41s7e6+x+A5xRVcPeFGvS7jHXc/cO5c51lZvtWVTCzHYGdgBeb2Zm5r6YSAq2KLtf9bcTD2fbN3+a6/x+wlrv/2czWA042s0+nF5WV1BmrGdAngQWAmWb2b6pfoPk+zFfwfR3HAZ8ApjMQDnX8DHgk1Wly7bfs0K+MZ9x9ppltAxzq7keY2XU1ddrcF136tlru855AK4FMy/vW3Tdpef48hxO/8Yx0rhvMbCznG0UbgTzDzPYGdgY2NLPJlAivHM9PgntPd78YuNjMLm7Q1hda9CvjP+7+pFk8U2Y2hfKHeUF3Pzt9/pqZTQfONrN3V9QZQRI6+dFn1Wj+n2b2v8AP0vl3Bh6qaeJy4AFgMeDrueMziBFfFV2u+13E/7OtQG5z3Se5+58B3P1yM9sU+LmZLVNRZwUz+ykhLLPPs3D3bas61/JFOsnMFiEWu7PPs4S0u/+zpv4j7v6rFu0BLO3uWzQtPEYV4VPpRT8N2Codq3uGG98XHfs21hdu1/sWM3slo2eR36+oMsnd78nu9UTTF28j2gjkHYgR2/vd/UEzWxb4ak2dp9LfB8zsLcD9wNJ1DSUh0paLzWwfYH4zewPwYeCskrJmZgu7+yOpvQvTdPo0YNGqRszsrYSAfBHwV2J6ehvwiopqOxEvmexh/Q2wY1U76ea+x8w2A55w92fM7KXAy4CbqurS7bo/DlxvZr8md3O7+8dq6rW57o+Z2Yvd/e507j8nXebPiAejiO1yn4+s6csszOxl7n57mc6wRFe4MDFSzZ64fBkHClUPuTYuNLOvAj9l5DWs0ktebmavcve6/+lwm+sCRwCrAPMAk4HHqlRnwHuJGdOX3P1uM3sxMUgoOv8RxG9ufV+07NvSZnY4cc2zz7Moa2cs/Uv19wU2Ju67XwJvAi4FqgTyfUlt4WlA+lHgd1XttKWNDnkB4N/u/nROMPzK3Z+qqLMlcAmwDPEPmgp8IdOlVtTL62vnId6AlTebxWLg+4HNiX/uOcB3ivSGZrYTcNfwAk56yfyfu+9W0c4NwKbA+e6+epqy7Ojuu1f9pq6k0fvrgEUIFcs1wOPu/q6KOq2ve5n6qU6n1/K6rwHMcPffDx2fh7iGtdPVNAJfBbjf3UtVN2Z2rLvvXqIzrNQVtqWLXjKnb50CrESM9P5DA11wqn8N8E7gVEIv/B7gJe7+2Zp68wPLuvsdNeUq1ZFV/6s2fevazlj6l+rfRKhLrnP31czshcR9u1VFnRcQaovNiP/TecBH3P3vVW21wptHN5oOPJdYCLsPOB04qWn9sWyEnujABuXmIRYdXwXMM0F9uSb9vYGYwgBcVVL2dGK0VLg1bO/a9PejwF7p83UT9NvmAV6Ztuc0KD8Z+EHHtpYGNkmf5wUWKCl3FPCK9HkqcDMxI3kAeEfHtgt/GzHbWTi3vwlwGKEXrr2fgBWaHMu1Vbq1uA9vzB27vKbOVsAdwN1p/9XAmS2u2yLAqhPRt4J2rGHZBYDJQ/fkcxvUuyr9nZ7uKwNu6XI/jefWxjHE3P1xYFvgCHffhuppOmb2UjP7tZndnPZXNbPPtWgTAHc/gxiVVrX1FuAPxBvsSOBOM3tTg/5928zONbMLsq2mOw+b2YKE2uEkMzsMmFlS9khCoPwJeIawTjkxla8coYzspr0WeBfwi3SsUtXU5bon1cHvU3+/CfzOzDasquPuTwOLpxFuY8zsfcQK/3fSoeUItUURG/vAHO69xMxmFWBN4H9btGlmtqmZfYf4fxRxCvGAY2avJkZ49xKC65sNmvlJwbFTiwq6+z0eaqkvZp/zxxq09Xi67teb2cFm9oms7xXsRyzAPpz6cD3w4qoKZnaRmU01s0WJQcjxZnbIePXNzD5vZi9Ln+dNz98fgL8kdV0dvwbmz+3PD5zfoN41ZvY8wtpqOqGeuqqqgpktb2anm9mDaTvNzJZv0FZzWry1rgNeS0ybsxHLTTV1LiZugOtyx25u0Na2ue3twJeB39bUuZ2YFmX7KwK319S5AfhQ6uOa2dbkjUwIxWnAx4hFtKo6vxnat+FjFXU3JITXZ9L+CsDh433diZty5dz+S4HpDfr3LeBqwoLik9lWU+d6YjSe71/hvTRU5ufALkXfVbT1GmKUey/wr/Q/W6SkbH5E9zXg4PR5Uv67gnovI3Tdfxi6d3ehZtRFmgHl9icDtzb4XcsRwmcqsC9wSP7+L6lzZcE1Lf1d+bKENdIXGtZp3DfgFgaq092BC9M1WIWSmefwvdTkWM05lqfZyP+3xKBgnrTtQo1caru1WdTbE9gbON3dbzGzFdLFq+K57n7V0Kpk2WgyT16PMxP4I7B1TZ2/uvuduf27iEW3Kma6+9EN+jMLd38st9vUROcFZra8u/8x7S8LLN6wvd8Qo/Fs/y7iJVBFl+v+HM/pFd39d2ZWtwIPsWB4PyG0mlo0/NtHWmZMrij7iJltkdrYANgtV2f+skpm9iXgHYQgPhnYn5hKV/3P8hdsU+J+x2NBter3rEyYQz2PkffujKy/Bf3bG8gWQzOPTQOepEEkMR9YNDxBc6ukm9P6yWQLe/GPEdY8VUwxsyWJa1mpn+7Ytyc9STvgjcCPPGZet6X1gjoeM7M1fGDPvmZqtxAzu5UwC/2Rh5krueeyjknufnxu/wQz+1DDuo1oLJA7Coa/W3gHxbDQ7O2E7q+urfc27VeOW8zsl8S004HtgavNbNt0zp8W1DnLzD5M6HrzK7Sl5k1dFhyBTwGXmFkm8FYiRuadyBasKop0ue7XmNlxhEoFQkUyva4v7t7FRPEyM9sLmC8tiu5BjH6L+CCh+lkC+JS7Z79jM+DskjoQo607CJvzn7v7v82sbgX7AjM7BXiQ0GNeAJAE0pNlldz9Z8DPzOy17v7bmjayOgcBB5nZQe6+d5M6eczsbgpMxrzCCYVYh/gsca//kFiArVOP7J/KXeruV6eB2O+rKrTs238szM/+Qujs/yf33XNr+gYxUDzVzO5P+0sSFmFl7EgsOJ5rZn8nXtanuPv9FXUyLjCz/wF+RPy+HQgZMhXGJxRCGyuLxYG9CL1xU++vFYi3/XqE3e3dwLu8xl7RzJYmrAPWJ374pcCe7l6m+8PMji/7Lrrp7yuoc3dJ2aqbevgcbyMcP/apKTc/A9OuW4mRQakNY9LZFX4F3ODupWZsXa67hcfYHsQo1IiX7ze9xuA+WRgUPXxV98VkQmDmLTO+5e7PVNQZJeyswtU5tbE58QBuSszmNgOWcffC2YLFMHgHQvif6slm2sxWB17g7ueU9S+Vm4+wOBl+Rkbde0P1FiFe0vk6la7JZvb83O58xABkUXf/fFW92UGbvpnZa4iZ5uKEs8oB6fibgXe7e6l5qKVYJYTKbGXiXrrdKyy/huqvS/y/twPuBE52929XlL+v4nTuDUIh1NJCz3IucbPdBmwEfBf4SkX5SaRVcELvulCLts4jdDVT0rYLcN546mrGcwOuaFF2Q+AY4MGack8Tape7c1u2/+REXPeOv33N3LY+oS88uEG95xAvqFWI2Bd15a8tOFar407l5iPWIk4jRmI/rCg7mTBp7HItTgUOIHTJ09Izc1hNnV0Ju/KHiJfGE8AFHdu/tOb784Dn5fYXAc4pKZtZ9BxBLJSP2Cagb/MVHFu0wXnHrMMl7JGvI5ycxnSusW5tdMitvL889G4fIaYDj5WVK2FxH62r+XhVhY6j6ucQqoPMmuAiYqRWZVud9wybRNhZVk4zkl5rJ+JNvDih6qmzNrkLeL0XeABWvanbXnczO8Xd32ElcQi8xh7W3YfVGpdV3RepzS2IEfy9DBwCdnP3cwvKrkMsJi9uZnkV2VTqvcyyPv6bsID4iZktRCy4lZV92swet5zjUAte4u7bm9nW7v49M8vUAlXsCaxNvNQ3SRYHtWogG+nwkt2HdTr8xTwXSMjdH7JyN/fb0t9r6voyTn07LV23mekcSxJqrDVr6p1r4dRVG6tkqI9rE7On7Yg1qmMpsYjJ1bmCGIie7BMUtKyNQO7i/XVe0rn8mJExKepcUP9uEVHu5LS/I/XxG44n9GLbp/2d07E3VNQ5mnioM5Omd6dju1bUabzgaBHYZgdiVHYy8eBd5e7HVZw/41BiBFPkkl0X8azNdd8z/e0UI2FItTKJeICWqKl2KLCZu/8uneOlhNnbKgVlFyDcx6cwciF0BoP/dVG/Plnb+XL+DdxkZucx8vrVrZlkz8jDSS/6ILGCX9mWh34biyhit5vZyg36mHenz+7Dd9TUecbMls1e8hZR+gqFmLuflf62jS3RtW9nEC/M7QiHpjMZqU8uI4tV8rSZPQHVwb7M7EDimXyI0AWvXzVoG2IXYuZ+g5ldDhzv7r9uWLcRbXTIXby/OuloLTzmjiRGRk6sBH+saLSYq3O9u7+67tjQ9ze4+2p1x7piZv8gzHoOAX7pYVlwV93vz9XvFM+3y3U3s6+4+2fqjpW05cSDMJNQqezv7pdW1PmNu29Yd2zo+xU8FpIbYTXBm7xiMdK6ey3uSqhFViUGAwsSnp/fqqhzOvGQf5zQdT9EWLyURmDrSm5mks1gNgR29wrdeHpZ/g+jo9GNm6djrq09gC1SWx9oe983bGNfYoTb2eU5rU+8lZBRTxKj5iO8Joxpo3O3GOWPC2Y2j7uXrlinMuu7+2V1x4a+Px84gZGj6vd6QRjIXJ1rge09mb+kxbCfeEmIR4tId3sxGMldQxI+RVPcpBLZIvVlQ0KHtwWwlFcsYA2do3UYyJLzVF53Kw7zeWOdyqJjX75JzK7yFjF3kqx4il7yaRr8v4wWDK3CcfYZM9uIiKdxds3/anXCcidbJL6G0NvfaWZTvGTRMtVdjFgIM0L/Wun2axEq4BiGItgVqKo69W1oJmPELPUmQqeLu9c5oWARX2aW2tHdyyx28nX2IDyNH077ixDu+5UOQGb2cuIFuhVhhXMSsRC+w3jci7UC2QZBPAppMI3LVq83IfSoW7n7C2vKFwmHyli4JaPqPb3asuD1xEjmLuJmWI4Q4qPsqy3M495HCORMr7YWYTZ0GLBP1cjazJ5LvFV3JJwVznX395SVz9VrHM+3oG7tdbewo/ww4XDyh9xXCwGXufvONW1sTwiQGRbegGsQ3melAXXM7MSy74iR/KjrYma3E3a7NxFej1nhPwyXHarX2PKhTI+eq1MVa3gj4CF3v9HM3kEIiDuBo71BaMh0f7wcuMfdS0Olpin9V4ADifvQCDXRx4j1kC/WDEJaWXSY2XR3r9Pjdu7bWGYyqf6XCVXgSenQjsRib6UXZ8mMui7O+JXEout3CSucJ3Lfnek1scMb4fUrkNOqtpq6jb2kUvnXEm/X+8h5fREunzfU9bXLRsRRWJUINDJvRbnbKFj1BZ6f/kkfatHm84ioeU3KziAE0FPAo2n/0fG67sSIbHliZrFcbqtd4U71b0x/NyBUWluTPMKqfn+H/9NlHf+/jS0f6BhfgnA3v4Qwv/oBoQ/9IBE5rDDeC/Fy/iPhsvtmQtVzBaF3nlZ1vYHlC44vT+i+S2O+0MGiIz17HybsexfNtvHuW9cttTkptz+ZGk/CXD0bqlfoVUkk4gB46Xj3f3hrMkKejzCd+tvQ8RcQguHfBXWGvaROJ7yk6vzmNyJMUD5ITJMyZgBn+VCUsFSn9QjezDZ19wtspMVEvs4oJxIzu80jhkJRv29395cVHK+cPbj74VXft6XrdR86R5s4z7NGFWZ2EOH+/MMGI40/EHEDjvcCy4qSOpsTK+LnM9KJpy5yYNa/G9191aRGOseLI7B1SuFkZre6+8vTs/Jnwmb56TRDudHdX1VQ5wZCVbMwIRxXdfe70vX/dVGdfFsl393h7qULgmkGkFl0vNqSRYe7lzpStFmPGGPfziPUh3kVwo/c/Y1ldVK5G4l4J/9M+4sSaou6aHlfJV4UxxDy44PAfe7+qYKyrTPVdKWJlcXhhEfUsJB6AzEqKvI46+IlhQ/M6U7w5sGuW5vlEHbUFzDSYmJWNxj9WwEeNbPV3P2G/EGLNC5l5lGZVcBKRGyJLE7wlgwWVmppoSPrdN1TG1sRi49t4jwD/NnMvkU4XXzFwsGkLmjVSoSb7G5mdhTx8vieV6sf3kXMZBZkoLJwYjW+ijaWD98kVC5tdff/hjCvM7N7PDn8uLubWZkJ5TM+sDK529OCpbv/1cyq3NyfspylRIaFxUSdaqS1RUebl/kY+7a4NzfJy3MQcJ2Fg5IRz0kTz8fPEM/Lh1K9cxkEu5pzNBjalwY6oXyIP5kI+Px9IrLWiYTrbq0DQDY1IFaDzyUE5wW0MJanYfg+4MVNjqXjGwD3EFO4rQih+gVi2rlBTTvnAFNz+1OJWNJNfsuXiYhW70vbecCXx/u6E4GWns8gmMwmwLEN6j2XsOtdKe0vCWze4n+1MTGqnJF+5zol5WqDUpXU2zXdDxsyiG/ygZKy1xV9btDGnwjV2qdyn7P9+yqu9yLpmmefM5VAqXqOCEX7O8IE61VEqNT3Ei/it9X083RCXbYfsYD6M8L6p6jspunvtkXbBPRtOhGnOdtfjgJnoJK6SxIqoK2BJTrcI4tSEVyICIJ/Y8F2Ew3UI222JiqLqql66Xe5MvMRwmtHQqj92t13qqnTeGXXzD5POEHcnkZnvyLCJc4EdnL30lB8JYuHpYsYZrYEoU97BfFWvQU4yt0frPk9txP/8CfT/rzEQzdKzVFQ90bg1Z6sMixMbq7z+ilZq+tuZte4+1rp2q/u4WBSmPC1oO5qRBB9gEt8aBZRUP55xIj3PYQ+87uEsFiTMEkaNSqziLNxsNcEVh+qMwl4u7uf0rD8DcQLYhIxCNgY6lM4dVmYspHmggVVKk0UVyOEff4+/FrddR86R6VFh5l9wd33teKQBO4l7uAFfbsZ+HqDe6KVSV4aPe8DvIQQjAd5i1gSZnYRIcSnENEH/wZc7O6j7NfN7BZCz1+Ijy2t1qiT1b09LqZg1ELooipDSDI02iRGhu9t0GYjl9hUtnX4PsYQLrHLBnyeMOP5XNqmA59rWPdGcosoxNu8KhTkLNfpoes+raad8wl1wBGECuEwGgQVJxxLbiaC0OxPPBwfranze2J2sVzBd/uU1LmJmPbeQiyEXUeDEVTdPTpU9o+MdlfPtrvG+Z7YIP0d5TI8AfffolXbBLa7YMvyixGDiK0Ir8KqsmcDXyJUX0cAJ7Rsq3FYUSYoIUTR1mSEvA5hL3oCg+hfWVqWd7r7lRV1W41Ac2X2I6aWtVHYbGSa+NMIc7JvlbWfjm9NTK/eykgd5AxiIWGUQXqFSVTTlDtrE299J0aRV1eVz9XbkVBbjNCRufuPKupUOlmU1FmA0IUaMXpdmLAQqPSQTCP413py007n+W3R9TCzA919HzOb5A3tsHN1Vyw67vVmb/9HWBO09RZt07fKxVkvXlie7u5rdl0wshYOG11G42kdZ5f0eZq38NizSKhwHCGQl02j5g94LvN6QZ3svlvB3fe3MGNdwt0Lg8bbkNla2+uYnufNicBGn/WIZFdod29mR7r7R5qeeyzULup5xNVdh4gEtks6fDPwGncvjDecVm9fASxsIy0ZptIsvfq09PfT+a5QnGSydfg+7xAukbGlX4cQCo/DrMSMjXD3k9P0am3igfqM16hI6OCy7t3iPJP6lI9a9zTFDz6EU8w+bYVx7rz3e3g7bkAs8BUm6Bwim1rvkTtWeC9ZSULUWZXKbatrw5QW8FRSB4xK7JnaqrPvP5VQ632HmszH3m5hLiNvU78n7e6JQ4mR65mp/RusJvsMsaD6DOGtuD8xODqNuO+LMBuZFXwAnOBFAAAfv0lEQVRyfr/BC7dxWNFMGFvk3TsQeJG7v8nCSeS13iwUQiMaxbJIgndfi7QsqxAXrspNsHXA7qH22txAHycCxywOfMNTRmOL8H3XFVUws73c/WBgpzQCHW5/1MPgY9ATWQT7yeIuG3CKmR3lFV5BNjprcuZv/yIze1GFcIB2Qigf33kUXh3nGcKx5koLF2AjFlbKbtDJQw/RcFtVD9EZwNpppPx9Ip3VD6l/Ua7iQ6aZSb9eRBaDYT5iFnhD6uuqwJWELr6o313iPWxJWKZsSjeB3jq5AkAaIG3AYKZ2RknRRtY5Zbj7fTYyqH/lS4MY4K1hZpmH3kNWnRpsOEM4DLKElw3e8v07lVwwIQ8rl+3KawChJTieQaD+3xGDntkrkGGWgPsWoXc14MVm9gF3/9Vw2Y4j0HxbjaOwediNjlocc/dfEum9i2gdyapCcFUGM0nsTujh/5XOdSDhSVjlpvnJVO/rBd85FTkG27zQ3H2h1Kf9CZOwExmoLWozgLj7IWkEnwmr97p74YuQ+D8NP0SzTkX1Q/SMuz+VBMqh7n549vDWcDnJlK3mGO6+CYCZ/YhYULop7b+SikA3ZnYW1S+1UR5cHi7LP0oL440X43J0Sa7wTWIRLAsv8EEze4O771FQPBu5GwWj+JoR/H1mth7gSah+jMEzV8ZTacHaU18XJ+eROYy7L19zvkKywZiV+C/U/K7F3P0Ui2wvuPtMM6t70bSiTbS3Q4gswXfCLJ3eLwirhjLuSyOnxiExE42jsFlNVC8v8IX3DpGsMsHVEWNgD0v6XJkTyCOF/SRi8a80hkdpg/FALM9I/eL3K6q80d1fk9s/2sJVtC6y3KwmiQeo6nfd6hUOIzXMtHDTfjeh/4eK8JsWFjFLESmSVs/1ayr1mShelgljAHe/2SLpaRlfq+t8Qf9mCQQrSA/VQGXRRq2XsRHwSk8LR2b2PWKxtIj8edva+n+QWBReipjZncvI2VoRhxMvlxdYODi9nfoQtQCY2VKEmVz+Xi9zB+8cVpRIF/V8Bv+3dSn3QehEG4HcJWfd8bQPiQmwto+MC3GBhUlSEZmgXJnQN2WLdFuRSzmVp8uIpuAcbTzaTgSuSIuOANvQQCfnYXr2NcKlvDEWsSJWJMx5sje4E1P9Mp42s3cxSE+zI/XTzMzscHtC32dEVuJT3b1J5uQ2vI9Q+xzs4dH2YgYjvSLeSKx5LE0MJjJmEOZSVdxmkZ36B8S12JmKEZ6HQ1NbugiEfJtd9MJ3EPkcM/XbMoQVT9H5R9yfZraAN4xrnkb/72rTMXc/ycymA68n7qO3uXvdqBoz+woRTvNWRt7rhc9+l8FYjk8S8mVFM7uMUJO+vcN5SmliZZEtyr2BeAvlI3Td4QWuhrm6ReEtK0NipjKtorClMucC23kKHG0RiPxUd9+ioOxG6eO2ROzebHFoR+CPXpGOycJr7usMebS5e6VHm4WVxetgVsbpplYWrYMLmdltwMublk91lidGNdls5jLg416TADK1tXqmp7VIVXWtF9inm9ku7n5C0z6NB2a2nbufVl9yRJ35GKky+w0RJGhUmIChepk1wwi8RUqwFn18LiEglk2zqZWIrOGlkc4sEgeszSDd/dpEJuXHUz9HDUSsm8VEkdXJI4Qb/89K6ryKgerxNne/uez8Q/XuIGz8awM4pfKVnp11gzGLxKtZuqg7itSoY6HJCDm/KPcXYtoDYUi9SE3dv1n7QPMQ06ULzWxEFLaaOssyMhHlk5S4yGYjGjM7wEeah51lZpW5zIhANesSaX5Wt0jSWZr3K8cdhMXDlNT2qu5eODoZolUA7sTNxIumNqFsRhK8dZm9i/gjMVPIhNW8jIwal2/jBJhlsvVpRk8zi0y2ViTCbj5ErN5/i0Ektd1qFjcBfm6RaXn5obb2L6uQBO830taGtXKfZ+WSq6qQdKWfISK9NcpVmTie0Mevl/b/RCxSVYWe7JJvr4vFxHyEcM0WzbYj7Mffb2abuPus7D9mtjDhMZiN1g14lZndC2zt9c4edxGqq0YCmZht3kfIpCupUR2mPpZlmHmpmeHFCZQ70cTsrU4QVvE+IiTmN2BWSMza87n7r7M3PsxKXFh3wU8Erko6ayfUAlVTdIi0QLMCn6dp8OI1dZ5y93+Y2SQLe9oL07SpFAtPrt0JB4NsBOUMRmCldNRdLwbcamZXMXLBp/TtnwTDbowWXJUJOtP5b7EIDuPETOrSbJRUogvNTLa+Tb1a5ATi4ZlKPEB7ES/A1xFrDOvW1P8ZMTqbTsOH1szWJ9yLh18YdSv3w4ONQ83sUqoF4UnESv1bCN3rNGKwU8eK7r6DJSshd3/CipTRI/t3sUVciZXc/fw0m5niNemIvL3FxEsI1+ssHdPRhB75DYzWWR9AqG829ZHeqAcRjh8frWnrceB6M/s1I+/1Mh38EqkfOxJhaX9BeIfeUtFGUcybWU1RHPumE22sLI6neDpW+sAmveoIIWCRG+/QkjZ2JtQoJyYBfGM6vpuZPebuP6xo60tmdjbNVvszPgFclEbikDIV1NR52MwWJKaxJ5nZXwk37Sp2Igzem77FZ5EesncRXo8HmNkywJJeYjCf2K9tO4TguoTw2Guzcnx62jIualCnjcnWQp7MAy3y7mWzrV9ZRJirY+kitVUNxxH3xgjX/TqsWy65VrkqczyZBGq2wLQiNS8cM9uNGBgsSqwxLE28GEvjJ9PNYmIpYlaXLXgtQNjuPm1mw33cjFA55GNcP21mWezrOs6kPsDULDwCP50NnG0RwmBHQgbs7+5HlNQZy6C0FW0W9fJTofmIEej9Hdr8JCUCmfCBLxo1/pjwVCsVyInrScF0AKwg8lQedz87jcQz3VWTkfjWhJPHJxh4tJVOfxO3EA9ma4HMSIP5A4j4xkdRYDBvZkcSGZW7LDI912vSNZXwKx9yEDKzlb065kQbk6286dPwinYTB5PLzexVeauJBjziBeacDRjOJXc39bnkuuSqBNiXECzLmNlJhO5/l5o6exBRB68EcPffW31EtS4WEwcTo9aLYJZ36YEWXpzDsWWe9IIMJx4mZbXPS35xzsLGfZk6VWASxG8hhPHyhIVHo1Fu+h8NJzuoe/4b0zmFk4VJ1vkNdF3D9e5z92VKvitNGVT1Xfr+o8RN+hcG3mJeVSfVa2welqZS57j7ZlXnLKi3JuHYcCMjBVBp9uNc3Ws9Gcz7wEW8MO+fme0JvJOIfvVjYip2fcM+fpGIXVFmu11W7w4ib9wpaf9TRPD9wri4qczdBYe9SCVgZo8DtxP/z5XTZ9L+S919gZr+3UpMoe8mrn3tfWGRhWIy8ZDm/191+urWWIdclbm6z2eQjukKr0/HdKW7v8YGMaKnEAuwE5Gma0lC+BsRU6Zw8GYReGtHRutyDfhB0eLwUP2LaBgkKJX/HhGF7ldEmIRGi4ep7jGEyeQmhIfk24nf9v6m56htYwwCeWXgF+7+kpb17nX3ZUu+uw1Yy4fMaywsJq72iuhoZnYn4e3TZNEwq1NoHlahf8pWad/tLVLEm9nNRESz4fRDtRlrLWyB1yN+/xpJ13uuVweAX44QzO8k3uQnEzdfaWJHC8eXBQgBlNlJ1y0eZg/escSi3guJ6eynPDnBjBUriWGR4fWxLJYrqVfqeWkRW7egSvHgw8YQ92EsWDv7W8zsYMLD9j2EbvbDhG34ZyvqtLaYSPUapYpKArXKBHWTsu9S/ezlsisxOt63ZmD3DINwAvl2a+93GyQ5yP4uSFg/bV7Vxza00SFnnmqW/j5IrA5XlR31FTB/RTPHEanAP+TJ3MrCHOso6t0T76O9kfZatDQPo1uK+H96g2SNJRQZzP9fVYUkbL5CBIxfnXgZ7EuM+srqdHJ8cfcHku5+b+Jls3eZMLYOmVrqBG6D/t1jEftiJXc/Pr3QFiwrbxGH5YtEGqp/5Y6/qaKZ1nEfbIy5Km1gf3sLIwP2V1kJ/S+RX/AmYq3kl9QHZW9sMZHr267EdViaGOysS5jXjXqhufvGNe3XMSUNCt7BwKW5FHevS55QRZZD73EzexHwT6CLPXgpjQVymwd2DA/318zsX8TCRvbQ/IsIyF63CHQXoZz/BSOnmVWCsLV5GLEq+4sW5QGuNrMDiMWHfN9qzd68g8G8DbJdvzPVu5gId1lVp9Dio2rEleqdR1y/VxIP4Hctos0VuRpvRMtMLWb2EOUvd3f3OrOyfYkX78qEqdhzCLvz9QvKfozQj94GZAtt2SjwS5R7pXaZZuYdQ75AvDDb8DbC7rip5chkIivLzoR1S1PaWExk7MkgVdQm6SVXeP+VvZwzil7SQzQOEjQO/NwilvfBDOKPjGuWkVqBnKZ8D2dTdAu727cR9qdHeUW68i64+zHAMUkgm9eY5OS4N23zpK0Jrc3D3P17Fqvby9YsXOXJgrxvnD8VDczezOxEd383A91p/thw2cycZ0ti4SaLydDEwyrvKjtf6vN0KmJmJI7yQYCah5NOvjCFjrvvm/62WbVerEXZIrYBVicFnnH3+5MKrIjdgDXd/V9pZvYTM1ve3Q+j2l61ddyHocWoj3dQc7Syv/WwXFjczOZp+cy2sZjIaJMqKns5v4BQzV2Q9jchLHYqBbJ3CxLUCgunrvvc/YC0vyDxMrqd9rbqlTQZIZ9C3NSPWPjzn0rYCL6asAAYFV+iK1YQl8Jy9o9Vo12vSRdewn5tK1jknvsaIfRfnK7J/jVC/HVl3zVghAdgGumUxZPeh7BE+R9vGe/X3UeMWi3M60rjWFiKRufuZ6SH7j/pPDPTqLmoTmtdq6f8dLlzLMrIEK51lj5Purtbyi1osdJfxuRMTeHufzSzjQmhvBzVAnkscR+gxQg7p+poa38LMYi6LK2D5NVtVbPINhYTGX9KI8kziFCwD1Hyf8pezmb2c0J9+EDaX5JQVRZiYcJ3kYeliBEqzben3zjN601e25DljMxmkl8mdPCvJtZPxs19uolAnt8HK6Q7A991969bWFk0WsFvQeu4FBlJN7gXo01SqqKiXWwR4zQzIbvKS2I859iPGD1elM5xvYVDSV3fvggs5e5bWsRRXccr3IgtIkrtQwTHybyVjPBALJxy+iBa2YoWdtv/SUJlVeD7nksi2YA/EWqIMn7IIGLabxkZPe2bFERTYwwxdi3Mjb5BqEX+QYzcfkdBpL8hTrFIwvq89BC/j/Ip+4Nm9mpPlilppLwloYMvzAKdyn0v9XH7NGLL93v74lqdyQT+dFrY3ybuT9skGkTyA/Cwkf4lA4uJfXLy4NMldbZJH/ezWCBdmDDRq2L5TBgn/kLk1ixjT8JpCGJWuBqhz12dWHcZyyBomMm5Ac4ORK7J04DTzGx8ZaDXpzq5Kff5WiIqWLY/rgn+cuc9l3AIyPYXInJ/1dV5P6H/24h4iL5SU+cdRKCV7xFefXcTOdiq6lzpQ2ld6q4DoXPeiZS8kphq3lRVJ1f3oA7X73riZfsSwo35G5Qks8zVOYK4kQ8nvCsvJcyOysqXJgQd3s/fP0WfW/ymxRmk3nkDcExF+ZcA6+fKfpWY2Xye8HIrqrM0JUkys3PV9HHUbyr7nUSQo0fTNjP3eQbwaIO2FiAERbY/mbAlH9dnMZ17EUIgb5htFWUn0SEhbbrnziFsqacR+vojqu6H3OcfElEkO91bDfp2MylRMKGm2DD/3Xi21WSEfIGZnUIs3CxC0vGkKcW46o9zNI5LkaOLx9Nnichyf4VZI9nziYD3ZdxsERthsoVTyccIl/AqXuDuPzSzTwN4xPVt6gGWj7CXqSw+59Uqmmc8VAfbELGDj7D62MH5qfZMwoa5Kuynl3wu2s8YS4zdme7+NwuXdXP38yysTso4lBTVzd3PI7J1Y2Zrpe9GLSx6RVjYqmuRLDDeDCw19JumUuLF6WML5wqRoXszYtEbwnrpXAaxLfL9O9TdP24lUQ692qW+scVEOtczZnaD1ThlFdT7SLpfs3WVY9399IoqzyQZ9BCxcJ2/F6osubpwMiFP/k5YWlwCYGYvYQ6E3/w4MUxfkkjMmHkWLUEDM5OOdIlL0cXjaZKPVFH8g3jDV/FR4nf/h3gzn0OoI6p4LOk+Mz3m2sRIqAmvN7PtiNH/YsTIv+5F85RFjINpDARPaexgmLVYOQ+DaWLdgmWZcDVCnVDEWHStjyS95aXA9y1c1qs89Zb3AisWd78mLdiNJ/cTv+etjMz+MYPw6JwI5vOcWZ6HeqUszvOJ6W/ruM20sJjIsSQR3+QqRuqq68LaXk68wJxBRLoyPk9c88nAmZ5iUVhEcryrqmJbPMIy/Jr4Xed6GhoTsqIu1kYrWjuGWHgHbQjc6+5dUs80bWdNBnEpfuM1Snor9njaz1P805I6XyX0q1l8hB0I9UOpC7GZrV7Xl4I6axHup68g0gItRYQXbXQeM9uBWOB4HNixZuRK0lF/kEg2enLSce/g7l+uqLMxobr5IyFUlyEWR8piSk+r6oNXLNiV6VqHjw19vxDx+ycRjg0LE3rxQu80M7vTS5yWqr4bC2b2HB/ncIwVbV1GZPe+Nu2vCRzp7qNiZ7cdrQ7Vvdrd10660td4rEtUhtC1QXjbEXiFS7+ZvYNQK11E3H+vAz7t7qWzVQv78v94mLu9nDD1vJ2QF+PimDTbaaA/+TmRZQDiDfEAcBYREPrj46k/GWp3MhFzeNls63COwv4xUr+4LRHA/BtU6BdzdS8k/ukHAK9o0Zd5iIWHVwPztKi3EjFy+BaxsHkME6ArJEZ2K+f2XwpMb1Bv+ybHhr5vrGvNfX9gk2O5704mwnMOH38/8OPxvn7p3FsSeRz/SQt9cMe21ibWBy5J252El2vl9QZOa9nO6URuzP3S/fczatYjOv6eGwjVXra/OGnNpaT8vsAVxCj5IEKV+vnUx89OxDWfHVuTC3VL7vM+xKgEYqFtohb1Pgr8nfAIupGw+WvdFjGKLzr+cyLC1PDxtYCzGpx3CUJ3fFnq2+da9msTIihPk7K3A69Pn40IwHRLTZ2VCD34rcT07S7grpo6o65vk2veRrgCbyJmL39hsIB4OLFaflWHdqoe2BcSL7KLiKA/XydUPb+lZOFuHO7bO4kZl03E+YfampdQQ72SsAB5DjBvSdnSBdiWbW5EqGUqBxSEnvlqQr/9JBGWoPLFxNAiNzETKl34Ts/dZCK2xKPA1HR8/omSS7Nja6JDzk/BXk8yGXL3GRZ+4RPBnsRorXFcihLKbEeX9zHoF939QeDwZNKzF/FmHqVHTlO3o4mR/hnEm/x7xE1TtSCVZx1PQbo97rivW03WA8IjbV9i1L8JEYO6LhD3NWZ2HAN947uoyIbcZSGLDrpWM/sAoX55qUUmmYyFqNBDu/tfgPUsHJky871fuPsFZXXGgfuIVfd2esBu/NYjg86s4Djp+hSZG1YtwJaSTFtvdPdXQrXKYYgjCS/RU4lBznuIQUIVZ5vZOYxUH1YFuprpYaP+uJn9IfeMPDGBcmniafBWPIsYsW5DrGg+L/cmqhypjeFNfCHJzGSM5ykbId9ZUaf0u/T9KsT07WZixPVhclOtobLXESvhCxDG448An2zY971yn7cf+q50qp6+n57+5k0WL6mpMy8RGvWnxDT1E5SMuFL51YhFw3vS32zbFlikpq3ntPgfLkKomE4lAkFlW+E1n5MboUbI4np8MtvGuY0lCMeg2wib2zXStjERPraoztMMVCitTOyIAPqt1IVE4CHIjVSJSIJ19fLqw21qyl5JUt0Ri/PZ8YUZZ7O32bk1yan3AsJffEnCTfbcdHwTws20y8ptXZvHEc4htXEprCaQkbuPmgWY2cnABe7+7aHj7wc2d/cdKvp2JaHyuIiIwFaaZ81yITPT/l2Ejrp2lGIp7Obw56L9grqXEYsiPyF0a38m4oGMcl8dy4JPqt96ISstwB7AIFJZ08hyr2Sw0HuJV2d5mO1Y5HX8F6Oj+nXxIi1rYxphq7sWI2cIM4ATfBzTCaX2LmCQh6+RxYRFGrTNCO+5B9K2ixeEjB2q90LC3tmpcdKynHfo0PHFiAQObeJf94bO4TcnEouAMKMYrxs7/eNPJ/Rb2dR5LWLhbRsPlcRwnSnAgYSn170kcy9CPfDZIqGUBHA+Gtah+X2viHlrI+MfDwv2EfsFddcmRlDPIwTfwkS25isKyuYF/2nu3ioOQBfhahEqdVtiBN/oBjSzPYjAP1ncjK2JAcI32/R3IjGza9x9rfqS49JW6+StHdvpYjGxHLFOMA8x05pKJIm9s6JOayuLZyNNRshjytLaZ4b0i7d4hX7RzL5B6C0/4YPM1lMJ284n3H3PgjonDh/L4e7+nor2Oo+Q21Al+BvW7yJcLyQWKhvr+szsRmA9T+ZMFgFeLvcJCK7eFYvA9hdks8gJamNnd/+BRSKAUde7aBY5uzCzrYmUWUel/SuJoEFOqOCqTNhuAN7gQ05adaPqZxtNFvVaZ2kdK9YhLkUX3P1CQl/dhC2JDBWzHgJ3f9TMPkRYQowSyO7+bgvPurd1GM2sZhHDwhgdz2K+ogodX56dFnxydFnI2gv4pYUnZdNQqcbIBeYsiH6f2APYyyIKWuMg/y3JgiMVxXQe9+muma1LWMasQox4JwOPlfymvYjFvIx5CX33gsRMsmq028VJ61lHE4HcJUvrWMky8W5Ju0y8E4kXCR2PMISlD0L6/uNAK4Hs7qXB5Cvo8vKsEvxNhEkX4folQtc6HzWhUs1sikcs3hOBK8wsu47b0CI40ezAx+4O3YRfpLZGqe8sIhGON20sJuZx9/ty+5d6BOX5p1VH2YP2VhbPSlrpkG2QpfWrRMjJwiytY+6U2XR3X9NyqVjM7GJ3L9RnzQ7M7AwiXcv3h47vDLyjZpHjc4QA+jEjF0YeLavTsY+TGbw8V2U2vDy7LGS10bUOqW7WJnSLRnhjXT2Wvo83ZrY+EfTmsXRfrEHEEum8aFrQxh1EgK8/Dh1/L2EPX5nyqkN717j7WkPP4uXuXhQzo8o78g9FfUuDlcuIOBlbEYu22f+3KpbFs5JGGUNsDFlaO9I1E+9EsgfwUzN7H7EQ6MTq8/zEaK2KD6S/n8odc8IDcdzwDinOx4FFvX1OsfPNbPOGutZZo/wkgHslhIc4mphxrEbMHDK77vEcSHyCiDH8Znf/PYBFqNadxrmdjMctYpzcYJGT7wEGapNhrjSz3Qqslz5AeWyKpYmwAi8jnMAuJwT0b8ej83MbTRb1Omdp7dypDnEpZhdmtimh2zZiIbA2UenspODleSYRw/rPE9Re64Usa5FQ1cz+RNimFjInF7GGsUGG8M8Df/aIPjhuC7C5dl5PuNK/jUgQsTawpbs/NJ7tpLYaW0xYmMieQfxfMyeeNQld8ts8nHXK2pmHUImsR6jeXktkKirNXv5spIlA7pyldTyxSHNz6OxoayKwiJL1ckYuUv5wnNuYEy/PTtmqW5z/AWLkWagPHy9TyPEg6dHPJjwjNyTWPa5399Lg9mNoawNC+F1OqMxK7eE7nn8sFhPZoAVqrJdydRYmhPD66e/zCMudNum+5np6aYdchJnd6+7jOsWfXSQd8ubEtOwc4I3EgkdlgscO7fTi5VlHG13rRIwwJwozW4JQHVzt7peY2bLAxsPrDmNsI5/9fV7iJfg04/8ivAx4Z7ZIZxHtbVOSxYS7v36c2jmWEN4ziIXoK4hQn+M+2p8bmJvMSvpm4tSGHYiYEg94JCddjRYZv5vi7pPcfaG0Tc1tC02UMDaz9bMVdDPb2cwOSYKoiqMJ3WSma72HQQyNUU2MX28nFnd/0N0PScJ4MSIx5rgJ49TGQrn/6TzuvsAE/Y8LLSbSS7POYqINyxIvlgcJj9I/AW1SjT2rmJsE8twxlC/mibTgNtMiru+DwApzuE/jRRvhmjEzmRBuDRzmkdW5zGRsXEZiE4mZrWtmF5nZT81sdTO7mYh18hcz22JO968ji+R33P0jud3Fx6sRd9+C0IFnIRg+BVxtZueaWW/UUbOLcR+ljQWriUsxm7sznlxnkYX3u0T8gUcZLHrM7cx0d086x8PSQta0mjozkmXAzsCGyVyvMKOJt8yePYc4kghNuzARO+RN7n5FWjc4mfoEn32ki8VEJ9LL+WYze5gIwPUI4YOwDhG18L+GuUaH/GzBIg/XVE+ZHuZ2uixkzQ5d6+zEchk0zOw2d18l911rd/Q+MBaLiZbtfIywrFif0IdnJm+XEYt6c28ozQ5IIM8mzOydRKS3L5nZMkT4yAlLgTW7GKtwTbrWf/hcfCPabIo7MifoYjHR8vyHkGyP3f2B8Tz33IgE8mzAzI4kpuQbuvsqFglPz3H3tedw18aVOuFqERfhy0SKowMIXfNipDx57j43Tu2xyCD+GAPV2uPZV0Qy0soEs0JkzE2LenMz67n7B4B/wyy9aGUMh77TcSHrSCKE6cmErnVXd1+CUHUcNFs6PgG4++ScpcOUIesWCWPRmF4t6j2LecoiHU4kxovM3XO7bqzLQtYUHyQ42N9TfGZ3v91srrFuE2LC0Ah59nAUEe1t8WTKcynwlTnbpTEzxd3PdfdTgQfzwrWiTv4l9MTQd9Kdif96NEKeQMzsl8CH3f37ZjadSGtjRI68CXdrnmC6CNfWMZ6F+G9Ci3oTiEVami8ScXsP9pa55/qMFrKEGH8kkCeY5Fb8eWALwqogHzO4N5HKhBBzHqksJp6niJHkvIR78Ny+mCeEmCAkkCeQZP51CBGTeA13f7ymihDivxipLCYQM7sE+KBPbP5BIcSzBAlkIYToCbJDFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RP+H93sr/Hiht7zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22557b33390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1454</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0          856       854          0             3       706.0         0.0   \n",
       "1         1262         0          0             3       978.0         0.0   \n",
       "2          920       866          0             3       486.0         0.0   \n",
       "3          961       756          0             3       216.0         0.0   \n",
       "4         1145      1053          0             4       655.0         0.0   \n",
       "...        ...       ...        ...           ...         ...         ...   \n",
       "1454       546       546          0             3         0.0         0.0   \n",
       "1455       546       546          0             3       252.0         0.0   \n",
       "1456      1224         0          0             4      1224.0         0.0   \n",
       "1457       970         0          0             3       337.0         0.0   \n",
       "1458       996      1004          0             3       758.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  \\\n",
       "0              1.0           0.0      150.0              0  ...     0     0   \n",
       "1              0.0           1.0      284.0              0  ...     0     0   \n",
       "2              1.0           0.0      434.0              0  ...     0     0   \n",
       "3              1.0           0.0      540.0            272  ...     0     0   \n",
       "4              1.0           0.0      490.0              0  ...     0     0   \n",
       "...            ...           ...        ...            ...  ...   ...   ...   \n",
       "1454           0.0           0.0      546.0              0  ...     0     0   \n",
       "1455           0.0           0.0      294.0              0  ...     0     0   \n",
       "1456           1.0           0.0        0.0              0  ...     0     0   \n",
       "1457           0.0           1.0      575.0              0  ...     0     0   \n",
       "1458           0.0           0.0      238.0              0  ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1       1        0        0        0       0    1  0  \n",
       "1       1       1        0        0        0       0    1  0  \n",
       "2       1       1        0        0        0       0    1  0  \n",
       "3       1       0        0        0        0       1    0  0  \n",
       "4       1       1        0        0        0       0    1  0  \n",
       "...   ...     ...      ...      ...      ...     ...  ... ..  \n",
       "1454    1       1        0        0        0       0    0  0  \n",
       "1455    1       0        0        0        1       0    0  0  \n",
       "1456    1       0        0        0        0       1    0  0  \n",
       "1457    1       1        0        0        0       0    0  0  \n",
       "1458    1       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0  ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0  ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0  ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272  ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0  ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0  ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0  ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0  ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 800, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=10, n_iter=200,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 5,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=5)]: Done 278 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=5)]: Done 872 tasks      | elapsed: 57.2min\n",
      "[Parallel(n_jobs=5)]: Done 1142 tasks      | elapsed: 80.7min\n",
      "[Parallel(n_jobs=5)]: Done 1448 tasks      | elapsed: 99.7min\n",
      "[Parallel(n_jobs=5)]: Done 1790 tasks      | elapsed: 124.3min\n",
      "[Parallel(n_jobs=5)]: Done 2000 out of 2000 | elapsed: 137.8min finished\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1),\n",
       "          fit_params=None, iid='warn', n_iter=200, n_jobs=5,\n",
       "          param_distributions={'n_estimators': [100, 500, 800, 1100, 1500], 'max_depth': [2, 3, 5, 10, 15], 'learning_rate': [0.05, 0.1, 0.15, 0.2], 'min_child_weight': [1, 2, 3, 4], 'booster': ['gbtree', 'gblinear'], 'base_score': [0.25, 0.5, 0.75, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=1, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=800,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=1, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=800,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0  ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0  ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0  ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0  ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117275.625, 163568.39 , 188306.14 , ..., 181178.69 , 115435.21 ,\n",
       "       236526.36 ], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('final_submission_work.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=40, kernel_initializer=\"he_uniform\")`\n",
      "  \n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=15, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=20, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=20, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=20, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\SHIVAM SINGH\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 995 samples, validate on 427 samples\n",
      "Epoch 1/3000\n",
      "995/995 [==============================] - 1s 1ms/step - loss: 184068.3304 - val_loss: 181146.1228\n",
      "Epoch 2/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 181740.9301 - val_loss: 174000.1387\n",
      "Epoch 3/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 143212.3915 - val_loss: 58374.7421\n",
      "Epoch 4/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 54339.2176 - val_loss: 44072.5038\n",
      "Epoch 5/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 47496.7208 - val_loss: 41019.0869\n",
      "Epoch 6/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 42467.3220 - val_loss: 38116.5616\n",
      "Epoch 7/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 38362.1733 - val_loss: 35666.5049\n",
      "Epoch 8/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 34925.9703 - val_loss: 33708.7853\n",
      "Epoch 9/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 32695.5133 - val_loss: 34340.9177\n",
      "Epoch 10/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 30811.5178 - val_loss: 30937.2452\n",
      "Epoch 11/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 29102.8891 - val_loss: 29894.3236\n",
      "Epoch 12/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 28142.8185 - val_loss: 29076.4018\n",
      "Epoch 13/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 27347.1471 - val_loss: 29117.1964\n",
      "Epoch 14/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 27168.5192 - val_loss: 29732.0134\n",
      "Epoch 15/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 26951.6017 - val_loss: 28642.6481\n",
      "Epoch 16/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 26624.8540 - val_loss: 28714.7429\n",
      "Epoch 17/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 27188.6839 - val_loss: 29277.2348\n",
      "Epoch 18/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 26848.0780 - val_loss: 28563.5818\n",
      "Epoch 19/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 26416.8690 - val_loss: 28556.7248\n",
      "Epoch 20/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 26564.3928 - val_loss: 30100.9548\n",
      "Epoch 21/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 26551.0551 - val_loss: 28339.8052\n",
      "Epoch 22/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 26570.8136 - val_loss: 30561.7642\n",
      "Epoch 23/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 26225.1547 - val_loss: 29985.3614\n",
      "Epoch 24/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 27075.784 - 0s 137us/step - loss: 26934.2919 - val_loss: 29826.7223\n",
      "Epoch 25/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 25962.8069 - val_loss: 28923.9184\n",
      "Epoch 26/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 25970.7115 - val_loss: 28668.0826\n",
      "Epoch 27/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 26045.2981 - val_loss: 29442.4683\n",
      "Epoch 28/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 25960.5976 - val_loss: 28137.7709\n",
      "Epoch 29/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 25803.2687 - val_loss: 28147.2735\n",
      "Epoch 30/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 26152.9692 - val_loss: 28640.3420\n",
      "Epoch 31/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 25580.8472 - val_loss: 28646.8855\n",
      "Epoch 32/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 25746.1351 - val_loss: 28439.6770\n",
      "Epoch 33/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 25526.7426 - val_loss: 28160.8820\n",
      "Epoch 34/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 25440.7008 - val_loss: 27889.9291\n",
      "Epoch 35/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 25578.3909 - val_loss: 28582.1759\n",
      "Epoch 36/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 25201.6418 - val_loss: 27834.9624\n",
      "Epoch 37/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 25754.5616 - val_loss: 31043.7293\n",
      "Epoch 38/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 25823.7465 - val_loss: 28144.5896\n",
      "Epoch 39/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 24975.1741 - val_loss: 27818.9169\n",
      "Epoch 40/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 25240.7403 - val_loss: 27625.3938\n",
      "Epoch 41/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 25792.8504 - val_loss: 29088.5318\n",
      "Epoch 42/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 25305.9261 - val_loss: 28166.5515\n",
      "Epoch 43/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 25208.9319 - val_loss: 27699.3378\n",
      "Epoch 44/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 24747.3794 - val_loss: 30168.6047\n",
      "Epoch 45/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 25120.6237 - val_loss: 27442.6636\n",
      "Epoch 46/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 24722.0218 - val_loss: 27366.4539\n",
      "Epoch 47/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 24701.6375 - val_loss: 27417.4336\n",
      "Epoch 48/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 24681.0088 - val_loss: 27444.2690\n",
      "Epoch 49/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 24377.8207 - val_loss: 27285.7288\n",
      "Epoch 50/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 24615.8472 - val_loss: 28188.7657\n",
      "Epoch 51/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 24299.1353 - val_loss: 27264.1618\n",
      "Epoch 52/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 25140.0315 - val_loss: 27292.5902\n",
      "Epoch 53/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 24160.9603 - val_loss: 27109.9032\n",
      "Epoch 54/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 24202.4165 - val_loss: 27297.4389\n",
      "Epoch 55/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 24228.8827 - val_loss: 27586.6860\n",
      "Epoch 56/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 24112.2162 - val_loss: 27041.7689\n",
      "Epoch 57/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 24059.0708 - val_loss: 27161.9171\n",
      "Epoch 58/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 23891.6273 - val_loss: 27279.6544\n",
      "Epoch 59/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 23978.5768 - val_loss: 27028.8086\n",
      "Epoch 60/3000\n",
      "995/995 [==============================] - 0s 177us/step - loss: 24390.8983 - val_loss: 27902.8669\n",
      "Epoch 61/3000\n",
      "995/995 [==============================] - 0s 181us/step - loss: 24029.8998 - val_loss: 27853.9971\n",
      "Epoch 62/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 23986.7730 - val_loss: 27120.2005\n",
      "Epoch 63/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 24198.8247 - val_loss: 27696.6414\n",
      "Epoch 64/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 24024.2550 - val_loss: 27620.8634\n",
      "Epoch 65/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 23760.7160 - val_loss: 26981.1765\n",
      "Epoch 66/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 24190.6203 - val_loss: 27654.9259\n",
      "Epoch 67/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 25471.6565 - val_loss: 26983.8639\n",
      "Epoch 68/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 23443.1673 - val_loss: 26934.2855\n",
      "Epoch 69/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 23969.9380 - val_loss: 27131.6724\n",
      "Epoch 70/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 23826.6047 - val_loss: 29988.6766\n",
      "Epoch 71/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 23968.5827 - val_loss: 26645.6567\n",
      "Epoch 72/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 23498.3265 - val_loss: 26996.7897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 23379.6897 - val_loss: 27332.8201\n",
      "Epoch 74/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 23445.7265 - val_loss: 27867.5724\n",
      "Epoch 75/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 23383.1604 - val_loss: 26602.2394\n",
      "Epoch 76/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 23247.5813 - val_loss: 27019.5410\n",
      "Epoch 77/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 23587.5654 - val_loss: 31996.9311\n",
      "Epoch 78/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 23855.7186 - val_loss: 27110.9903\n",
      "Epoch 79/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 23154.6124 - val_loss: 26667.5426\n",
      "Epoch 80/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 23102.2298 - val_loss: 26626.3295\n",
      "Epoch 81/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 23117.7969 - val_loss: 27044.2856\n",
      "Epoch 82/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 23453.9051 - val_loss: 26557.4625\n",
      "Epoch 83/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 23078.2955 - val_loss: 26816.3301\n",
      "Epoch 84/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 23572.3617 - val_loss: 30565.2231\n",
      "Epoch 85/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 26096.9580 - val_loss: 26630.8302\n",
      "Epoch 86/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22974.2373 - val_loss: 26549.0858\n",
      "Epoch 87/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22930.7219 - val_loss: 27931.5379\n",
      "Epoch 88/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 23413.7995 - val_loss: 26517.8623\n",
      "Epoch 89/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 23178.6103 - val_loss: 27667.1386\n",
      "Epoch 90/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 23048.9028 - val_loss: 28116.7148\n",
      "Epoch 91/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 22700.2624 - val_loss: 26683.5661\n",
      "Epoch 92/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 22911.7131 - val_loss: 26968.7977\n",
      "Epoch 93/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 22883.8138 - val_loss: 27316.0399\n",
      "Epoch 94/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 23001.9904 - val_loss: 26510.9803\n",
      "Epoch 95/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22686.6912 - val_loss: 27044.5492\n",
      "Epoch 96/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 23108.4533 - val_loss: 27020.4747\n",
      "Epoch 97/3000\n",
      "995/995 [==============================] - 0s 133us/step - loss: 22564.0264 - val_loss: 26279.5583\n",
      "Epoch 98/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 22711.8091 - val_loss: 26436.0934\n",
      "Epoch 99/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22608.9670 - val_loss: 27065.4600\n",
      "Epoch 100/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22464.9014 - val_loss: 26403.7951\n",
      "Epoch 101/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 22974.7861 - val_loss: 26437.3935\n",
      "Epoch 102/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22958.1665 - val_loss: 26690.8219\n",
      "Epoch 103/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 22323.4686 - val_loss: 26271.8327\n",
      "Epoch 104/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22250.6232 - val_loss: 27250.2078\n",
      "Epoch 105/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22906.8888 - val_loss: 26935.1465\n",
      "Epoch 106/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 22796.4591 - val_loss: 26271.9515\n",
      "Epoch 107/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 22246.1102 - val_loss: 26181.4198\n",
      "Epoch 108/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 22477.2341 - val_loss: 27031.8703\n",
      "Epoch 109/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 22454.8100 - val_loss: 26457.5768\n",
      "Epoch 110/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 22468.1606 - val_loss: 26012.3324\n",
      "Epoch 111/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 24387.3069 - val_loss: 28668.1454\n",
      "Epoch 112/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22603.0474 - val_loss: 26348.0538\n",
      "Epoch 113/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 21972.2024 - val_loss: 25987.2733\n",
      "Epoch 114/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 22759.9381 - val_loss: 26931.8362\n",
      "Epoch 115/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 22438.4061 - val_loss: 26184.3988\n",
      "Epoch 116/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22385.2295 - val_loss: 26269.5545\n",
      "Epoch 117/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22346.2413 - val_loss: 26053.3591\n",
      "Epoch 118/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 22324.6259 - val_loss: 26148.7270\n",
      "Epoch 119/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 22274.0711 - val_loss: 27347.6338\n",
      "Epoch 120/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 21843.4338 - val_loss: 26091.1792\n",
      "Epoch 121/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22928.0806 - val_loss: 26167.7770\n",
      "Epoch 122/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21944.5395 - val_loss: 27446.5523\n",
      "Epoch 123/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 22087.6107 - val_loss: 28658.8200\n",
      "Epoch 124/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 22445.5685 - val_loss: 27043.6430\n",
      "Epoch 125/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21918.7667 - val_loss: 27281.3642\n",
      "Epoch 126/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22307.8137 - val_loss: 26963.3060\n",
      "Epoch 127/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 22856.1605 - val_loss: 26006.0691\n",
      "Epoch 128/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 21805.1610 - val_loss: 26031.4935\n",
      "Epoch 129/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 21660.6927 - val_loss: 26385.9575\n",
      "Epoch 130/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21825.8213 - val_loss: 26387.2786\n",
      "Epoch 131/3000\n",
      "995/995 [==============================] - 0s 179us/step - loss: 22014.8807 - val_loss: 26126.1422\n",
      "Epoch 132/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21674.0303 - val_loss: 26771.7765\n",
      "Epoch 133/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22030.9974 - val_loss: 26005.0625\n",
      "Epoch 134/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 22276.4382 - val_loss: 26289.3199\n",
      "Epoch 135/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21901.7371 - val_loss: 25822.0070\n",
      "Epoch 136/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 21486.8819 - val_loss: 28278.5404\n",
      "Epoch 137/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22538.4614 - val_loss: 27021.5600\n",
      "Epoch 138/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 22009.0383 - val_loss: 25750.9257\n",
      "Epoch 139/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 21707.0649 - val_loss: 27302.8915\n",
      "Epoch 140/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 21749.8994 - val_loss: 27519.2008\n",
      "Epoch 141/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 21197.0969 - val_loss: 25786.9977\n",
      "Epoch 142/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 21625.2623 - val_loss: 26751.1065\n",
      "Epoch 143/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 22207.7256 - val_loss: 27010.5516\n",
      "Epoch 144/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 22492.8955 - val_loss: 27113.0160\n",
      "Epoch 145/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 149us/step - loss: 21461.0300 - val_loss: 28150.9389\n",
      "Epoch 146/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22452.1031 - val_loss: 25829.4041\n",
      "Epoch 147/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 21564.2236 - val_loss: 25809.7137\n",
      "Epoch 148/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 21279.3373 - val_loss: 25862.9335\n",
      "Epoch 149/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 21337.8496 - val_loss: 25915.2313\n",
      "Epoch 150/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 21328.3456 - val_loss: 26232.1237\n",
      "Epoch 151/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 22934.9121 - val_loss: 25875.3199\n",
      "Epoch 152/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 21323.2938 - val_loss: 25823.2653\n",
      "Epoch 153/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 21533.7878 - val_loss: 25585.9430\n",
      "Epoch 154/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21578.3712 - val_loss: 25779.8180\n",
      "Epoch 155/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 21375.2249 - val_loss: 25777.5457\n",
      "Epoch 156/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 21045.2563 - val_loss: 27675.1078\n",
      "Epoch 157/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 21028.9342 - val_loss: 25866.5910\n",
      "Epoch 158/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 21320.5182 - val_loss: 26297.7942\n",
      "Epoch 159/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 21344.2666 - val_loss: 26000.2627\n",
      "Epoch 160/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 21028.9144 - val_loss: 26108.9822\n",
      "Epoch 161/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 21641.0485 - val_loss: 25651.5546\n",
      "Epoch 162/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 21497.7270 - val_loss: 27321.7657\n",
      "Epoch 163/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 21150.6068 - val_loss: 25362.5984\n",
      "Epoch 164/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 21142.8122 - val_loss: 25646.8653\n",
      "Epoch 165/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 20776.8977 - val_loss: 25457.0924\n",
      "Epoch 166/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 21108.2675 - val_loss: 25365.0130\n",
      "Epoch 167/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 20979.1254 - val_loss: 25611.1734\n",
      "Epoch 168/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 20977.7629 - val_loss: 26653.6236\n",
      "Epoch 169/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 21453.6407 - val_loss: 25759.8531\n",
      "Epoch 170/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 20557.3818 - val_loss: 25668.1466\n",
      "Epoch 171/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 20487.8660 - val_loss: 25604.3222\n",
      "Epoch 172/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 20459.8658 - val_loss: 26731.5239\n",
      "Epoch 173/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 21256.5377 - val_loss: 25478.2735\n",
      "Epoch 174/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 20694.9025 - val_loss: 27335.6660\n",
      "Epoch 175/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 20816.9170 - val_loss: 26215.2146\n",
      "Epoch 176/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 21010.7081 - val_loss: 25491.6723\n",
      "Epoch 177/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 20731.5127 - val_loss: 26545.4609\n",
      "Epoch 178/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 21385.2389 - val_loss: 25389.8185\n",
      "Epoch 179/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 20672.8915 - val_loss: 25259.6920\n",
      "Epoch 180/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 20956.7762 - val_loss: 25507.9983\n",
      "Epoch 181/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 20527.7161 - val_loss: 28038.6750\n",
      "Epoch 182/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 21038.9117 - val_loss: 26223.0843\n",
      "Epoch 183/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 20227.0443 - val_loss: 25198.6015\n",
      "Epoch 184/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 20463.4761 - val_loss: 25399.9109\n",
      "Epoch 185/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 20500.1996 - val_loss: 25398.8160\n",
      "Epoch 186/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 20264.0948 - val_loss: 25786.6422\n",
      "Epoch 187/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 20172.7533 - val_loss: 25339.5354\n",
      "Epoch 188/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 20060.4650 - val_loss: 26767.4175\n",
      "Epoch 189/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 20684.0301 - val_loss: 25242.3861\n",
      "Epoch 190/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 20091.8148 - val_loss: 25090.3916\n",
      "Epoch 191/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 20706.9148 - val_loss: 27102.1416\n",
      "Epoch 192/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 21339.8117 - val_loss: 25023.2242\n",
      "Epoch 193/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 20323.7907 - val_loss: 26555.4949\n",
      "Epoch 194/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 20385.0301 - val_loss: 25624.4455\n",
      "Epoch 195/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 20137.5900 - val_loss: 25073.8438\n",
      "Epoch 196/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 19994.0443 - val_loss: 26294.5001\n",
      "Epoch 197/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 20642.2653 - val_loss: 25187.4726\n",
      "Epoch 198/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 19967.3655 - val_loss: 25057.3825\n",
      "Epoch 199/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 20349.9814 - val_loss: 27570.7140\n",
      "Epoch 200/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 20208.0834 - val_loss: 24997.2673\n",
      "Epoch 201/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 19756.0738 - val_loss: 25410.7516\n",
      "Epoch 202/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 20411.6931 - val_loss: 25540.4700\n",
      "Epoch 203/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 20489.1194 - val_loss: 26127.0561\n",
      "Epoch 204/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 20122.0185 - val_loss: 24857.7315\n",
      "Epoch 205/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 20047.2352 - val_loss: 25414.6201\n",
      "Epoch 206/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 20003.0994 - val_loss: 26192.4025\n",
      "Epoch 207/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 20070.5726 - val_loss: 25371.9599\n",
      "Epoch 208/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 20601.0108 - val_loss: 26397.4032\n",
      "Epoch 209/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 20204.0907 - val_loss: 27622.9917\n",
      "Epoch 210/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 21590.0508 - val_loss: 26114.1604\n",
      "Epoch 211/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 19956.0691 - val_loss: 24858.4151\n",
      "Epoch 212/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 19781.9486 - val_loss: 24836.9583\n",
      "Epoch 213/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 19465.3967 - val_loss: 25163.9354\n",
      "Epoch 214/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 19558.0081 - val_loss: 25297.6938\n",
      "Epoch 215/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 20512.9539 - val_loss: 28373.3694\n",
      "Epoch 216/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 22071.0491 - val_loss: 25133.3248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 19734.4660 - val_loss: 24962.3270\n",
      "Epoch 218/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 19766.0564 - val_loss: 24802.5084\n",
      "Epoch 219/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 20406.9641 - val_loss: 26550.8198\n",
      "Epoch 220/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 20176.4304 - val_loss: 25231.6993\n",
      "Epoch 221/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 19503.5755 - val_loss: 24636.0739\n",
      "Epoch 222/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19689.0044 - val_loss: 25188.9393\n",
      "Epoch 223/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 19864.3923 - val_loss: 24944.7827\n",
      "Epoch 224/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 19310.6205 - val_loss: 26451.5139\n",
      "Epoch 225/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19630.2079 - val_loss: 24951.5712\n",
      "Epoch 226/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19792.6875 - val_loss: 25480.1587\n",
      "Epoch 227/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 19905.6522 - val_loss: 24765.3313\n",
      "Epoch 228/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 19338.3764 - val_loss: 24697.3856\n",
      "Epoch 229/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 19625.6928 - val_loss: 24340.1307\n",
      "Epoch 230/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 19633.2602 - val_loss: 25023.6557\n",
      "Epoch 231/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19730.1644 - val_loss: 25264.7365\n",
      "Epoch 232/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 19357.5235 - val_loss: 24634.2659\n",
      "Epoch 233/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 19291.063 - 0s 132us/step - loss: 19255.7721 - val_loss: 24675.0162\n",
      "Epoch 234/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19371.4533 - val_loss: 24958.6891\n",
      "Epoch 235/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 19651.4849 - val_loss: 24582.9328\n",
      "Epoch 236/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 19514.9615 - val_loss: 24879.7898\n",
      "Epoch 237/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 19419.392 - 0s 149us/step - loss: 19339.7438 - val_loss: 24580.9821\n",
      "Epoch 238/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 19134.8693 - val_loss: 24544.3463\n",
      "Epoch 239/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 19133.7540 - val_loss: 24944.3426\n",
      "Epoch 240/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 18846.3850 - val_loss: 25048.9435\n",
      "Epoch 241/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 19296.8086 - val_loss: 27135.7045\n",
      "Epoch 242/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19640.8803 - val_loss: 24693.6152\n",
      "Epoch 243/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 18843.6773 - val_loss: 24520.6083\n",
      "Epoch 244/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 18770.4062 - val_loss: 24282.0029\n",
      "Epoch 245/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 19159.5401 - val_loss: 25968.7554\n",
      "Epoch 246/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 18850.4394 - val_loss: 25539.7223\n",
      "Epoch 247/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 19057.3632 - val_loss: 24922.2487\n",
      "Epoch 248/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 18975.7068 - val_loss: 24465.5829\n",
      "Epoch 249/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 18691.4200 - val_loss: 25698.6147\n",
      "Epoch 250/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 19891.9830 - val_loss: 24669.4699\n",
      "Epoch 251/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 18989.6488 - val_loss: 25578.8175\n",
      "Epoch 252/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 19237.7595 - val_loss: 26745.1528\n",
      "Epoch 253/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 19251.6107 - val_loss: 25558.6370\n",
      "Epoch 254/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 20144.1897 - val_loss: 24244.4944\n",
      "Epoch 255/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 18579.8562 - val_loss: 24425.5976\n",
      "Epoch 256/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18884.1877 - val_loss: 24081.9101\n",
      "Epoch 257/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 19724.0270 - val_loss: 24407.7797\n",
      "Epoch 258/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 19919.6735 - val_loss: 27014.4860\n",
      "Epoch 259/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18774.0669 - val_loss: 24754.0329\n",
      "Epoch 260/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 20328.342 - 0s 132us/step - loss: 20128.8355 - val_loss: 24685.7796\n",
      "Epoch 261/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 20264.9822 - val_loss: 24280.5279\n",
      "Epoch 262/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18843.5279 - val_loss: 24165.7417\n",
      "Epoch 263/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18567.6496 - val_loss: 24457.2938\n",
      "Epoch 264/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18279.3722 - val_loss: 24121.6250\n",
      "Epoch 265/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 18697.9577 - val_loss: 24678.3022\n",
      "Epoch 266/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18317.1640 - val_loss: 24132.6292\n",
      "Epoch 267/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 18360.8750 - val_loss: 24169.0435\n",
      "Epoch 268/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 18383.7739 - val_loss: 24279.0572\n",
      "Epoch 269/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18271.0431 - val_loss: 24636.7619\n",
      "Epoch 270/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 18582.7516 - val_loss: 24305.9572\n",
      "Epoch 271/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 18812.1168 - val_loss: 24723.8573\n",
      "Epoch 272/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 19295.6712 - val_loss: 24485.2025\n",
      "Epoch 273/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 18387.5703 - val_loss: 24215.3846\n",
      "Epoch 274/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 18098.7002 - val_loss: 24100.1550\n",
      "Epoch 275/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18994.2947 - val_loss: 23919.5076\n",
      "Epoch 276/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 19012.3362 - val_loss: 24677.2851\n",
      "Epoch 277/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18304.2663 - val_loss: 25602.7415\n",
      "Epoch 278/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 18834.0112 - val_loss: 25001.8749\n",
      "Epoch 279/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18601.1413 - val_loss: 25620.8434\n",
      "Epoch 280/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18566.9283 - val_loss: 24059.3836\n",
      "Epoch 281/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 18232.0904 - val_loss: 26829.3561\n",
      "Epoch 282/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 18067.5514 - val_loss: 25614.2971\n",
      "Epoch 283/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 20686.1730 - val_loss: 24420.7278\n",
      "Epoch 284/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18221.1245 - val_loss: 24036.7031\n",
      "Epoch 285/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18176.0288 - val_loss: 24383.4208\n",
      "Epoch 286/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 17945.7593 - val_loss: 23755.3461\n",
      "Epoch 287/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17933.6063 - val_loss: 23971.7647\n",
      "Epoch 288/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 153us/step - loss: 18542.4548 - val_loss: 23529.0553\n",
      "Epoch 289/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18216.7980 - val_loss: 23850.2551\n",
      "Epoch 290/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 17627.4328 - val_loss: 24591.7583\n",
      "Epoch 291/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 18723.3442 - val_loss: 24536.4250\n",
      "Epoch 292/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18702.3564 - val_loss: 23687.6429\n",
      "Epoch 293/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 18605.5815 - val_loss: 23680.1470\n",
      "Epoch 294/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 17583.0719 - val_loss: 24501.2053\n",
      "Epoch 295/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18568.2799 - val_loss: 24228.7064\n",
      "Epoch 296/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 17918.4107 - val_loss: 25100.1481\n",
      "Epoch 297/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18654.7540 - val_loss: 24094.1855\n",
      "Epoch 298/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 17655.9493 - val_loss: 24019.1492\n",
      "Epoch 299/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 18066.2742 - val_loss: 24434.2829\n",
      "Epoch 300/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 18669.8575 - val_loss: 23748.0770\n",
      "Epoch 301/3000\n",
      "995/995 [==============================] - 0s 108us/step - loss: 19002.0349 - val_loss: 23432.8142\n",
      "Epoch 302/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17875.0424 - val_loss: 26236.6763\n",
      "Epoch 303/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 19372.2676 - val_loss: 23391.0551\n",
      "Epoch 304/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 17835.0676 - val_loss: 23273.4560\n",
      "Epoch 305/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 18055.5735 - val_loss: 24239.2249\n",
      "Epoch 306/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 18028.9045 - val_loss: 23323.8482\n",
      "Epoch 307/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 17790.3673 - val_loss: 23246.6750\n",
      "Epoch 308/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 17334.5837 - val_loss: 23409.0222\n",
      "Epoch 309/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17487.6235 - val_loss: 24566.3845\n",
      "Epoch 310/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17211.5418 - val_loss: 24600.6960\n",
      "Epoch 311/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 17005.8154 - val_loss: 23487.1426\n",
      "Epoch 312/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17249.9844 - val_loss: 23727.2997\n",
      "Epoch 313/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 19247.1111 - val_loss: 22967.0777\n",
      "Epoch 314/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 17775.2357 - val_loss: 23119.5564\n",
      "Epoch 315/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 17524.0646 - val_loss: 23192.5734\n",
      "Epoch 316/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 17205.0270 - val_loss: 23978.8593\n",
      "Epoch 317/3000\n",
      "995/995 [==============================] - 0s 108us/step - loss: 17406.2834 - val_loss: 23195.3360\n",
      "Epoch 318/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 18261.3614 - val_loss: 23587.0293\n",
      "Epoch 319/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 19079.1376 - val_loss: 22911.0504\n",
      "Epoch 320/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 17744.1391 - val_loss: 23171.2405\n",
      "Epoch 321/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 18331.4962 - val_loss: 23334.0531\n",
      "Epoch 322/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 17273.9285 - val_loss: 23761.5176\n",
      "Epoch 323/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17728.0590 - val_loss: 23017.9780\n",
      "Epoch 324/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 17089.5052 - val_loss: 23116.8130\n",
      "Epoch 325/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17298.7224 - val_loss: 23634.5799\n",
      "Epoch 326/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 17125.4946 - val_loss: 23463.4154\n",
      "Epoch 327/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 18204.3614 - val_loss: 22834.7092\n",
      "Epoch 328/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 16867.1784 - val_loss: 24494.5362\n",
      "Epoch 329/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 17620.9077 - val_loss: 23762.8678\n",
      "Epoch 330/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 17587.0885 - val_loss: 22795.0962\n",
      "Epoch 331/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 17747.0486 - val_loss: 22719.4638\n",
      "Epoch 332/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 16690.1249 - val_loss: 22761.1021\n",
      "Epoch 333/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 17165.4861 - val_loss: 22761.5705\n",
      "Epoch 334/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 17147.5972 - val_loss: 22576.1102\n",
      "Epoch 335/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16622.8308 - val_loss: 22888.9164\n",
      "Epoch 336/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 16860.9029 - val_loss: 22886.1587\n",
      "Epoch 337/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16999.8423 - val_loss: 22481.6706\n",
      "Epoch 338/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 17094.9132 - val_loss: 23002.3186\n",
      "Epoch 339/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 17127.6347 - val_loss: 22939.3276\n",
      "Epoch 340/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 16875.6732 - val_loss: 22635.9698\n",
      "Epoch 341/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 16826.0837 - val_loss: 23185.3705\n",
      "Epoch 342/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 16497.5597 - val_loss: 23083.5323\n",
      "Epoch 343/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 16440.4219 - val_loss: 23628.8922\n",
      "Epoch 344/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 18228.1909 - val_loss: 22197.1881\n",
      "Epoch 345/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 17120.2069 - val_loss: 23271.9700\n",
      "Epoch 346/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 16246.9054 - val_loss: 22677.1044\n",
      "Epoch 347/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16520.9655 - val_loss: 22228.1324\n",
      "Epoch 348/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 17144.5736 - val_loss: 22873.0771\n",
      "Epoch 349/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 16798.6830 - val_loss: 23339.6315\n",
      "Epoch 350/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16385.7087 - val_loss: 22821.9496\n",
      "Epoch 351/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 16522.6598 - val_loss: 22377.7662\n",
      "Epoch 352/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 16425.1671 - val_loss: 23304.8062\n",
      "Epoch 353/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 16838.8485 - val_loss: 22689.5399\n",
      "Epoch 354/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16428.6380 - val_loss: 22132.6491\n",
      "Epoch 355/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 16923.4927 - val_loss: 22223.9754\n",
      "Epoch 356/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 16096.1712 - val_loss: 22356.5593\n",
      "Epoch 357/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 16408.6369 - val_loss: 25025.3505\n",
      "Epoch 358/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17802.3155 - val_loss: 22971.6193\n",
      "Epoch 359/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 17181.2008 - val_loss: 22491.3186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 17174.3765 - val_loss: 23415.6632\n",
      "Epoch 361/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17016.1139 - val_loss: 22190.0841\n",
      "Epoch 362/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 16018.7493 - val_loss: 23287.1142\n",
      "Epoch 363/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16206.2822 - val_loss: 22076.8583\n",
      "Epoch 364/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 16560.3443 - val_loss: 22839.6779\n",
      "Epoch 365/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16634.7765 - val_loss: 21932.3657\n",
      "Epoch 366/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 18579.2303 - val_loss: 22372.1056\n",
      "Epoch 367/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 17471.1171 - val_loss: 21734.8127\n",
      "Epoch 368/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 16636.7065 - val_loss: 24061.2802\n",
      "Epoch 369/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16997.2245 - val_loss: 21986.2968\n",
      "Epoch 370/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 16627.2784 - val_loss: 22068.7329\n",
      "Epoch 371/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16776.4260 - val_loss: 22705.8850\n",
      "Epoch 372/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 16867.0031 - val_loss: 21858.4981\n",
      "Epoch 373/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 15935.8119 - val_loss: 21900.6473\n",
      "Epoch 374/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16397.4723 - val_loss: 21885.0986\n",
      "Epoch 375/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 16118.7812 - val_loss: 21982.3114\n",
      "Epoch 376/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17117.9776 - val_loss: 22751.0071\n",
      "Epoch 377/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 16918.8073 - val_loss: 22454.3213\n",
      "Epoch 378/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 16157.9968 - val_loss: 21976.4294\n",
      "Epoch 379/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 15790.8550 - val_loss: 22760.1982\n",
      "Epoch 380/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16338.4556 - val_loss: 21629.7756\n",
      "Epoch 381/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 16102.0430 - val_loss: 21614.7060\n",
      "Epoch 382/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16108.7687 - val_loss: 23588.6325\n",
      "Epoch 383/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 15934.7313 - val_loss: 22300.5615\n",
      "Epoch 384/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 16503.6461 - val_loss: 21683.6506\n",
      "Epoch 385/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 16887.8085 - val_loss: 24339.2253\n",
      "Epoch 386/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 17480.3669 - val_loss: 22582.4089\n",
      "Epoch 387/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16520.0152 - val_loss: 22443.3858\n",
      "Epoch 388/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16959.9899 - val_loss: 22130.7113\n",
      "Epoch 389/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 15916.8465 - val_loss: 25414.4250\n",
      "Epoch 390/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16330.5525 - val_loss: 21606.4037\n",
      "Epoch 391/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15906.3322 - val_loss: 21773.8370\n",
      "Epoch 392/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15843.4430 - val_loss: 22025.3372\n",
      "Epoch 393/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 15917.2320 - val_loss: 22191.0424\n",
      "Epoch 394/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15598.9267 - val_loss: 21852.3098\n",
      "Epoch 395/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15645.7347 - val_loss: 21669.5398\n",
      "Epoch 396/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 15965.4178 - val_loss: 21527.9643\n",
      "Epoch 397/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 16113.783 - 0s 161us/step - loss: 16482.3314 - val_loss: 22339.0961\n",
      "Epoch 398/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15854.8474 - val_loss: 21864.6762\n",
      "Epoch 399/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15982.2413 - val_loss: 21634.1060\n",
      "Epoch 400/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 16144.2246 - val_loss: 21673.1855\n",
      "Epoch 401/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16427.9946 - val_loss: 21393.8246\n",
      "Epoch 402/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 15941.2091 - val_loss: 22052.3662\n",
      "Epoch 403/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 17665.6709 - val_loss: 24327.2075\n",
      "Epoch 404/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 16289.6929 - val_loss: 21562.0746\n",
      "Epoch 405/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 15762.5547 - val_loss: 21866.7432\n",
      "Epoch 406/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 15635.3942 - val_loss: 21498.0395\n",
      "Epoch 407/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15559.3509 - val_loss: 23723.8556\n",
      "Epoch 408/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16337.8091 - val_loss: 21494.9215\n",
      "Epoch 409/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 16550.4024 - val_loss: 22915.5286\n",
      "Epoch 410/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 15866.3037 - val_loss: 21559.5759\n",
      "Epoch 411/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 15780.9466 - val_loss: 21759.9851\n",
      "Epoch 412/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15247.2818 - val_loss: 21324.2234\n",
      "Epoch 413/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15617.7857 - val_loss: 21383.1400\n",
      "Epoch 414/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15056.9412 - val_loss: 21726.6425\n",
      "Epoch 415/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 15943.9802 - val_loss: 23798.2410\n",
      "Epoch 416/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 15210.6734 - val_loss: 22366.5961\n",
      "Epoch 417/3000\n",
      "995/995 [==============================] - 0s 177us/step - loss: 15388.8141 - val_loss: 20934.7307\n",
      "Epoch 418/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15124.2738 - val_loss: 22109.3770\n",
      "Epoch 419/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15910.7918 - val_loss: 21039.3183\n",
      "Epoch 420/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15553.9256 - val_loss: 21217.8104\n",
      "Epoch 421/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15192.9430 - val_loss: 21197.8987\n",
      "Epoch 422/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16424.8407 - val_loss: 24337.2322\n",
      "Epoch 423/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16857.4824 - val_loss: 21749.4518\n",
      "Epoch 424/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15874.6044 - val_loss: 22384.3018\n",
      "Epoch 425/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15888.9775 - val_loss: 21839.7662\n",
      "Epoch 426/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 15836.7136 - val_loss: 22813.1986\n",
      "Epoch 427/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15208.3977 - val_loss: 21474.2909\n",
      "Epoch 428/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15956.3807 - val_loss: 22290.1864\n",
      "Epoch 429/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16212.6513 - val_loss: 21133.1090\n",
      "Epoch 430/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 17431.5264 - val_loss: 21576.1386\n",
      "Epoch 431/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 141us/step - loss: 15457.3474 - val_loss: 21854.9535\n",
      "Epoch 432/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 15751.5618 - val_loss: 21300.2531\n",
      "Epoch 433/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 15813.4216 - val_loss: 21055.0708\n",
      "Epoch 434/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15091.2290 - val_loss: 21232.8999\n",
      "Epoch 435/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15761.7542 - val_loss: 21461.4560\n",
      "Epoch 436/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 16808.7777 - val_loss: 21148.5613\n",
      "Epoch 437/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 15308.4997 - val_loss: 21958.6476\n",
      "Epoch 438/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 15073.4348 - val_loss: 21721.9276\n",
      "Epoch 439/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 15289.0045 - val_loss: 21505.9247\n",
      "Epoch 440/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15259.8750 - val_loss: 20992.6834\n",
      "Epoch 441/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 15069.0282 - val_loss: 21285.2486\n",
      "Epoch 442/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15892.0995 - val_loss: 22085.4147\n",
      "Epoch 443/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 16026.4681 - val_loss: 21169.4428\n",
      "Epoch 444/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 14618.3156 - val_loss: 21027.3300\n",
      "Epoch 445/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16518.4381 - val_loss: 20958.0163\n",
      "Epoch 446/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14884.0242 - val_loss: 20929.4133\n",
      "Epoch 447/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 15964.7196 - val_loss: 21187.5344\n",
      "Epoch 448/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14651.8449 - val_loss: 22463.3719\n",
      "Epoch 449/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15357.3199 - val_loss: 21977.6860\n",
      "Epoch 450/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14886.4517 - val_loss: 21231.7878\n",
      "Epoch 451/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15813.6466 - val_loss: 20668.4538\n",
      "Epoch 452/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14841.2300 - val_loss: 22015.3224\n",
      "Epoch 453/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14548.6929 - val_loss: 20886.0241\n",
      "Epoch 454/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15038.9686 - val_loss: 21039.8884\n",
      "Epoch 455/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 15121.1727 - val_loss: 21409.4206\n",
      "Epoch 456/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16832.8223 - val_loss: 21337.4271\n",
      "Epoch 457/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 14880.2106 - val_loss: 23269.5018\n",
      "Epoch 458/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16637.3293 - val_loss: 22071.0824\n",
      "Epoch 459/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16013.9565 - val_loss: 20696.3503\n",
      "Epoch 460/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14672.3945 - val_loss: 21791.7506\n",
      "Epoch 461/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14898.6435 - val_loss: 21169.8063\n",
      "Epoch 462/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 14885.2306 - val_loss: 20720.5688\n",
      "Epoch 463/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15421.3776 - val_loss: 21379.5332\n",
      "Epoch 464/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15364.2169 - val_loss: 21531.9675\n",
      "Epoch 465/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14346.1595 - val_loss: 21292.9863\n",
      "Epoch 466/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15010.3538 - val_loss: 21590.2366\n",
      "Epoch 467/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14554.1370 - val_loss: 22533.9623\n",
      "Epoch 468/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 15658.3501 - val_loss: 21404.0667\n",
      "Epoch 469/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15048.8086 - val_loss: 21692.7442\n",
      "Epoch 470/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14887.5404 - val_loss: 21108.2871\n",
      "Epoch 471/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14935.6307 - val_loss: 24211.9376\n",
      "Epoch 472/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 15720.4910 - val_loss: 21598.1624\n",
      "Epoch 473/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 16247.5154 - val_loss: 21052.0386\n",
      "Epoch 474/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14375.6689 - val_loss: 20806.6735\n",
      "Epoch 475/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 14389.4437 - val_loss: 22327.1877\n",
      "Epoch 476/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 15661.5496 - val_loss: 21045.3666\n",
      "Epoch 477/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 14593.6488 - val_loss: 21078.0875\n",
      "Epoch 478/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 16539.5136 - val_loss: 20557.1627\n",
      "Epoch 479/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16112.2868 - val_loss: 21155.7929\n",
      "Epoch 480/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15250.9550 - val_loss: 21218.4963\n",
      "Epoch 481/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14869.7093 - val_loss: 21160.0072\n",
      "Epoch 482/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14690.9747 - val_loss: 21484.8320\n",
      "Epoch 483/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 14518.0727 - val_loss: 21969.8428\n",
      "Epoch 484/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14738.6151 - val_loss: 20743.2880\n",
      "Epoch 485/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14639.8713 - val_loss: 21938.6260\n",
      "Epoch 486/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 14973.008 - 0s 141us/step - loss: 14848.8887 - val_loss: 20755.2022\n",
      "Epoch 487/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 14449.6763 - val_loss: 20588.6831\n",
      "Epoch 488/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14328.3700 - val_loss: 21650.3776\n",
      "Epoch 489/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14875.5989 - val_loss: 21496.2319\n",
      "Epoch 490/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 15463.6645 - val_loss: 23290.4217\n",
      "Epoch 491/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14613.5972 - val_loss: 21453.4350\n",
      "Epoch 492/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 14363.6040 - val_loss: 21422.4462\n",
      "Epoch 493/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14470.3105 - val_loss: 21219.6608\n",
      "Epoch 494/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14713.8431 - val_loss: 20782.5213\n",
      "Epoch 495/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14026.2594 - val_loss: 20828.4325\n",
      "Epoch 496/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14229.9110 - val_loss: 20648.5921\n",
      "Epoch 497/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14650.9019 - val_loss: 21069.4642\n",
      "Epoch 498/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14091.2125 - val_loss: 21046.1614\n",
      "Epoch 499/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14691.8705 - val_loss: 20736.0866\n",
      "Epoch 500/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 14465.9648 - val_loss: 21072.2921\n",
      "Epoch 501/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 14276.9078 - val_loss: 20757.1352\n",
      "Epoch 502/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13940.0147 - val_loss: 21115.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14517.1398 - val_loss: 20812.1226\n",
      "Epoch 504/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14367.3236 - val_loss: 20891.9090\n",
      "Epoch 505/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 14797.2391 - val_loss: 21097.9664\n",
      "Epoch 506/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 14306.7277 - val_loss: 22715.7174\n",
      "Epoch 507/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 14412.3046 - val_loss: 20800.8950\n",
      "Epoch 508/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 15305.6972 - val_loss: 21330.2853\n",
      "Epoch 509/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14715.2841 - val_loss: 22701.4536\n",
      "Epoch 510/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15016.1353 - val_loss: 24333.9588\n",
      "Epoch 511/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 15803.1642 - val_loss: 20863.1642\n",
      "Epoch 512/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 13875.6761 - val_loss: 22290.2397\n",
      "Epoch 513/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14507.1785 - val_loss: 20937.2415\n",
      "Epoch 514/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 13862.4471 - val_loss: 23495.1757\n",
      "Epoch 515/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 15105.5191 - val_loss: 22678.0240\n",
      "Epoch 516/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15743.8334 - val_loss: 20821.2351\n",
      "Epoch 517/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 15267.3579 - val_loss: 20585.2979\n",
      "Epoch 518/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14852.1212 - val_loss: 20315.5789\n",
      "Epoch 519/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15608.6128 - val_loss: 23549.8324\n",
      "Epoch 520/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 14812.3880 - val_loss: 20566.9449\n",
      "Epoch 521/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14010.6728 - val_loss: 20386.5029\n",
      "Epoch 522/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14953.4660 - val_loss: 20576.1168\n",
      "Epoch 523/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14026.9140 - val_loss: 20580.9869\n",
      "Epoch 524/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14391.5937 - val_loss: 20268.3828\n",
      "Epoch 525/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 14545.2585 - val_loss: 20833.3936\n",
      "Epoch 526/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13803.1179 - val_loss: 20962.3381\n",
      "Epoch 527/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13705.0033 - val_loss: 21460.7146\n",
      "Epoch 528/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13748.3183 - val_loss: 20527.0772\n",
      "Epoch 529/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 14182.7095 - val_loss: 21338.5498\n",
      "Epoch 530/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14004.9296 - val_loss: 20531.8904\n",
      "Epoch 531/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13945.0992 - val_loss: 20751.6062\n",
      "Epoch 532/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13775.1544 - val_loss: 20621.7678\n",
      "Epoch 533/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13739.4435 - val_loss: 21326.9224\n",
      "Epoch 534/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13664.1765 - val_loss: 20440.0795\n",
      "Epoch 535/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 13834.8775 - val_loss: 20746.4689\n",
      "Epoch 536/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14100.1223 - val_loss: 21487.4021\n",
      "Epoch 537/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13548.8603 - val_loss: 21563.8089\n",
      "Epoch 538/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 13776.5248 - val_loss: 20815.1372\n",
      "Epoch 539/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14047.7864 - val_loss: 20078.2872\n",
      "Epoch 540/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14341.6575 - val_loss: 22093.3471\n",
      "Epoch 541/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 16284.4726 - val_loss: 20967.6482\n",
      "Epoch 542/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 13941.7924 - val_loss: 20527.7315\n",
      "Epoch 543/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13432.3615 - val_loss: 20203.3520\n",
      "Epoch 544/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14005.6158 - val_loss: 20956.1136\n",
      "Epoch 545/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 15083.8593 - val_loss: 20303.5967\n",
      "Epoch 546/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13968.8888 - val_loss: 20067.1872\n",
      "Epoch 547/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14563.7397 - val_loss: 23600.6632\n",
      "Epoch 548/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13984.9080 - val_loss: 21034.3081\n",
      "Epoch 549/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 14540.3795 - val_loss: 23087.3834\n",
      "Epoch 550/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 14156.3954 - val_loss: 22089.9091\n",
      "Epoch 551/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14186.7199 - val_loss: 20720.8146\n",
      "Epoch 552/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13506.8857 - val_loss: 21988.1421\n",
      "Epoch 553/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13328.1463 - val_loss: 23152.7108\n",
      "Epoch 554/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 15042.2179 - val_loss: 21639.2859\n",
      "Epoch 555/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15283.7865 - val_loss: 20918.5030\n",
      "Epoch 556/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14256.7842 - val_loss: 22214.8322\n",
      "Epoch 557/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 17656.7235 - val_loss: 20354.7998\n",
      "Epoch 558/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 13371.3989 - val_loss: 21034.7079\n",
      "Epoch 559/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14138.2746 - val_loss: 21683.2193\n",
      "Epoch 560/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 14507.0862 - val_loss: 25402.3955\n",
      "Epoch 561/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 14820.4244 - val_loss: 20047.3254\n",
      "Epoch 562/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15259.6613 - val_loss: 22829.5057\n",
      "Epoch 563/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 14215.7870 - val_loss: 20255.9693\n",
      "Epoch 564/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 14070.1682 - val_loss: 21693.4660\n",
      "Epoch 565/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 13889.3401 - val_loss: 20330.4533\n",
      "Epoch 566/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 13021.9704 - val_loss: 20585.0641\n",
      "Epoch 567/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14228.1626 - val_loss: 21179.0671\n",
      "Epoch 568/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 14573.4681 - val_loss: 20720.3568\n",
      "Epoch 569/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13356.1376 - val_loss: 20083.8655\n",
      "Epoch 570/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12978.4432 - val_loss: 20403.5814\n",
      "Epoch 571/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13006.3945 - val_loss: 20249.2131\n",
      "Epoch 572/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13430.2166 - val_loss: 20671.9161\n",
      "Epoch 573/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13516.4808 - val_loss: 20270.8267\n",
      "Epoch 574/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13031.0104 - val_loss: 20347.8366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 14193.1255 - val_loss: 20518.1944\n",
      "Epoch 576/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13676.3922 - val_loss: 20514.8438\n",
      "Epoch 577/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 15136.7119 - val_loss: 20020.7703\n",
      "Epoch 578/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 14048.1396 - val_loss: 20149.1701\n",
      "Epoch 579/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 13741.4855 - val_loss: 19842.5872\n",
      "Epoch 580/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13171.3941 - val_loss: 20136.4162\n",
      "Epoch 581/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12924.0681 - val_loss: 19535.4741\n",
      "Epoch 582/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13924.6695 - val_loss: 19721.6267\n",
      "Epoch 583/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13067.7203 - val_loss: 20994.7107\n",
      "Epoch 584/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13922.9984 - val_loss: 25004.8577\n",
      "Epoch 585/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 15393.0777 - val_loss: 20184.5436\n",
      "Epoch 586/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 13412.7253 - val_loss: 20626.8973\n",
      "Epoch 587/3000\n",
      "995/995 [==============================] - 0s 181us/step - loss: 13542.8963 - val_loss: 20610.8962\n",
      "Epoch 588/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 13504.8084 - val_loss: 19967.9572\n",
      "Epoch 589/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12859.5195 - val_loss: 20355.7624\n",
      "Epoch 590/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13352.0620 - val_loss: 20163.6944\n",
      "Epoch 591/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 13044.1112 - val_loss: 19974.4371\n",
      "Epoch 592/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13473.5159 - val_loss: 20170.5363\n",
      "Epoch 593/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 13923.2970 - val_loss: 22384.8988\n",
      "Epoch 594/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 13922.1117 - val_loss: 19822.9362\n",
      "Epoch 595/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13121.0264 - val_loss: 20348.3008\n",
      "Epoch 596/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 14169.8268 - val_loss: 19854.4933\n",
      "Epoch 597/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13245.0904 - val_loss: 20123.0531\n",
      "Epoch 598/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12865.0945 - val_loss: 19743.4931\n",
      "Epoch 599/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 12584.2198 - val_loss: 27638.0906\n",
      "Epoch 600/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 16633.0755 - val_loss: 20076.6526\n",
      "Epoch 601/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 13519.3592 - val_loss: 20019.3241\n",
      "Epoch 602/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13205.2339 - val_loss: 19714.4365\n",
      "Epoch 603/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14163.3355 - val_loss: 20848.2521\n",
      "Epoch 604/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13054.6495 - val_loss: 20852.1960\n",
      "Epoch 605/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 14114.7711 - val_loss: 19823.2175\n",
      "Epoch 606/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12842.8510 - val_loss: 20059.9951\n",
      "Epoch 607/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13119.6397 - val_loss: 21444.7458\n",
      "Epoch 608/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14349.8407 - val_loss: 24090.1200\n",
      "Epoch 609/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13288.9302 - val_loss: 21202.4031\n",
      "Epoch 610/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13005.6352 - val_loss: 20876.1019\n",
      "Epoch 611/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 13656.7693 - val_loss: 19991.7404\n",
      "Epoch 612/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12995.7670 - val_loss: 20246.7592\n",
      "Epoch 613/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13004.8687 - val_loss: 19655.9978\n",
      "Epoch 614/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13049.6176 - val_loss: 19919.3735\n",
      "Epoch 615/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13018.2657 - val_loss: 20166.9444\n",
      "Epoch 616/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13021.9803 - val_loss: 20634.9973\n",
      "Epoch 617/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13219.5157 - val_loss: 19576.7575\n",
      "Epoch 618/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12866.9889 - val_loss: 20645.0143\n",
      "Epoch 619/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 14086.9440 - val_loss: 20001.6151\n",
      "Epoch 620/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12977.9364 - val_loss: 20537.7055\n",
      "Epoch 621/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 13385.2503 - val_loss: 20177.7090\n",
      "Epoch 622/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12589.7729 - val_loss: 19808.5343\n",
      "Epoch 623/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13158.8752 - val_loss: 20345.2407\n",
      "Epoch 624/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12807.1344 - val_loss: 19736.7448\n",
      "Epoch 625/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 13283.1618 - val_loss: 20822.7811\n",
      "Epoch 626/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 15210.6523 - val_loss: 20513.6709\n",
      "Epoch 627/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13317.9072 - val_loss: 22068.4071\n",
      "Epoch 628/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13555.1460 - val_loss: 19496.4012\n",
      "Epoch 629/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 13029.6325 - val_loss: 20600.6590\n",
      "Epoch 630/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 13255.1841 - val_loss: 19948.5830\n",
      "Epoch 631/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 12594.1878 - val_loss: 19615.2513\n",
      "Epoch 632/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 12807.7827 - val_loss: 21951.8950\n",
      "Epoch 633/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 13134.7089 - val_loss: 19609.2781\n",
      "Epoch 634/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 12138.4019 - val_loss: 19677.5058\n",
      "Epoch 635/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12781.7520 - val_loss: 19864.4359\n",
      "Epoch 636/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 12210.3958 - val_loss: 19627.5669\n",
      "Epoch 637/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 14826.6581 - val_loss: 20058.2842\n",
      "Epoch 638/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13749.7364 - val_loss: 20161.8110\n",
      "Epoch 639/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 13180.7299 - val_loss: 19727.1661\n",
      "Epoch 640/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12878.8789 - val_loss: 19659.4054\n",
      "Epoch 641/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12936.3537 - val_loss: 19007.9621\n",
      "Epoch 642/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13181.5346 - val_loss: 19327.5362\n",
      "Epoch 643/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12817.0513 - val_loss: 19240.1580\n",
      "Epoch 644/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12955.6932 - val_loss: 19227.4546\n",
      "Epoch 645/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14600.7175 - val_loss: 19954.3496\n",
      "Epoch 646/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14137.6394 - val_loss: 19416.5688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 647/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12321.4429 - val_loss: 20383.3181\n",
      "Epoch 648/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12570.5704 - val_loss: 19330.0592\n",
      "Epoch 649/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13571.3336 - val_loss: 19593.9162\n",
      "Epoch 650/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13249.0177 - val_loss: 22070.8613\n",
      "Epoch 651/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 13888.6633 - val_loss: 19317.4169\n",
      "Epoch 652/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 12907.2772 - val_loss: 19304.7992\n",
      "Epoch 653/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12518.0540 - val_loss: 19596.8251\n",
      "Epoch 654/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 13221.8822 - val_loss: 20972.5498\n",
      "Epoch 655/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13140.5507 - val_loss: 19906.9260\n",
      "Epoch 656/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12523.4770 - val_loss: 20102.7560\n",
      "Epoch 657/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12419.5234 - val_loss: 19592.3314\n",
      "Epoch 658/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13822.6834 - val_loss: 20267.8444\n",
      "Epoch 659/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12479.8993 - val_loss: 19395.4245\n",
      "Epoch 660/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13087.2419 - val_loss: 19456.9713\n",
      "Epoch 661/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 13440.0428 - val_loss: 22287.2411\n",
      "Epoch 662/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13413.1833 - val_loss: 19386.7895\n",
      "Epoch 663/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12236.0701 - val_loss: 19735.5925\n",
      "Epoch 664/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12326.2521 - val_loss: 21145.1602\n",
      "Epoch 665/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 14769.6011 - val_loss: 19189.2054\n",
      "Epoch 666/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12057.8163 - val_loss: 19842.8569\n",
      "Epoch 667/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 13280.4140 - val_loss: 19549.4685\n",
      "Epoch 668/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12311.3539 - val_loss: 19208.9095\n",
      "Epoch 669/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12462.1525 - val_loss: 20447.0879\n",
      "Epoch 670/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13425.6456 - val_loss: 19090.7147\n",
      "Epoch 671/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 12647.7609 - val_loss: 20734.1444\n",
      "Epoch 672/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12743.8622 - val_loss: 20484.9650\n",
      "Epoch 673/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12840.1812 - val_loss: 19242.7035\n",
      "Epoch 674/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13634.8393 - val_loss: 19277.5609\n",
      "Epoch 675/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12836.6495 - val_loss: 20229.2399\n",
      "Epoch 676/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13110.5814 - val_loss: 19138.9563\n",
      "Epoch 677/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12496.7813 - val_loss: 19859.5247\n",
      "Epoch 678/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 14769.8720 - val_loss: 19524.1657\n",
      "Epoch 679/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12967.2408 - val_loss: 19075.0040\n",
      "Epoch 680/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11936.0603 - val_loss: 19774.2305\n",
      "Epoch 681/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12015.3665 - val_loss: 19392.1646\n",
      "Epoch 682/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11774.3406 - val_loss: 19970.8464\n",
      "Epoch 683/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 14583.3160 - val_loss: 19804.8372\n",
      "Epoch 684/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12849.1790 - val_loss: 19801.5379\n",
      "Epoch 685/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12719.3271 - val_loss: 19514.1429\n",
      "Epoch 686/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12548.4372 - val_loss: 20093.3393\n",
      "Epoch 687/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13129.5964 - val_loss: 18972.9482\n",
      "Epoch 688/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 14334.7519 - val_loss: 23550.3872\n",
      "Epoch 689/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 14456.7146 - val_loss: 19475.6370\n",
      "Epoch 690/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11905.7655 - val_loss: 19785.2530\n",
      "Epoch 691/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12868.8185 - val_loss: 21116.5478\n",
      "Epoch 692/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 12687.2809 - val_loss: 21075.8208\n",
      "Epoch 693/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14584.6904 - val_loss: 19378.3224\n",
      "Epoch 694/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12298.6781 - val_loss: 18867.7628\n",
      "Epoch 695/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13647.1422 - val_loss: 21578.5126\n",
      "Epoch 696/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 14128.1895 - val_loss: 19530.2989\n",
      "Epoch 697/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 15546.9974 - val_loss: 19871.9948\n",
      "Epoch 698/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12576.2606 - val_loss: 20889.6831\n",
      "Epoch 699/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 13656.9481 - val_loss: 22024.4472\n",
      "Epoch 700/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14387.5845 - val_loss: 20944.0955\n",
      "Epoch 701/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11918.1552 - val_loss: 19451.8782\n",
      "Epoch 702/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11861.1811 - val_loss: 19176.8867\n",
      "Epoch 703/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 12452.0387 - val_loss: 19388.5350\n",
      "Epoch 704/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12577.8912 - val_loss: 19228.4193\n",
      "Epoch 705/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12122.2366 - val_loss: 19859.2701\n",
      "Epoch 706/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 11694.7554 - val_loss: 19625.7670\n",
      "Epoch 707/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12382.9683 - val_loss: 19211.0735\n",
      "Epoch 708/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11776.0868 - val_loss: 19224.6248\n",
      "Epoch 709/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12568.4264 - val_loss: 19096.1931\n",
      "Epoch 710/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12669.1780 - val_loss: 19473.8820\n",
      "Epoch 711/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11705.4865 - val_loss: 19266.3504\n",
      "Epoch 712/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12463.3783 - val_loss: 18973.0899\n",
      "Epoch 713/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12276.9396 - val_loss: 18876.2199\n",
      "Epoch 714/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 11966.9081 - val_loss: 19374.7389\n",
      "Epoch 715/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11665.8285 - val_loss: 18978.2493\n",
      "Epoch 716/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12421.2323 - val_loss: 19057.2226\n",
      "Epoch 717/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12109.8531 - val_loss: 19742.4375\n",
      "Epoch 718/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12732.8427 - val_loss: 18918.0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12046.4404 - val_loss: 21853.9624\n",
      "Epoch 720/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12458.7582 - val_loss: 19272.7257\n",
      "Epoch 721/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12655.2988 - val_loss: 20891.6253\n",
      "Epoch 722/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 14368.3765 - val_loss: 20221.1258\n",
      "Epoch 723/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13104.0788 - val_loss: 19495.9695\n",
      "Epoch 724/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11961.7551 - val_loss: 19467.9649\n",
      "Epoch 725/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12599.4827 - val_loss: 19444.2092\n",
      "Epoch 726/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11934.8211 - val_loss: 19313.0950\n",
      "Epoch 727/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12785.2682 - val_loss: 19567.9319\n",
      "Epoch 728/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11910.2000 - val_loss: 19746.4450\n",
      "Epoch 729/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11997.8507 - val_loss: 19153.7516\n",
      "Epoch 730/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11892.4315 - val_loss: 19648.5381\n",
      "Epoch 731/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12142.2779 - val_loss: 18963.1372\n",
      "Epoch 732/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11612.3312 - val_loss: 19627.9870\n",
      "Epoch 733/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11512.0869 - val_loss: 19339.6988\n",
      "Epoch 734/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 13214.0193 - val_loss: 18870.7604\n",
      "Epoch 735/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 13088.8005 - val_loss: 19906.0553\n",
      "Epoch 736/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13605.6693 - val_loss: 19773.4639\n",
      "Epoch 737/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 13011.5956 - val_loss: 21353.7776\n",
      "Epoch 738/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 12821.2143 - val_loss: 19402.2702\n",
      "Epoch 739/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11433.0186 - val_loss: 19779.3522\n",
      "Epoch 740/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12001.0924 - val_loss: 19095.0965\n",
      "Epoch 741/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11771.8798 - val_loss: 19201.9415\n",
      "Epoch 742/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11438.9554 - val_loss: 19800.2578\n",
      "Epoch 743/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11784.1276 - val_loss: 19773.5973\n",
      "Epoch 744/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 12404.9086 - val_loss: 19685.9403\n",
      "Epoch 745/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 11850.6070 - val_loss: 19193.1466\n",
      "Epoch 746/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11569.8758 - val_loss: 19947.9827\n",
      "Epoch 747/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12414.1987 - val_loss: 18974.2071\n",
      "Epoch 748/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12392.3230 - val_loss: 20073.3560\n",
      "Epoch 749/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11807.5085 - val_loss: 19145.7528\n",
      "Epoch 750/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11871.8550 - val_loss: 19711.9030\n",
      "Epoch 751/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11795.1632 - val_loss: 18987.4765\n",
      "Epoch 752/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11708.0374 - val_loss: 19659.2677\n",
      "Epoch 753/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12188.0164 - val_loss: 22633.3434\n",
      "Epoch 754/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14505.0081 - val_loss: 20068.0254\n",
      "Epoch 755/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11774.2332 - val_loss: 19758.2514\n",
      "Epoch 756/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11659.7082 - val_loss: 19865.3083\n",
      "Epoch 757/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11328.0134 - val_loss: 19018.0432\n",
      "Epoch 758/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12071.7800 - val_loss: 19404.4601\n",
      "Epoch 759/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11664.1279 - val_loss: 19413.2378\n",
      "Epoch 760/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12048.9385 - val_loss: 20055.2838\n",
      "Epoch 761/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12497.5825 - val_loss: 20386.5733\n",
      "Epoch 762/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12892.4516 - val_loss: 19811.5722\n",
      "Epoch 763/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11872.8830 - val_loss: 19798.1117\n",
      "Epoch 764/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11975.0953 - val_loss: 20047.6698\n",
      "Epoch 765/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13280.4665 - val_loss: 19169.6312\n",
      "Epoch 766/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12518.3022 - val_loss: 18834.5506\n",
      "Epoch 767/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 14446.7892 - val_loss: 19952.8746\n",
      "Epoch 768/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11971.8999 - val_loss: 19131.3937\n",
      "Epoch 769/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11461.3683 - val_loss: 19467.5935\n",
      "Epoch 770/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12344.5890 - val_loss: 20995.4073\n",
      "Epoch 771/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11948.4863 - val_loss: 19099.9832\n",
      "Epoch 772/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11468.7552 - val_loss: 19260.4835\n",
      "Epoch 773/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12007.0281 - val_loss: 18683.2982\n",
      "Epoch 774/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12636.9307 - val_loss: 19931.6027\n",
      "Epoch 775/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 11508.9142 - val_loss: 18952.2288\n",
      "Epoch 776/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12417.0005 - val_loss: 19496.3662\n",
      "Epoch 777/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11849.7080 - val_loss: 20479.3554\n",
      "Epoch 778/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11241.1714 - val_loss: 19145.2330\n",
      "Epoch 779/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11993.7496 - val_loss: 19432.1008\n",
      "Epoch 780/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11607.7202 - val_loss: 18974.3791\n",
      "Epoch 781/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11315.8596 - val_loss: 19629.9294\n",
      "Epoch 782/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12231.2664 - val_loss: 18905.8109\n",
      "Epoch 783/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 14052.7320 - val_loss: 18974.4614\n",
      "Epoch 784/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11565.0416 - val_loss: 19555.3209\n",
      "Epoch 785/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 12301.1893 - val_loss: 19198.7522\n",
      "Epoch 786/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 12591.5425 - val_loss: 19189.4782\n",
      "Epoch 787/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11443.1470 - val_loss: 20549.0266\n",
      "Epoch 788/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11552.1152 - val_loss: 19323.0820\n",
      "Epoch 789/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 13337.6146 - val_loss: 20570.4864\n",
      "Epoch 790/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11390.3496 - val_loss: 19072.9989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12454.9882 - val_loss: 19233.8187\n",
      "Epoch 792/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11742.9950 - val_loss: 19069.4329\n",
      "Epoch 793/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12068.4944 - val_loss: 18693.6497\n",
      "Epoch 794/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10837.8673 - val_loss: 19121.0071\n",
      "Epoch 795/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11273.2063 - val_loss: 19134.3695\n",
      "Epoch 796/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12179.1095 - val_loss: 23494.1919\n",
      "Epoch 797/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 13052.5342 - val_loss: 20195.6717\n",
      "Epoch 798/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11704.1141 - val_loss: 18820.2686\n",
      "Epoch 799/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10951.3573 - val_loss: 18808.5995\n",
      "Epoch 800/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12540.7219 - val_loss: 21040.4001\n",
      "Epoch 801/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11943.7071 - val_loss: 20399.2113\n",
      "Epoch 802/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 12912.3429 - val_loss: 19481.7779\n",
      "Epoch 803/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11186.1807 - val_loss: 19769.1441\n",
      "Epoch 804/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11530.3792 - val_loss: 20307.8855\n",
      "Epoch 805/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12034.5038 - val_loss: 20473.9775\n",
      "Epoch 806/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12081.8271 - val_loss: 18857.2801\n",
      "Epoch 807/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11331.9502 - val_loss: 18866.9271\n",
      "Epoch 808/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11833.5696 - val_loss: 19213.2771\n",
      "Epoch 809/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12389.9848 - val_loss: 20357.9136\n",
      "Epoch 810/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12209.5969 - val_loss: 18743.2450\n",
      "Epoch 811/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10809.3941 - val_loss: 18936.4693\n",
      "Epoch 812/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11899.7950 - val_loss: 19656.0064\n",
      "Epoch 813/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 11216.2599 - val_loss: 19146.3954\n",
      "Epoch 814/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11062.5297 - val_loss: 19739.7261\n",
      "Epoch 815/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11012.6949 - val_loss: 18617.6830\n",
      "Epoch 816/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10974.2706 - val_loss: 19003.0249\n",
      "Epoch 817/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11288.9412 - val_loss: 19144.5659\n",
      "Epoch 818/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 11220.2990 - val_loss: 20562.9367\n",
      "Epoch 819/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12098.7315 - val_loss: 18895.2718\n",
      "Epoch 820/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11277.2695 - val_loss: 19552.5494\n",
      "Epoch 821/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11311.2990 - val_loss: 21676.0456\n",
      "Epoch 822/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 13201.3305 - val_loss: 19402.5453\n",
      "Epoch 823/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11504.2936 - val_loss: 19060.2305\n",
      "Epoch 824/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11501.3879 - val_loss: 19448.6142\n",
      "Epoch 825/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11386.2755 - val_loss: 19342.4912\n",
      "Epoch 826/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10796.8424 - val_loss: 18717.5460\n",
      "Epoch 827/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11530.2826 - val_loss: 19525.3797\n",
      "Epoch 828/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11225.2975 - val_loss: 19165.2182\n",
      "Epoch 829/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11403.7499 - val_loss: 19110.8164\n",
      "Epoch 830/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11180.4867 - val_loss: 18758.4000\n",
      "Epoch 831/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11019.3108 - val_loss: 19156.1604\n",
      "Epoch 832/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11828.4767 - val_loss: 19225.2142\n",
      "Epoch 833/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11601.2102 - val_loss: 19444.6113\n",
      "Epoch 834/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11474.0681 - val_loss: 19562.4555\n",
      "Epoch 835/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11548.8600 - val_loss: 18925.2326\n",
      "Epoch 836/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11338.9365 - val_loss: 19814.1953\n",
      "Epoch 837/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11506.9508 - val_loss: 20286.3746\n",
      "Epoch 838/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11799.0203 - val_loss: 18757.6804\n",
      "Epoch 839/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10804.3842 - val_loss: 19458.5885\n",
      "Epoch 840/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10884.7524 - val_loss: 19590.5923\n",
      "Epoch 841/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11029.2020 - val_loss: 21286.4640\n",
      "Epoch 842/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12691.3738 - val_loss: 19283.6763\n",
      "Epoch 843/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10833.1384 - val_loss: 19336.1996\n",
      "Epoch 844/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11177.5474 - val_loss: 19411.9442\n",
      "Epoch 845/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11418.5878 - val_loss: 19131.1666\n",
      "Epoch 846/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11156.7041 - val_loss: 18810.8923\n",
      "Epoch 847/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10576.7532 - val_loss: 18844.8635\n",
      "Epoch 848/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10664.5678 - val_loss: 19022.8801\n",
      "Epoch 849/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10868.2419 - val_loss: 19337.2193\n",
      "Epoch 850/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11217.1627 - val_loss: 22815.3938\n",
      "Epoch 851/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12157.1003 - val_loss: 19091.4226\n",
      "Epoch 852/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11422.0135 - val_loss: 20130.5069\n",
      "Epoch 853/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11207.8791 - val_loss: 19443.4469\n",
      "Epoch 854/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10784.7700 - val_loss: 19238.7655\n",
      "Epoch 855/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11041.8910 - val_loss: 19410.0511\n",
      "Epoch 856/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11263.1464 - val_loss: 19704.7716\n",
      "Epoch 857/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11179.4099 - val_loss: 18901.6762\n",
      "Epoch 858/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11319.0429 - val_loss: 20271.5396\n",
      "Epoch 859/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12470.1501 - val_loss: 19484.2223\n",
      "Epoch 860/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11840.2538 - val_loss: 20223.8605\n",
      "Epoch 861/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11241.1383 - val_loss: 19468.1862\n",
      "Epoch 862/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11816.5270 - val_loss: 19260.2244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 12012.3333 - val_loss: 19030.9193\n",
      "Epoch 864/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11366.3794 - val_loss: 19462.5097\n",
      "Epoch 865/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12119.7139 - val_loss: 19304.8726\n",
      "Epoch 866/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10809.8982 - val_loss: 19328.2348\n",
      "Epoch 867/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11120.6515 - val_loss: 19629.9317\n",
      "Epoch 868/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11255.2608 - val_loss: 18973.9866\n",
      "Epoch 869/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10744.0798 - val_loss: 18683.2137\n",
      "Epoch 870/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10671.8249 - val_loss: 19441.2161\n",
      "Epoch 871/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11217.4894 - val_loss: 19236.9403\n",
      "Epoch 872/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10543.0873 - val_loss: 19296.6294\n",
      "Epoch 873/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10596.3601 - val_loss: 19252.3047\n",
      "Epoch 874/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10434.4561 - val_loss: 19193.6298\n",
      "Epoch 875/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10986.6367 - val_loss: 20670.0882\n",
      "Epoch 876/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11410.3378 - val_loss: 19836.6244\n",
      "Epoch 877/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10953.7124 - val_loss: 19594.8634\n",
      "Epoch 878/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10795.3525 - val_loss: 18932.4021\n",
      "Epoch 879/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10460.2337 - val_loss: 19631.7805\n",
      "Epoch 880/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11289.3750 - val_loss: 19344.8584\n",
      "Epoch 881/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10858.5069 - val_loss: 19342.3644\n",
      "Epoch 882/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11689.2314 - val_loss: 21872.6916\n",
      "Epoch 883/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11835.0824 - val_loss: 21976.1977\n",
      "Epoch 884/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 11715.0800 - val_loss: 20988.1674\n",
      "Epoch 885/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 11016.8129 - val_loss: 20625.2250\n",
      "Epoch 886/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10898.2174 - val_loss: 20009.4726\n",
      "Epoch 887/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11846.4844 - val_loss: 19642.8098\n",
      "Epoch 888/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12424.5173 - val_loss: 20680.2110\n",
      "Epoch 889/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10680.3131 - val_loss: 19308.4295\n",
      "Epoch 890/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10659.8307 - val_loss: 19703.7497\n",
      "Epoch 891/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10837.1437 - val_loss: 19119.1247\n",
      "Epoch 892/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10618.1864 - val_loss: 19164.9487\n",
      "Epoch 893/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10473.8172 - val_loss: 19720.3550\n",
      "Epoch 894/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11164.9678 - val_loss: 19671.5092\n",
      "Epoch 895/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11974.3176 - val_loss: 20434.0241\n",
      "Epoch 896/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10873.6704 - val_loss: 20272.1581\n",
      "Epoch 897/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10545.2715 - val_loss: 20258.8434\n",
      "Epoch 898/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11839.5430 - val_loss: 23154.8369\n",
      "Epoch 899/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12211.4668 - val_loss: 18978.1418\n",
      "Epoch 900/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11354.1271 - val_loss: 19045.8804\n",
      "Epoch 901/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11978.0289 - val_loss: 21483.3918\n",
      "Epoch 902/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11262.4483 - val_loss: 21564.4382\n",
      "Epoch 903/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10806.7531 - val_loss: 18941.8623\n",
      "Epoch 904/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11350.9994 - val_loss: 21758.2400\n",
      "Epoch 905/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11622.9145 - val_loss: 19453.3404\n",
      "Epoch 906/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 13010.0978 - val_loss: 19388.8321\n",
      "Epoch 907/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11260.0885 - val_loss: 20894.9380\n",
      "Epoch 908/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11412.7621 - val_loss: 19076.9230\n",
      "Epoch 909/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10617.0935 - val_loss: 19203.6467\n",
      "Epoch 910/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10829.5073 - val_loss: 20774.6481\n",
      "Epoch 911/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 11749.8756 - val_loss: 18826.7383\n",
      "Epoch 912/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11450.5472 - val_loss: 19509.1358\n",
      "Epoch 913/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11852.0477 - val_loss: 19266.2624\n",
      "Epoch 914/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10320.2050 - val_loss: 19168.0228\n",
      "Epoch 915/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10757.0691 - val_loss: 19100.2730\n",
      "Epoch 916/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11291.0907 - val_loss: 21970.8579\n",
      "Epoch 917/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 12363.4618 - val_loss: 19578.9036\n",
      "Epoch 918/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11321.7690 - val_loss: 20692.6236\n",
      "Epoch 919/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10896.9222 - val_loss: 19146.4018\n",
      "Epoch 920/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11043.2817 - val_loss: 19850.9513\n",
      "Epoch 921/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12355.1019 - val_loss: 19923.6110\n",
      "Epoch 922/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10962.2127 - val_loss: 20666.2531\n",
      "Epoch 923/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11290.3573 - val_loss: 20383.2112\n",
      "Epoch 924/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10913.5501 - val_loss: 19900.8178\n",
      "Epoch 925/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10839.1567 - val_loss: 18796.7054\n",
      "Epoch 926/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10909.4426 - val_loss: 19236.9493\n",
      "Epoch 927/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10749.1091 - val_loss: 19407.5073\n",
      "Epoch 928/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10259.7903 - val_loss: 19288.0295\n",
      "Epoch 929/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10822.3497 - val_loss: 19986.2823\n",
      "Epoch 930/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10495.9170 - val_loss: 19086.9774\n",
      "Epoch 931/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10647.0773 - val_loss: 19848.3005\n",
      "Epoch 932/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11495.3715 - val_loss: 19470.4809\n",
      "Epoch 933/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10263.5927 - val_loss: 21481.1762\n",
      "Epoch 934/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 12525.5448 - val_loss: 19626.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10894.0997 - val_loss: 19685.6518\n",
      "Epoch 936/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11731.8938 - val_loss: 19557.8044\n",
      "Epoch 937/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11319.8054 - val_loss: 19962.5729\n",
      "Epoch 938/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10426.4104 - val_loss: 19249.3010\n",
      "Epoch 939/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11254.0266 - val_loss: 19529.2515\n",
      "Epoch 940/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10889.8872 - val_loss: 19224.9634\n",
      "Epoch 941/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 10487.2175 - val_loss: 19486.2231\n",
      "Epoch 942/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10822.8130 - val_loss: 19340.8949\n",
      "Epoch 943/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10142.8342 - val_loss: 19224.4302\n",
      "Epoch 944/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10308.1810 - val_loss: 19936.0222\n",
      "Epoch 945/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11162.7244 - val_loss: 19777.8386\n",
      "Epoch 946/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10430.6876 - val_loss: 20445.2465\n",
      "Epoch 947/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 12019.0040 - val_loss: 19767.5956\n",
      "Epoch 948/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10708.9529 - val_loss: 19365.2645\n",
      "Epoch 949/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10292.7249 - val_loss: 19003.8148\n",
      "Epoch 950/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10586.9089 - val_loss: 19564.9708\n",
      "Epoch 951/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11811.9758 - val_loss: 19249.3549\n",
      "Epoch 952/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10083.5843 - val_loss: 18827.9950\n",
      "Epoch 953/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11236.7195 - val_loss: 19229.8337\n",
      "Epoch 954/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 10279.5038 - val_loss: 19164.4945\n",
      "Epoch 955/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10494.4512 - val_loss: 19504.1362\n",
      "Epoch 956/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10558.7853 - val_loss: 19937.3810\n",
      "Epoch 957/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11695.9055 - val_loss: 19016.5355\n",
      "Epoch 958/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11199.1879 - val_loss: 19329.9569\n",
      "Epoch 959/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10464.5445 - val_loss: 19840.6690\n",
      "Epoch 960/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11661.2905 - val_loss: 20077.2071\n",
      "Epoch 961/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11157.4768 - val_loss: 18964.3114\n",
      "Epoch 962/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10258.9620 - val_loss: 19160.0636\n",
      "Epoch 963/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10346.4276 - val_loss: 19608.6530\n",
      "Epoch 964/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10821.1845 - val_loss: 19554.3631\n",
      "Epoch 965/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 11084.5512 - val_loss: 19229.8412\n",
      "Epoch 966/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11639.4628 - val_loss: 19226.4325\n",
      "Epoch 967/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10602.5641 - val_loss: 21065.7824\n",
      "Epoch 968/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12374.5369 - val_loss: 19029.2363\n",
      "Epoch 969/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10344.9411 - val_loss: 19346.2372\n",
      "Epoch 970/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10482.9515 - val_loss: 19271.6576\n",
      "Epoch 971/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10299.6775 - val_loss: 19236.8558\n",
      "Epoch 972/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10369.0746 - val_loss: 19369.6435\n",
      "Epoch 973/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 10263.475 - 0s 145us/step - loss: 10244.0187 - val_loss: 19173.8873\n",
      "Epoch 974/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10002.5919 - val_loss: 19136.3088\n",
      "Epoch 975/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9983.6560 - val_loss: 19435.3738\n",
      "Epoch 976/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10397.1630 - val_loss: 19782.8919\n",
      "Epoch 977/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9990.6317 - val_loss: 19499.3767\n",
      "Epoch 978/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 10929.1664 - val_loss: 20173.4912\n",
      "Epoch 979/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10521.0419 - val_loss: 19297.4513\n",
      "Epoch 980/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10442.8887 - val_loss: 21481.4304\n",
      "Epoch 981/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11998.9697 - val_loss: 19667.9454\n",
      "Epoch 982/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10670.9015 - val_loss: 20183.0013\n",
      "Epoch 983/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10657.9654 - val_loss: 19669.1204\n",
      "Epoch 984/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10441.2567 - val_loss: 19784.6925\n",
      "Epoch 985/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10228.7794 - val_loss: 21086.8770\n",
      "Epoch 986/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12530.6170 - val_loss: 19006.5717\n",
      "Epoch 987/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10401.2577 - val_loss: 19874.4050\n",
      "Epoch 988/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10873.8598 - val_loss: 19549.9795\n",
      "Epoch 989/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10526.9110 - val_loss: 20026.6357\n",
      "Epoch 990/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10799.5330 - val_loss: 19267.2200\n",
      "Epoch 991/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10092.7230 - val_loss: 19264.6155\n",
      "Epoch 992/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10571.1381 - val_loss: 19447.1679\n",
      "Epoch 993/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10040.5453 - val_loss: 19936.9017\n",
      "Epoch 994/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11976.8260 - val_loss: 19321.9363\n",
      "Epoch 995/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11198.5682 - val_loss: 19250.7957\n",
      "Epoch 996/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10391.3115 - val_loss: 20781.8751\n",
      "Epoch 997/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11125.3962 - val_loss: 19713.3679\n",
      "Epoch 998/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10373.2005 - val_loss: 20190.0959\n",
      "Epoch 999/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10314.4849 - val_loss: 19827.7741\n",
      "Epoch 1000/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11278.4869 - val_loss: 19350.4828\n",
      "Epoch 1001/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11222.1842 - val_loss: 19926.5075\n",
      "Epoch 1002/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 11289.2107 - val_loss: 21942.1138\n",
      "Epoch 1003/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 10999.5785 - val_loss: 19416.2551\n",
      "Epoch 1004/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10059.8920 - val_loss: 19386.5663\n",
      "Epoch 1005/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10289.3469 - val_loss: 20373.7216\n",
      "Epoch 1006/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 120us/step - loss: 12233.4267 - val_loss: 18799.7103\n",
      "Epoch 1007/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12305.9838 - val_loss: 19077.6944\n",
      "Epoch 1008/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11765.4507 - val_loss: 20381.5760\n",
      "Epoch 1009/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11303.7014 - val_loss: 19439.9287\n",
      "Epoch 1010/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10632.7970 - val_loss: 20373.2821\n",
      "Epoch 1011/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10411.6325 - val_loss: 18990.2584\n",
      "Epoch 1012/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10106.2176 - val_loss: 20608.2720\n",
      "Epoch 1013/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11276.3191 - val_loss: 19622.6080\n",
      "Epoch 1014/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10510.0803 - val_loss: 19858.4989\n",
      "Epoch 1015/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 11833.8445 - val_loss: 18918.8830\n",
      "Epoch 1016/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10666.3503 - val_loss: 21562.1186\n",
      "Epoch 1017/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11436.0153 - val_loss: 19415.8956\n",
      "Epoch 1018/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12128.0834 - val_loss: 19253.2528\n",
      "Epoch 1019/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11348.9961 - val_loss: 19042.5863\n",
      "Epoch 1020/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 10005.871 - 0s 153us/step - loss: 10078.9809 - val_loss: 19879.5817\n",
      "Epoch 1021/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10222.6885 - val_loss: 21648.7369\n",
      "Epoch 1022/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11713.3558 - val_loss: 19804.3657\n",
      "Epoch 1023/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11175.6104 - val_loss: 18993.3089\n",
      "Epoch 1024/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10580.5497 - val_loss: 19391.7761\n",
      "Epoch 1025/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10327.7159 - val_loss: 21185.6383\n",
      "Epoch 1026/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11332.6610 - val_loss: 21158.5960\n",
      "Epoch 1027/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11377.0570 - val_loss: 19387.6211\n",
      "Epoch 1028/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10439.5694 - val_loss: 19968.9374\n",
      "Epoch 1029/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10413.9220 - val_loss: 19328.3674\n",
      "Epoch 1030/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10386.1293 - val_loss: 18967.5265\n",
      "Epoch 1031/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10482.5217 - val_loss: 20361.6003\n",
      "Epoch 1032/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10037.5991 - val_loss: 19397.1266\n",
      "Epoch 1033/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9941.7931 - val_loss: 19488.4322\n",
      "Epoch 1034/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 14216.4839 - val_loss: 22623.8535\n",
      "Epoch 1035/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11245.1497 - val_loss: 19269.8977\n",
      "Epoch 1036/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11433.5613 - val_loss: 18987.9351\n",
      "Epoch 1037/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10099.5395 - val_loss: 19370.5436\n",
      "Epoch 1038/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9982.2978 - val_loss: 20682.9290\n",
      "Epoch 1039/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10154.4240 - val_loss: 19560.7857\n",
      "Epoch 1040/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11365.2848 - val_loss: 19108.5776\n",
      "Epoch 1041/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10877.2110 - val_loss: 24786.0578\n",
      "Epoch 1042/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11084.1792 - val_loss: 19033.1954\n",
      "Epoch 1043/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10918.2287 - val_loss: 19666.0699\n",
      "Epoch 1044/3000\n",
      "995/995 [==============================] - 0s 177us/step - loss: 10291.4613 - val_loss: 19294.0513\n",
      "Epoch 1045/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10045.6067 - val_loss: 19185.3175\n",
      "Epoch 1046/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9996.0825 - val_loss: 19295.9638\n",
      "Epoch 1047/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10509.7382 - val_loss: 19657.0117\n",
      "Epoch 1048/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10211.1345 - val_loss: 19183.7329\n",
      "Epoch 1049/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10297.2288 - val_loss: 19477.7199\n",
      "Epoch 1050/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10739.9292 - val_loss: 20153.4086\n",
      "Epoch 1051/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9878.5583 - val_loss: 19442.6049\n",
      "Epoch 1052/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10588.9539 - val_loss: 20591.6469\n",
      "Epoch 1053/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9914.0251 - val_loss: 18946.7597\n",
      "Epoch 1054/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10393.4204 - val_loss: 18592.0820\n",
      "Epoch 1055/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9982.2058 - val_loss: 19201.7643\n",
      "Epoch 1056/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9919.9291 - val_loss: 20245.7444\n",
      "Epoch 1057/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9904.1499 - val_loss: 19174.2943\n",
      "Epoch 1058/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9566.9382 - val_loss: 19275.4477\n",
      "Epoch 1059/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10615.8563 - val_loss: 19491.5759\n",
      "Epoch 1060/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11062.2164 - val_loss: 19948.1520\n",
      "Epoch 1061/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 10580.2408 - val_loss: 19146.6096\n",
      "Epoch 1062/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9984.5870 - val_loss: 19164.1016\n",
      "Epoch 1063/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11118.2745 - val_loss: 19301.3055\n",
      "Epoch 1064/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9753.0725 - val_loss: 19601.8966\n",
      "Epoch 1065/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9964.5762 - val_loss: 19277.1369\n",
      "Epoch 1066/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10058.5784 - val_loss: 19340.9761\n",
      "Epoch 1067/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11238.6499 - val_loss: 19577.5319\n",
      "Epoch 1068/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12021.7507 - val_loss: 20365.3972\n",
      "Epoch 1069/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10298.1827 - val_loss: 19824.5430\n",
      "Epoch 1070/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10450.7376 - val_loss: 20525.2157\n",
      "Epoch 1071/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11494.6314 - val_loss: 19899.8526\n",
      "Epoch 1072/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11586.6348 - val_loss: 19860.3223\n",
      "Epoch 1073/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11170.4629 - val_loss: 21910.8087\n",
      "Epoch 1074/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10898.7635 - val_loss: 19013.4895\n",
      "Epoch 1075/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11882.0699 - val_loss: 19197.7752\n",
      "Epoch 1076/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10610.9007 - val_loss: 20469.0177\n",
      "Epoch 1077/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 132us/step - loss: 10927.8949 - val_loss: 19442.6424\n",
      "Epoch 1078/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11424.6141 - val_loss: 20168.2879\n",
      "Epoch 1079/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10042.5395 - val_loss: 19335.7266\n",
      "Epoch 1080/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 10463.1904 - val_loss: 21315.9656\n",
      "Epoch 1081/3000\n",
      "995/995 [==============================] - 0s 181us/step - loss: 11224.4411 - val_loss: 21814.6899\n",
      "Epoch 1082/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 10583.3956 - val_loss: 19934.9170\n",
      "Epoch 1083/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9897.8814 - val_loss: 19062.4181\n",
      "Epoch 1084/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11358.3306 - val_loss: 19716.2532\n",
      "Epoch 1085/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 10729.4782 - val_loss: 19670.5181\n",
      "Epoch 1086/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 9999.258 - 0s 181us/step - loss: 10704.0586 - val_loss: 19806.9788\n",
      "Epoch 1087/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 9941.5871 - val_loss: 19796.3290\n",
      "Epoch 1088/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 10960.8055 - val_loss: 19438.7202\n",
      "Epoch 1089/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10034.5623 - val_loss: 19079.6093\n",
      "Epoch 1090/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9840.3344 - val_loss: 19967.4643\n",
      "Epoch 1091/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10314.0028 - val_loss: 19492.1644\n",
      "Epoch 1092/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9576.1344 - val_loss: 20098.8703\n",
      "Epoch 1093/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9872.7910 - val_loss: 19994.4935\n",
      "Epoch 1094/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10371.9548 - val_loss: 19560.2489\n",
      "Epoch 1095/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9379.7035 - val_loss: 19484.6271\n",
      "Epoch 1096/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10832.7142 - val_loss: 19885.9979\n",
      "Epoch 1097/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10705.6282 - val_loss: 19703.7432\n",
      "Epoch 1098/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9937.5646 - val_loss: 19946.8041\n",
      "Epoch 1099/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10000.8274 - val_loss: 19259.7201\n",
      "Epoch 1100/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9846.4505 - val_loss: 19107.6490\n",
      "Epoch 1101/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9861.0162 - val_loss: 19212.4230\n",
      "Epoch 1102/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10076.4473 - val_loss: 19351.6338\n",
      "Epoch 1103/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 12119.6264 - val_loss: 20228.2157\n",
      "Epoch 1104/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10767.7209 - val_loss: 18963.3122\n",
      "Epoch 1105/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 12350.5596 - val_loss: 19885.5222\n",
      "Epoch 1106/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10696.9748 - val_loss: 19266.7348\n",
      "Epoch 1107/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10856.9435 - val_loss: 18955.2690\n",
      "Epoch 1108/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 10084.6926 - val_loss: 18953.7615\n",
      "Epoch 1109/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9842.3090 - val_loss: 20613.2684\n",
      "Epoch 1110/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9464.5797 - val_loss: 19176.9857\n",
      "Epoch 1111/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9946.1851 - val_loss: 18956.9763\n",
      "Epoch 1112/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9794.5628 - val_loss: 18967.7995\n",
      "Epoch 1113/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10084.6402 - val_loss: 19443.2915\n",
      "Epoch 1114/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10440.7422 - val_loss: 19449.8599\n",
      "Epoch 1115/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10574.4587 - val_loss: 19715.4706\n",
      "Epoch 1116/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10644.2938 - val_loss: 19061.1228\n",
      "Epoch 1117/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10245.8057 - val_loss: 19219.6351\n",
      "Epoch 1118/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10131.6236 - val_loss: 19817.7792\n",
      "Epoch 1119/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11894.7053 - val_loss: 19425.4063\n",
      "Epoch 1120/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11103.8029 - val_loss: 18926.6819\n",
      "Epoch 1121/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10659.9061 - val_loss: 19070.1267\n",
      "Epoch 1122/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10718.3452 - val_loss: 20630.3700\n",
      "Epoch 1123/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10960.5509 - val_loss: 21251.6594\n",
      "Epoch 1124/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10089.4596 - val_loss: 19454.3635\n",
      "Epoch 1125/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9635.6753 - val_loss: 19476.8816\n",
      "Epoch 1126/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9584.8853 - val_loss: 20162.6819\n",
      "Epoch 1127/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9580.0329 - val_loss: 19794.8098\n",
      "Epoch 1128/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9865.9260 - val_loss: 19519.7819\n",
      "Epoch 1129/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10693.4169 - val_loss: 18932.7363\n",
      "Epoch 1130/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9790.0644 - val_loss: 19306.2770\n",
      "Epoch 1131/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9559.6682 - val_loss: 21096.2597\n",
      "Epoch 1132/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11557.0598 - val_loss: 19182.9343\n",
      "Epoch 1133/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10407.8262 - val_loss: 18970.0406\n",
      "Epoch 1134/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9655.1155 - val_loss: 19922.5517\n",
      "Epoch 1135/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10040.0331 - val_loss: 19400.2122\n",
      "Epoch 1136/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9605.2888 - val_loss: 19342.2857\n",
      "Epoch 1137/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9719.2400 - val_loss: 18668.6740\n",
      "Epoch 1138/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9417.7276 - val_loss: 19138.6749\n",
      "Epoch 1139/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9549.2694 - val_loss: 18982.6460\n",
      "Epoch 1140/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9741.9567 - val_loss: 19613.2779\n",
      "Epoch 1141/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9754.9419 - val_loss: 19501.4286\n",
      "Epoch 1142/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10427.1678 - val_loss: 21308.1491\n",
      "Epoch 1143/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10655.3197 - val_loss: 19372.0092\n",
      "Epoch 1144/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9515.4957 - val_loss: 19000.1184\n",
      "Epoch 1145/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9426.5515 - val_loss: 19078.2065\n",
      "Epoch 1146/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10070.1135 - val_loss: 19255.7855\n",
      "Epoch 1147/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10215.6242 - val_loss: 19515.1525\n",
      "Epoch 1148/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 141us/step - loss: 10452.5151 - val_loss: 18982.0365\n",
      "Epoch 1149/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10623.6066 - val_loss: 19288.5151\n",
      "Epoch 1150/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10755.8910 - val_loss: 19071.6363\n",
      "Epoch 1151/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9737.9888 - val_loss: 19499.2745\n",
      "Epoch 1152/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11588.2002 - val_loss: 21581.0119\n",
      "Epoch 1153/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11326.7643 - val_loss: 19083.4388\n",
      "Epoch 1154/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10093.8874 - val_loss: 19620.3996\n",
      "Epoch 1155/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9646.1263 - val_loss: 19027.0373\n",
      "Epoch 1156/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9411.6261 - val_loss: 21059.1419\n",
      "Epoch 1157/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10167.6175 - val_loss: 19328.5406\n",
      "Epoch 1158/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10897.0100 - val_loss: 19217.2770\n",
      "Epoch 1159/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 12357.2371 - val_loss: 19218.2565\n",
      "Epoch 1160/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9485.5784 - val_loss: 19240.9992\n",
      "Epoch 1161/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9354.2461 - val_loss: 19415.8998\n",
      "Epoch 1162/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 11335.8167 - val_loss: 20233.4583\n",
      "Epoch 1163/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11232.1603 - val_loss: 19835.5044\n",
      "Epoch 1164/3000\n",
      "995/995 [==============================] - 0s 177us/step - loss: 10879.0065 - val_loss: 19242.1884\n",
      "Epoch 1165/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9766.1293 - val_loss: 20798.1894\n",
      "Epoch 1166/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10200.9843 - val_loss: 20513.7090\n",
      "Epoch 1167/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11214.4857 - val_loss: 21977.1228\n",
      "Epoch 1168/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11657.6854 - val_loss: 19200.1465\n",
      "Epoch 1169/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9734.9951 - val_loss: 19561.5132\n",
      "Epoch 1170/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9967.0608 - val_loss: 21718.5430\n",
      "Epoch 1171/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10798.1616 - val_loss: 19774.4383\n",
      "Epoch 1172/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10179.4411 - val_loss: 19988.2804\n",
      "Epoch 1173/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10112.5000 - val_loss: 19232.0662\n",
      "Epoch 1174/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9938.1773 - val_loss: 19810.6213\n",
      "Epoch 1175/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10436.6085 - val_loss: 20097.0091\n",
      "Epoch 1176/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9580.1558 - val_loss: 19106.0189\n",
      "Epoch 1177/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9557.9261 - val_loss: 19984.5029\n",
      "Epoch 1178/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10522.7818 - val_loss: 19120.3368\n",
      "Epoch 1179/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10353.0762 - val_loss: 19567.2018\n",
      "Epoch 1180/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10069.7709 - val_loss: 19428.0086\n",
      "Epoch 1181/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9922.9317 - val_loss: 19038.1235\n",
      "Epoch 1182/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9501.6863 - val_loss: 20432.9865\n",
      "Epoch 1183/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9873.2843 - val_loss: 19126.9482\n",
      "Epoch 1184/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11588.5310 - val_loss: 19359.1508\n",
      "Epoch 1185/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10033.8323 - val_loss: 19208.6273\n",
      "Epoch 1186/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9349.5787 - val_loss: 18917.6152\n",
      "Epoch 1187/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9755.3919 - val_loss: 19889.6736\n",
      "Epoch 1188/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11314.1936 - val_loss: 19100.5235\n",
      "Epoch 1189/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10965.3932 - val_loss: 19664.0770\n",
      "Epoch 1190/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10368.0869 - val_loss: 18745.2210\n",
      "Epoch 1191/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9523.1067 - val_loss: 19055.0811\n",
      "Epoch 1192/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9382.0603 - val_loss: 19434.4765\n",
      "Epoch 1193/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9368.5475 - val_loss: 18969.0929\n",
      "Epoch 1194/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9349.4426 - val_loss: 18940.3116\n",
      "Epoch 1195/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9452.3094 - val_loss: 18828.5863\n",
      "Epoch 1196/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10165.0839 - val_loss: 21487.3416\n",
      "Epoch 1197/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10950.2248 - val_loss: 19650.4643\n",
      "Epoch 1198/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9926.1383 - val_loss: 20040.1328\n",
      "Epoch 1199/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10431.5156 - val_loss: 19263.7982\n",
      "Epoch 1200/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9317.6455 - val_loss: 20231.6418\n",
      "Epoch 1201/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11308.5599 - val_loss: 18897.2276\n",
      "Epoch 1202/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 11958.8130 - val_loss: 20004.8272\n",
      "Epoch 1203/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9843.1013 - val_loss: 19035.1630\n",
      "Epoch 1204/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10245.2040 - val_loss: 18988.9140\n",
      "Epoch 1205/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10036.1656 - val_loss: 19206.4092\n",
      "Epoch 1206/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10417.1600 - val_loss: 18914.5333\n",
      "Epoch 1207/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9596.9040 - val_loss: 19599.2006\n",
      "Epoch 1208/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9703.2103 - val_loss: 18659.4752\n",
      "Epoch 1209/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9759.2271 - val_loss: 19088.1922\n",
      "Epoch 1210/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10017.8067 - val_loss: 18751.7540\n",
      "Epoch 1211/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9432.3301 - val_loss: 18872.4658\n",
      "Epoch 1212/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9346.8684 - val_loss: 19113.5646\n",
      "Epoch 1213/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9530.9809 - val_loss: 19513.3368\n",
      "Epoch 1214/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10184.7598 - val_loss: 19288.7014\n",
      "Epoch 1215/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9803.3408 - val_loss: 20469.1842\n",
      "Epoch 1216/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10914.9146 - val_loss: 19383.8506\n",
      "Epoch 1217/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10509.2440 - val_loss: 19034.0034\n",
      "Epoch 1218/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9926.0050 - val_loss: 19688.3207\n",
      "Epoch 1219/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 165us/step - loss: 9142.3951 - val_loss: 19104.6180\n",
      "Epoch 1220/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9632.7074 - val_loss: 19445.1460\n",
      "Epoch 1221/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11393.1166 - val_loss: 21480.5474\n",
      "Epoch 1222/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 11471.6718 - val_loss: 19533.1071\n",
      "Epoch 1223/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10322.4049 - val_loss: 19242.8126\n",
      "Epoch 1224/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10197.5451 - val_loss: 19982.9785\n",
      "Epoch 1225/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9309.8882 - val_loss: 19269.4448\n",
      "Epoch 1226/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9242.3328 - val_loss: 19430.6823\n",
      "Epoch 1227/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9597.7194 - val_loss: 20168.1832\n",
      "Epoch 1228/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9735.7875 - val_loss: 19318.4822\n",
      "Epoch 1229/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9474.4426 - val_loss: 19222.3489\n",
      "Epoch 1230/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9417.4905 - val_loss: 18905.2850\n",
      "Epoch 1231/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9325.0530 - val_loss: 18814.9149\n",
      "Epoch 1232/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9336.1879 - val_loss: 20027.9927\n",
      "Epoch 1233/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10312.3352 - val_loss: 19154.3374\n",
      "Epoch 1234/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 10280.3535 - val_loss: 20043.8648\n",
      "Epoch 1235/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10436.7520 - val_loss: 18758.5864\n",
      "Epoch 1236/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9952.0063 - val_loss: 20302.8575\n",
      "Epoch 1237/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10117.9386 - val_loss: 18662.5081\n",
      "Epoch 1238/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9563.0272 - val_loss: 19251.1367\n",
      "Epoch 1239/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10310.9966 - val_loss: 18985.9845\n",
      "Epoch 1240/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10444.7884 - val_loss: 19111.7371\n",
      "Epoch 1241/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9392.1687 - val_loss: 18956.7296\n",
      "Epoch 1242/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9868.9225 - val_loss: 18932.7658\n",
      "Epoch 1243/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9356.9966 - val_loss: 19516.0722\n",
      "Epoch 1244/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9777.9212 - val_loss: 19055.3447\n",
      "Epoch 1245/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9668.0747 - val_loss: 18875.8851\n",
      "Epoch 1246/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9111.1550 - val_loss: 19127.4873\n",
      "Epoch 1247/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9586.8761 - val_loss: 20088.0461\n",
      "Epoch 1248/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9964.5821 - val_loss: 18949.0890\n",
      "Epoch 1249/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9611.4381 - val_loss: 19073.6853\n",
      "Epoch 1250/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10010.2112 - val_loss: 19200.3074\n",
      "Epoch 1251/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9940.6681 - val_loss: 21548.0415\n",
      "Epoch 1252/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10910.5471 - val_loss: 18801.0035\n",
      "Epoch 1253/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10308.8049 - val_loss: 19906.4308\n",
      "Epoch 1254/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10074.9539 - val_loss: 19950.7003\n",
      "Epoch 1255/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10252.4258 - val_loss: 19282.7809\n",
      "Epoch 1256/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9755.1818 - val_loss: 19656.6240\n",
      "Epoch 1257/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10379.2201 - val_loss: 19316.1796\n",
      "Epoch 1258/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8979.7078 - val_loss: 19547.5067\n",
      "Epoch 1259/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10638.9857 - val_loss: 19630.1942\n",
      "Epoch 1260/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10516.3768 - val_loss: 19074.0010\n",
      "Epoch 1261/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9282.0826 - val_loss: 18863.2997\n",
      "Epoch 1262/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9052.6915 - val_loss: 18860.7036\n",
      "Epoch 1263/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9051.3233 - val_loss: 19004.9403\n",
      "Epoch 1264/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 9780.3748 - val_loss: 18848.8507\n",
      "Epoch 1265/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11036.2031 - val_loss: 19116.0603\n",
      "Epoch 1266/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9745.3511 - val_loss: 19227.8494\n",
      "Epoch 1267/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9213.0628 - val_loss: 18894.4183\n",
      "Epoch 1268/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9532.8350 - val_loss: 18945.5346\n",
      "Epoch 1269/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9856.5811 - val_loss: 19169.3104\n",
      "Epoch 1270/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9445.2798 - val_loss: 19867.3226\n",
      "Epoch 1271/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10328.9577 - val_loss: 19604.3045\n",
      "Epoch 1272/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10029.2406 - val_loss: 18860.6789\n",
      "Epoch 1273/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9548.5047 - val_loss: 18789.9166\n",
      "Epoch 1274/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9532.4375 - val_loss: 19211.4653\n",
      "Epoch 1275/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10007.1182 - val_loss: 20109.4888\n",
      "Epoch 1276/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10763.5935 - val_loss: 19019.0132\n",
      "Epoch 1277/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9192.7767 - val_loss: 19629.9999\n",
      "Epoch 1278/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9617.7729 - val_loss: 18891.4749\n",
      "Epoch 1279/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10325.7384 - val_loss: 19094.0905\n",
      "Epoch 1280/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10526.3340 - val_loss: 19454.1055\n",
      "Epoch 1281/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 12742.5565 - val_loss: 20171.5606\n",
      "Epoch 1282/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9706.2500 - val_loss: 18928.1631\n",
      "Epoch 1283/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9943.5814 - val_loss: 18868.9759\n",
      "Epoch 1284/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9496.3625 - val_loss: 18942.6149\n",
      "Epoch 1285/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11215.6317 - val_loss: 19042.5555\n",
      "Epoch 1286/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9120.6979 - val_loss: 19797.3288\n",
      "Epoch 1287/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 11064.3680 - val_loss: 19934.6403\n",
      "Epoch 1288/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9855.3400 - val_loss: 18821.2626\n",
      "Epoch 1289/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10818.2657 - val_loss: 19216.3416\n",
      "Epoch 1290/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9819.8139 - val_loss: 19263.2234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1291/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10156.6018 - val_loss: 20571.6813\n",
      "Epoch 1292/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9880.8681 - val_loss: 18469.6588\n",
      "Epoch 1293/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9625.8566 - val_loss: 18710.3033\n",
      "Epoch 1294/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9687.9773 - val_loss: 18972.8373\n",
      "Epoch 1295/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9889.2858 - val_loss: 19100.5338\n",
      "Epoch 1296/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9566.5450 - val_loss: 19039.7320\n",
      "Epoch 1297/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9617.7704 - val_loss: 18835.1130\n",
      "Epoch 1298/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9742.8615 - val_loss: 19259.3655\n",
      "Epoch 1299/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10277.7000 - val_loss: 19501.6820\n",
      "Epoch 1300/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9879.0433 - val_loss: 18998.2980\n",
      "Epoch 1301/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9752.8599 - val_loss: 20602.5499\n",
      "Epoch 1302/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10141.5633 - val_loss: 18967.3113\n",
      "Epoch 1303/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9643.1147 - val_loss: 18800.6457\n",
      "Epoch 1304/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10651.7838 - val_loss: 18825.6987\n",
      "Epoch 1305/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10831.0121 - val_loss: 18736.0190\n",
      "Epoch 1306/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9685.4419 - val_loss: 19511.2697\n",
      "Epoch 1307/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9965.0564 - val_loss: 18941.9214\n",
      "Epoch 1308/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10108.5358 - val_loss: 19267.3448\n",
      "Epoch 1309/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9022.3400 - val_loss: 19304.7575\n",
      "Epoch 1310/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9641.2351 - val_loss: 20543.2492\n",
      "Epoch 1311/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10041.1770 - val_loss: 18573.9112\n",
      "Epoch 1312/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9206.2867 - val_loss: 19029.7224\n",
      "Epoch 1313/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10283.5377 - val_loss: 19061.0742\n",
      "Epoch 1314/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9124.8132 - val_loss: 18899.5401\n",
      "Epoch 1315/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9088.2599 - val_loss: 19039.5001\n",
      "Epoch 1316/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9272.9480 - val_loss: 19749.7424\n",
      "Epoch 1317/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9801.7297 - val_loss: 18973.5313\n",
      "Epoch 1318/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 9749.8128 - val_loss: 19008.9813\n",
      "Epoch 1319/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9503.5376 - val_loss: 19326.4584\n",
      "Epoch 1320/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9488.6178 - val_loss: 18727.3871\n",
      "Epoch 1321/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9289.0945 - val_loss: 19598.9264\n",
      "Epoch 1322/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10136.6124 - val_loss: 18857.8501\n",
      "Epoch 1323/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9524.5006 - val_loss: 18848.1236\n",
      "Epoch 1324/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9141.4898 - val_loss: 19020.0311\n",
      "Epoch 1325/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10216.9136 - val_loss: 19051.0656\n",
      "Epoch 1326/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9799.6989 - val_loss: 19341.3386\n",
      "Epoch 1327/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10453.5411 - val_loss: 19746.2862\n",
      "Epoch 1328/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10237.1164 - val_loss: 18941.3335\n",
      "Epoch 1329/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9125.2510 - val_loss: 18831.8541\n",
      "Epoch 1330/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9088.3571 - val_loss: 19231.7994\n",
      "Epoch 1331/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10043.7992 - val_loss: 19098.3836\n",
      "Epoch 1332/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9594.7955 - val_loss: 19535.3859\n",
      "Epoch 1333/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11041.8130 - val_loss: 19373.0144\n",
      "Epoch 1334/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10765.9605 - val_loss: 19972.4843\n",
      "Epoch 1335/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10624.9237 - val_loss: 19300.3530\n",
      "Epoch 1336/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 9974.8333 - val_loss: 18874.2374\n",
      "Epoch 1337/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9598.9256 - val_loss: 20704.3519\n",
      "Epoch 1338/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10427.4328 - val_loss: 19101.7412\n",
      "Epoch 1339/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9097.1769 - val_loss: 18721.0748\n",
      "Epoch 1340/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9193.7703 - val_loss: 20567.0603\n",
      "Epoch 1341/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11547.0411 - val_loss: 19311.7907\n",
      "Epoch 1342/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9043.4431 - val_loss: 19736.3795\n",
      "Epoch 1343/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10324.4839 - val_loss: 18967.2283\n",
      "Epoch 1344/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9985.6133 - val_loss: 19043.9880\n",
      "Epoch 1345/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9658.0575 - val_loss: 18708.0021\n",
      "Epoch 1346/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9178.6602 - val_loss: 20829.2809\n",
      "Epoch 1347/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11386.6438 - val_loss: 20002.7968\n",
      "Epoch 1348/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9508.1649 - val_loss: 18769.8320\n",
      "Epoch 1349/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9757.9384 - val_loss: 20237.8586\n",
      "Epoch 1350/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10127.9957 - val_loss: 18973.5737\n",
      "Epoch 1351/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10320.8928 - val_loss: 18921.6786\n",
      "Epoch 1352/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10106.8427 - val_loss: 22336.6676\n",
      "Epoch 1353/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11026.9075 - val_loss: 19169.6896\n",
      "Epoch 1354/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10101.1043 - val_loss: 19433.9548\n",
      "Epoch 1355/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9331.7139 - val_loss: 19137.6963\n",
      "Epoch 1356/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9685.5066 - val_loss: 20612.3031\n",
      "Epoch 1357/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9675.5693 - val_loss: 20425.1673\n",
      "Epoch 1358/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10774.3381 - val_loss: 19324.2778\n",
      "Epoch 1359/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9152.2996 - val_loss: 19247.2053\n",
      "Epoch 1360/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9120.5092 - val_loss: 19268.6733\n",
      "Epoch 1361/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9838.7039 - val_loss: 18985.1906\n",
      "Epoch 1362/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 153us/step - loss: 9726.7116 - val_loss: 18950.0097\n",
      "Epoch 1363/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8887.9183 - val_loss: 18636.1957\n",
      "Epoch 1364/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8681.0406 - val_loss: 18524.2261\n",
      "Epoch 1365/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10022.5094 - val_loss: 19902.1125\n",
      "Epoch 1366/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10186.8186 - val_loss: 18944.9237\n",
      "Epoch 1367/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9730.4841 - val_loss: 19076.6191\n",
      "Epoch 1368/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8846.6119 - val_loss: 19642.9008\n",
      "Epoch 1369/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9637.0107 - val_loss: 18919.9840\n",
      "Epoch 1370/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8855.9322 - val_loss: 19287.8747\n",
      "Epoch 1371/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8800.7674 - val_loss: 18915.1148\n",
      "Epoch 1372/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9109.7135 - val_loss: 19204.8693\n",
      "Epoch 1373/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9194.9907 - val_loss: 18980.3162\n",
      "Epoch 1374/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9020.6750 - val_loss: 18777.6284\n",
      "Epoch 1375/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9410.8501 - val_loss: 21158.0516\n",
      "Epoch 1376/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9217.7406 - val_loss: 18933.4553\n",
      "Epoch 1377/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 9306.2579 - val_loss: 18618.7586\n",
      "Epoch 1378/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9827.2729 - val_loss: 19506.3144\n",
      "Epoch 1379/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9180.8371 - val_loss: 18701.1844\n",
      "Epoch 1380/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8932.3085 - val_loss: 19249.7205\n",
      "Epoch 1381/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11318.8225 - val_loss: 18414.5353\n",
      "Epoch 1382/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9219.2277 - val_loss: 19225.7533\n",
      "Epoch 1383/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9178.4525 - val_loss: 19624.7376\n",
      "Epoch 1384/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8927.5267 - val_loss: 19434.6809\n",
      "Epoch 1385/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8948.0369 - val_loss: 18684.0325\n",
      "Epoch 1386/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11103.7368 - val_loss: 19367.5231\n",
      "Epoch 1387/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9371.3412 - val_loss: 20578.0968\n",
      "Epoch 1388/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 13558.9871 - val_loss: 19295.8924\n",
      "Epoch 1389/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9814.4365 - val_loss: 19355.9314\n",
      "Epoch 1390/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9585.8461 - val_loss: 20045.8460\n",
      "Epoch 1391/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10091.8124 - val_loss: 19309.1549\n",
      "Epoch 1392/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9582.2599 - val_loss: 18750.4254\n",
      "Epoch 1393/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9566.4559 - val_loss: 19238.8346\n",
      "Epoch 1394/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9163.8484 - val_loss: 18957.9035\n",
      "Epoch 1395/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9830.7216 - val_loss: 19493.7840\n",
      "Epoch 1396/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9185.5475 - val_loss: 20275.8374\n",
      "Epoch 1397/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9418.4540 - val_loss: 18995.4421\n",
      "Epoch 1398/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9169.9857 - val_loss: 19088.9568\n",
      "Epoch 1399/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9128.3543 - val_loss: 19311.0756\n",
      "Epoch 1400/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9353.2562 - val_loss: 18590.7743\n",
      "Epoch 1401/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9092.9686 - val_loss: 18730.7403\n",
      "Epoch 1402/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8749.1793 - val_loss: 20604.5017\n",
      "Epoch 1403/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9967.8042 - val_loss: 18945.5100\n",
      "Epoch 1404/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8988.4584 - val_loss: 18802.2142\n",
      "Epoch 1405/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9314.1229 - val_loss: 18751.5585\n",
      "Epoch 1406/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9970.1491 - val_loss: 19193.7901\n",
      "Epoch 1407/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9188.1043 - val_loss: 19451.4934\n",
      "Epoch 1408/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9841.5341 - val_loss: 19148.2826\n",
      "Epoch 1409/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9018.7303 - val_loss: 19429.5699\n",
      "Epoch 1410/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9435.2415 - val_loss: 19045.4083\n",
      "Epoch 1411/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8850.2239 - val_loss: 19549.5858\n",
      "Epoch 1412/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9403.6284 - val_loss: 19062.3650\n",
      "Epoch 1413/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8727.5881 - val_loss: 19353.7338\n",
      "Epoch 1414/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9431.0269 - val_loss: 19434.6105\n",
      "Epoch 1415/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8769.2616 - val_loss: 19244.3209\n",
      "Epoch 1416/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10390.1051 - val_loss: 19035.1840\n",
      "Epoch 1417/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9434.0015 - val_loss: 20309.4430\n",
      "Epoch 1418/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9339.9555 - val_loss: 18701.5781\n",
      "Epoch 1419/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9311.7445 - val_loss: 20684.4207\n",
      "Epoch 1420/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9259.7410 - val_loss: 18992.0278\n",
      "Epoch 1421/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8890.9030 - val_loss: 19983.2203\n",
      "Epoch 1422/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9539.2172 - val_loss: 19801.4867\n",
      "Epoch 1423/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10208.7501 - val_loss: 18916.0180\n",
      "Epoch 1424/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9569.8539 - val_loss: 19575.5136\n",
      "Epoch 1425/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9032.4479 - val_loss: 19234.2757\n",
      "Epoch 1426/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8825.6563 - val_loss: 19127.1177\n",
      "Epoch 1427/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8964.3810 - val_loss: 18768.2109\n",
      "Epoch 1428/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9430.9227 - val_loss: 19438.2724\n",
      "Epoch 1429/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9617.6683 - val_loss: 18592.8859\n",
      "Epoch 1430/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9527.2168 - val_loss: 19944.8501\n",
      "Epoch 1431/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10103.9828 - val_loss: 19470.3642\n",
      "Epoch 1432/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9961.0354 - val_loss: 19278.0245\n",
      "Epoch 1433/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10619.4631 - val_loss: 19847.2588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1434/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9970.1327 - val_loss: 18919.4450\n",
      "Epoch 1435/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9683.3594 - val_loss: 19130.1104\n",
      "Epoch 1436/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8753.7182 - val_loss: 19525.8519\n",
      "Epoch 1437/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9146.5609 - val_loss: 18446.5164\n",
      "Epoch 1438/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9093.1316 - val_loss: 19041.3374\n",
      "Epoch 1439/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9031.7279 - val_loss: 19092.9433\n",
      "Epoch 1440/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8900.5159 - val_loss: 19547.9921\n",
      "Epoch 1441/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9107.0843 - val_loss: 18942.4489\n",
      "Epoch 1442/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8892.8284 - val_loss: 18819.8028\n",
      "Epoch 1443/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8500.2558 - val_loss: 18727.9955\n",
      "Epoch 1444/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9125.8933 - val_loss: 18710.7025\n",
      "Epoch 1445/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10021.8694 - val_loss: 19009.5101\n",
      "Epoch 1446/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9525.9788 - val_loss: 19319.2072\n",
      "Epoch 1447/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9901.6177 - val_loss: 19942.2094\n",
      "Epoch 1448/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10395.2632 - val_loss: 21573.6850\n",
      "Epoch 1449/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10018.4573 - val_loss: 20406.4711\n",
      "Epoch 1450/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9734.0743 - val_loss: 19627.1684\n",
      "Epoch 1451/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8547.3440 - val_loss: 19585.2152\n",
      "Epoch 1452/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9445.9130 - val_loss: 18818.4897\n",
      "Epoch 1453/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9926.1305 - val_loss: 19011.3055\n",
      "Epoch 1454/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8970.2241 - val_loss: 19157.1917\n",
      "Epoch 1455/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8552.6902 - val_loss: 19505.8536\n",
      "Epoch 1456/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8831.4321 - val_loss: 19201.3854\n",
      "Epoch 1457/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8690.3893 - val_loss: 19058.2804\n",
      "Epoch 1458/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10182.1015 - val_loss: 18950.3334\n",
      "Epoch 1459/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11840.9062 - val_loss: 18723.8584\n",
      "Epoch 1460/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9339.3421 - val_loss: 19790.7394\n",
      "Epoch 1461/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10938.3625 - val_loss: 19985.2560\n",
      "Epoch 1462/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9494.8072 - val_loss: 20122.5571\n",
      "Epoch 1463/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9970.5956 - val_loss: 18601.7445\n",
      "Epoch 1464/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9227.4222 - val_loss: 18504.8497\n",
      "Epoch 1465/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9151.8992 - val_loss: 19385.8166\n",
      "Epoch 1466/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10223.7418 - val_loss: 18987.6017\n",
      "Epoch 1467/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9221.9977 - val_loss: 18975.0527\n",
      "Epoch 1468/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9531.4161 - val_loss: 18666.2394\n",
      "Epoch 1469/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9481.2233 - val_loss: 18981.9800\n",
      "Epoch 1470/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9478.6486 - val_loss: 19348.2064\n",
      "Epoch 1471/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8696.8701 - val_loss: 18809.5778\n",
      "Epoch 1472/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8850.1009 - val_loss: 19460.9548\n",
      "Epoch 1473/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9951.5895 - val_loss: 19148.4146\n",
      "Epoch 1474/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10434.7684 - val_loss: 19313.9661\n",
      "Epoch 1475/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9107.8377 - val_loss: 18942.7696\n",
      "Epoch 1476/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8965.3334 - val_loss: 19154.8994\n",
      "Epoch 1477/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8848.6761 - val_loss: 19019.2844\n",
      "Epoch 1478/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8979.1806 - val_loss: 18976.4006\n",
      "Epoch 1479/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9914.7497 - val_loss: 18977.8536\n",
      "Epoch 1480/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9089.3418 - val_loss: 19296.2664\n",
      "Epoch 1481/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8972.6225 - val_loss: 18697.1965\n",
      "Epoch 1482/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10900.0755 - val_loss: 19901.5988\n",
      "Epoch 1483/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9922.1386 - val_loss: 18772.1037\n",
      "Epoch 1484/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8573.4954 - val_loss: 19121.4469\n",
      "Epoch 1485/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9874.7716 - val_loss: 20156.9819\n",
      "Epoch 1486/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9323.1973 - val_loss: 20711.2100\n",
      "Epoch 1487/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9961.3978 - val_loss: 20170.0573\n",
      "Epoch 1488/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9152.0951 - val_loss: 21155.6039\n",
      "Epoch 1489/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 10869.8422 - val_loss: 19867.3428\n",
      "Epoch 1490/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8925.7754 - val_loss: 19309.2231\n",
      "Epoch 1491/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8921.0124 - val_loss: 19212.2564\n",
      "Epoch 1492/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9143.5490 - val_loss: 18987.2908\n",
      "Epoch 1493/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8957.5972 - val_loss: 18706.1747\n",
      "Epoch 1494/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9040.5519 - val_loss: 19016.3643\n",
      "Epoch 1495/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9407.9763 - val_loss: 18983.3839\n",
      "Epoch 1496/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9058.6590 - val_loss: 19032.2899\n",
      "Epoch 1497/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9529.4723 - val_loss: 18821.9978\n",
      "Epoch 1498/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9711.3735 - val_loss: 19474.0713\n",
      "Epoch 1499/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8948.0150 - val_loss: 18861.9716\n",
      "Epoch 1500/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8537.0740 - val_loss: 19035.3755\n",
      "Epoch 1501/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9199.2661 - val_loss: 19588.0616\n",
      "Epoch 1502/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9708.7667 - val_loss: 20302.3456\n",
      "Epoch 1503/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10120.8999 - val_loss: 19781.7834\n",
      "Epoch 1504/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9322.8108 - val_loss: 19162.9187\n",
      "Epoch 1505/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9353.4801 - val_loss: 18650.3361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1506/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9368.8199 - val_loss: 19043.8872\n",
      "Epoch 1507/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9436.9329 - val_loss: 18875.8308\n",
      "Epoch 1508/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9664.5135 - val_loss: 18580.0810\n",
      "Epoch 1509/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8648.2454 - val_loss: 19130.8576\n",
      "Epoch 1510/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8606.5849 - val_loss: 19332.3261\n",
      "Epoch 1511/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9205.0732 - val_loss: 18918.5937\n",
      "Epoch 1512/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9078.7362 - val_loss: 19108.3596\n",
      "Epoch 1513/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8886.7611 - val_loss: 19449.3831\n",
      "Epoch 1514/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8384.0417 - val_loss: 19278.6999\n",
      "Epoch 1515/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8377.5845 - val_loss: 18840.1560\n",
      "Epoch 1516/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8550.2937 - val_loss: 19461.1048\n",
      "Epoch 1517/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10231.2490 - val_loss: 19072.8312\n",
      "Epoch 1518/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9582.4817 - val_loss: 19191.2115\n",
      "Epoch 1519/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9083.3122 - val_loss: 18609.1139\n",
      "Epoch 1520/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8869.7986 - val_loss: 18770.7313\n",
      "Epoch 1521/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8639.9698 - val_loss: 19659.4167\n",
      "Epoch 1522/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8940.0865 - val_loss: 18627.8490\n",
      "Epoch 1523/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8794.4413 - val_loss: 21219.4467\n",
      "Epoch 1524/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 11466.6440 - val_loss: 18670.3141\n",
      "Epoch 1525/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9940.8522 - val_loss: 18983.5136\n",
      "Epoch 1526/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9642.6483 - val_loss: 19328.0171\n",
      "Epoch 1527/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9353.2825 - val_loss: 19161.1928\n",
      "Epoch 1528/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9354.8659 - val_loss: 19230.9313\n",
      "Epoch 1529/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8863.4480 - val_loss: 19150.4601\n",
      "Epoch 1530/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8869.3491 - val_loss: 20406.6484\n",
      "Epoch 1531/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8823.8304 - val_loss: 18952.8929\n",
      "Epoch 1532/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8585.5373 - val_loss: 19174.2426\n",
      "Epoch 1533/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8730.7793 - val_loss: 19286.5430\n",
      "Epoch 1534/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8400.6999 - val_loss: 18790.0802\n",
      "Epoch 1535/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10292.8561 - val_loss: 18962.9199\n",
      "Epoch 1536/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8981.9879 - val_loss: 20877.8099\n",
      "Epoch 1537/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10144.4824 - val_loss: 19019.1830\n",
      "Epoch 1538/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8764.9385 - val_loss: 18958.0341\n",
      "Epoch 1539/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8401.6203 - val_loss: 19277.1622\n",
      "Epoch 1540/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8564.1437 - val_loss: 18994.2904\n",
      "Epoch 1541/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8754.2976 - val_loss: 19062.8242\n",
      "Epoch 1542/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9234.2881 - val_loss: 18870.2103\n",
      "Epoch 1543/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8555.3079 - val_loss: 19258.5613\n",
      "Epoch 1544/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9588.3993 - val_loss: 19065.7959\n",
      "Epoch 1545/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8653.1871 - val_loss: 18854.4167\n",
      "Epoch 1546/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9027.7319 - val_loss: 18965.0608\n",
      "Epoch 1547/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10206.6323 - val_loss: 20262.5822\n",
      "Epoch 1548/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10076.1002 - val_loss: 19932.1704\n",
      "Epoch 1549/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10444.0408 - val_loss: 20519.9407\n",
      "Epoch 1550/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10369.4904 - val_loss: 18710.0674\n",
      "Epoch 1551/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8765.7252 - val_loss: 18728.2449\n",
      "Epoch 1552/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8998.0520 - val_loss: 19104.5611\n",
      "Epoch 1553/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9026.3773 - val_loss: 18682.7808\n",
      "Epoch 1554/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8724.2084 - val_loss: 19133.4943\n",
      "Epoch 1555/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9346.2237 - val_loss: 19920.3743\n",
      "Epoch 1556/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9486.2606 - val_loss: 19019.6513\n",
      "Epoch 1557/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9841.2955 - val_loss: 19086.6189\n",
      "Epoch 1558/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9347.9497 - val_loss: 18983.4977\n",
      "Epoch 1559/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9658.1728 - val_loss: 18931.4445\n",
      "Epoch 1560/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9359.3223 - val_loss: 19002.1630\n",
      "Epoch 1561/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8805.6235 - val_loss: 18739.1911\n",
      "Epoch 1562/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8427.8168 - val_loss: 18652.3434\n",
      "Epoch 1563/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8469.7156 - val_loss: 18846.7920\n",
      "Epoch 1564/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8873.6708 - val_loss: 18807.0737\n",
      "Epoch 1565/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8668.3107 - val_loss: 20040.5191\n",
      "Epoch 1566/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10982.0295 - val_loss: 20304.6162\n",
      "Epoch 1567/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10715.8172 - val_loss: 19436.3700\n",
      "Epoch 1568/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8633.5983 - val_loss: 19625.3934\n",
      "Epoch 1569/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9813.9096 - val_loss: 20113.1186\n",
      "Epoch 1570/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9838.4982 - val_loss: 19065.5043\n",
      "Epoch 1571/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9117.3843 - val_loss: 19862.9852\n",
      "Epoch 1572/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9422.8438 - val_loss: 19992.5240\n",
      "Epoch 1573/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10864.7248 - val_loss: 19041.3414\n",
      "Epoch 1574/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9120.6850 - val_loss: 20436.3677\n",
      "Epoch 1575/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9114.8353 - val_loss: 18944.3362\n",
      "Epoch 1576/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9306.1872 - val_loss: 19206.9829\n",
      "Epoch 1577/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8935.9443 - val_loss: 18957.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1578/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9528.1438 - val_loss: 19767.3241\n",
      "Epoch 1579/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9336.1327 - val_loss: 20325.8336\n",
      "Epoch 1580/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9592.8427 - val_loss: 19793.8600\n",
      "Epoch 1581/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9120.6108 - val_loss: 19519.6737\n",
      "Epoch 1582/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8440.5900 - val_loss: 19154.2928\n",
      "Epoch 1583/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10038.7161 - val_loss: 19927.3490\n",
      "Epoch 1584/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8923.8311 - val_loss: 19069.3338\n",
      "Epoch 1585/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8496.3030 - val_loss: 20043.7012\n",
      "Epoch 1586/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10706.8702 - val_loss: 18833.5366\n",
      "Epoch 1587/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8662.1594 - val_loss: 18723.2739\n",
      "Epoch 1588/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8977.3818 - val_loss: 19196.0325\n",
      "Epoch 1589/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8966.5755 - val_loss: 19028.7693\n",
      "Epoch 1590/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8933.0439 - val_loss: 18591.4254\n",
      "Epoch 1591/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8840.8812 - val_loss: 18460.5176\n",
      "Epoch 1592/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9106.5206 - val_loss: 19435.0898\n",
      "Epoch 1593/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8785.9189 - val_loss: 18983.6704\n",
      "Epoch 1594/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10366.0627 - val_loss: 19046.6020\n",
      "Epoch 1595/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9303.7451 - val_loss: 19121.6328\n",
      "Epoch 1596/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9652.0799 - val_loss: 18904.4776\n",
      "Epoch 1597/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9345.7576 - val_loss: 18670.1682\n",
      "Epoch 1598/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10018.5987 - val_loss: 18594.9464\n",
      "Epoch 1599/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8512.9682 - val_loss: 18941.7582\n",
      "Epoch 1600/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8826.6986 - val_loss: 19080.9985\n",
      "Epoch 1601/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8759.1433 - val_loss: 19898.0738\n",
      "Epoch 1602/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10727.1515 - val_loss: 18912.3016\n",
      "Epoch 1603/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8808.2594 - val_loss: 19406.4206\n",
      "Epoch 1604/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8192.1284 - val_loss: 19248.1998\n",
      "Epoch 1605/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8857.9601 - val_loss: 18646.1890\n",
      "Epoch 1606/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8413.8353 - val_loss: 19060.1603\n",
      "Epoch 1607/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9511.6552 - val_loss: 18712.6707\n",
      "Epoch 1608/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8696.1148 - val_loss: 18830.2207\n",
      "Epoch 1609/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8767.8996 - val_loss: 18867.3048\n",
      "Epoch 1610/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9692.4788 - val_loss: 18620.4134\n",
      "Epoch 1611/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8698.5286 - val_loss: 18890.0751\n",
      "Epoch 1612/3000\n",
      "995/995 [==============================] - 0s 139us/step - loss: 8662.3213 - val_loss: 18887.4618\n",
      "Epoch 1613/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9646.0383 - val_loss: 18955.3637\n",
      "Epoch 1614/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8779.1410 - val_loss: 18617.3849\n",
      "Epoch 1615/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8307.0233 - val_loss: 18998.8360\n",
      "Epoch 1616/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8573.8639 - val_loss: 18499.5952\n",
      "Epoch 1617/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9770.7902 - val_loss: 18564.8000\n",
      "Epoch 1618/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8886.8914 - val_loss: 18810.4138\n",
      "Epoch 1619/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8718.1111 - val_loss: 18656.1925\n",
      "Epoch 1620/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8709.4416 - val_loss: 19458.1656\n",
      "Epoch 1621/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9561.3086 - val_loss: 18677.1927\n",
      "Epoch 1622/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8657.1515 - val_loss: 18703.1169\n",
      "Epoch 1623/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8623.5497 - val_loss: 19099.0053\n",
      "Epoch 1624/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9993.9589 - val_loss: 22177.7085\n",
      "Epoch 1625/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10200.4765 - val_loss: 19303.4847\n",
      "Epoch 1626/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9100.3824 - val_loss: 19230.9866\n",
      "Epoch 1627/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8607.0231 - val_loss: 19042.1209\n",
      "Epoch 1628/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8381.1887 - val_loss: 18832.2282\n",
      "Epoch 1629/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8288.4797 - val_loss: 18745.6794\n",
      "Epoch 1630/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8870.0559 - val_loss: 18961.7016\n",
      "Epoch 1631/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8346.1181 - val_loss: 18814.1628\n",
      "Epoch 1632/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8903.9019 - val_loss: 19242.1945\n",
      "Epoch 1633/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9573.5468 - val_loss: 20292.8735\n",
      "Epoch 1634/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9926.6102 - val_loss: 18926.4009\n",
      "Epoch 1635/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8719.4534 - val_loss: 19104.8254\n",
      "Epoch 1636/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8634.0934 - val_loss: 18918.4262\n",
      "Epoch 1637/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9273.9198 - val_loss: 19322.4644\n",
      "Epoch 1638/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8472.8528 - val_loss: 18883.8486\n",
      "Epoch 1639/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8564.2390 - val_loss: 19972.9028\n",
      "Epoch 1640/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9064.9619 - val_loss: 19209.0360\n",
      "Epoch 1641/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8881.7729 - val_loss: 18791.9351\n",
      "Epoch 1642/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8785.5960 - val_loss: 18777.4106\n",
      "Epoch 1643/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8151.7463 - val_loss: 18871.7870\n",
      "Epoch 1644/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9248.2619 - val_loss: 18793.8703\n",
      "Epoch 1645/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8813.4882 - val_loss: 19465.0907\n",
      "Epoch 1646/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9269.9111 - val_loss: 18669.0768\n",
      "Epoch 1647/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9350.7314 - val_loss: 19054.2289\n",
      "Epoch 1648/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8860.2424 - val_loss: 21407.1830\n",
      "Epoch 1649/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 11695.7315 - val_loss: 19699.6266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1650/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9162.4279 - val_loss: 19216.2825\n",
      "Epoch 1651/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8853.7519 - val_loss: 18913.9425\n",
      "Epoch 1652/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9319.0973 - val_loss: 19043.4134\n",
      "Epoch 1653/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8972.4494 - val_loss: 18529.7704\n",
      "Epoch 1654/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8693.8240 - val_loss: 18765.2823\n",
      "Epoch 1655/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8573.1080 - val_loss: 19533.4838\n",
      "Epoch 1656/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8590.2241 - val_loss: 18778.0648\n",
      "Epoch 1657/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9657.4474 - val_loss: 18735.2448\n",
      "Epoch 1658/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8351.7619 - val_loss: 19119.2349\n",
      "Epoch 1659/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8972.4584 - val_loss: 19086.2121\n",
      "Epoch 1660/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9390.6959 - val_loss: 19092.1131\n",
      "Epoch 1661/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8753.6168 - val_loss: 19143.5278\n",
      "Epoch 1662/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9866.9085 - val_loss: 18622.2022\n",
      "Epoch 1663/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8894.7942 - val_loss: 19932.5909\n",
      "Epoch 1664/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9450.1585 - val_loss: 18902.1989\n",
      "Epoch 1665/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9266.3811 - val_loss: 18310.7214\n",
      "Epoch 1666/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9043.7833 - val_loss: 18902.5945\n",
      "Epoch 1667/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9310.1874 - val_loss: 19231.3852\n",
      "Epoch 1668/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8202.5214 - val_loss: 18928.4513\n",
      "Epoch 1669/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8584.6339 - val_loss: 18966.2854\n",
      "Epoch 1670/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8718.8208 - val_loss: 18880.4496\n",
      "Epoch 1671/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8850.0034 - val_loss: 19169.4154\n",
      "Epoch 1672/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8698.8641 - val_loss: 19363.2365\n",
      "Epoch 1673/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8200.6614 - val_loss: 18729.1244\n",
      "Epoch 1674/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8173.2757 - val_loss: 18690.3189\n",
      "Epoch 1675/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8559.4710 - val_loss: 18916.0493\n",
      "Epoch 1676/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9364.3526 - val_loss: 18735.7214\n",
      "Epoch 1677/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9373.4134 - val_loss: 19329.9660\n",
      "Epoch 1678/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8779.8295 - val_loss: 20716.1731\n",
      "Epoch 1679/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 11891.5678 - val_loss: 19486.0483\n",
      "Epoch 1680/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9557.8280 - val_loss: 18518.6900\n",
      "Epoch 1681/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8624.5180 - val_loss: 18791.2867\n",
      "Epoch 1682/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9143.6207 - val_loss: 18802.5624\n",
      "Epoch 1683/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9017.6103 - val_loss: 19874.1355\n",
      "Epoch 1684/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 10277.3858 - val_loss: 19922.5649\n",
      "Epoch 1685/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8465.8150 - val_loss: 18905.8541\n",
      "Epoch 1686/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8504.5375 - val_loss: 19234.6042\n",
      "Epoch 1687/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8908.5271 - val_loss: 20843.2873\n",
      "Epoch 1688/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 10257.3696 - val_loss: 19184.2545\n",
      "Epoch 1689/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8929.4733 - val_loss: 18666.5930\n",
      "Epoch 1690/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8438.8067 - val_loss: 18843.4880\n",
      "Epoch 1691/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8560.0931 - val_loss: 18870.8950\n",
      "Epoch 1692/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8757.0692 - val_loss: 19260.6514\n",
      "Epoch 1693/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8650.0349 - val_loss: 18612.8578\n",
      "Epoch 1694/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8772.4515 - val_loss: 19062.3170\n",
      "Epoch 1695/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8767.4131 - val_loss: 19647.7546\n",
      "Epoch 1696/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8993.7049 - val_loss: 18837.5249\n",
      "Epoch 1697/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8551.1502 - val_loss: 18671.7598\n",
      "Epoch 1698/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9756.6891 - val_loss: 19256.7674\n",
      "Epoch 1699/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8272.6112 - val_loss: 19206.3001\n",
      "Epoch 1700/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8347.4451 - val_loss: 20294.0291\n",
      "Epoch 1701/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10387.5278 - val_loss: 18764.1522\n",
      "Epoch 1702/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8687.5904 - val_loss: 19101.4279\n",
      "Epoch 1703/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8444.9428 - val_loss: 19309.0737\n",
      "Epoch 1704/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8938.9054 - val_loss: 18829.0416\n",
      "Epoch 1705/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9322.9316 - val_loss: 19260.7266\n",
      "Epoch 1706/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8878.8062 - val_loss: 19169.7269\n",
      "Epoch 1707/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8795.1205 - val_loss: 18766.6027\n",
      "Epoch 1708/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8895.1676 - val_loss: 18890.4060\n",
      "Epoch 1709/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9887.1597 - val_loss: 20553.8210\n",
      "Epoch 1710/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9789.7806 - val_loss: 18742.6958\n",
      "Epoch 1711/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9096.9816 - val_loss: 19212.7187\n",
      "Epoch 1712/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9582.6830 - val_loss: 18654.2055\n",
      "Epoch 1713/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8973.6413 - val_loss: 18821.5272\n",
      "Epoch 1714/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9123.6264 - val_loss: 19556.7330\n",
      "Epoch 1715/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9904.3140 - val_loss: 18715.2533\n",
      "Epoch 1716/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8625.8068 - val_loss: 18512.9054\n",
      "Epoch 1717/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8171.1302 - val_loss: 18732.2937\n",
      "Epoch 1718/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8251.8147 - val_loss: 19022.0163\n",
      "Epoch 1719/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9057.7230 - val_loss: 19012.0734\n",
      "Epoch 1720/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8954.5909 - val_loss: 19279.0621\n",
      "Epoch 1721/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9197.7854 - val_loss: 19321.4215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1722/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9118.4731 - val_loss: 19049.7518\n",
      "Epoch 1723/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9416.9643 - val_loss: 18772.5930\n",
      "Epoch 1724/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8484.9124 - val_loss: 19304.8127\n",
      "Epoch 1725/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8141.8519 - val_loss: 19070.1229\n",
      "Epoch 1726/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8874.5502 - val_loss: 18535.2944\n",
      "Epoch 1727/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9165.2097 - val_loss: 19206.1295\n",
      "Epoch 1728/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9318.9254 - val_loss: 19649.0113\n",
      "Epoch 1729/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 9735.6297 - val_loss: 18875.4484\n",
      "Epoch 1730/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9093.5729 - val_loss: 18747.1387\n",
      "Epoch 1731/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9596.1826 - val_loss: 18715.1240\n",
      "Epoch 1732/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9005.5096 - val_loss: 18716.3671\n",
      "Epoch 1733/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8532.4543 - val_loss: 18906.3374\n",
      "Epoch 1734/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8725.8584 - val_loss: 19062.9821\n",
      "Epoch 1735/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8913.3843 - val_loss: 21887.2322\n",
      "Epoch 1736/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11636.1077 - val_loss: 18986.7671\n",
      "Epoch 1737/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8832.8840 - val_loss: 18829.0816\n",
      "Epoch 1738/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8064.0133 - val_loss: 19563.1917\n",
      "Epoch 1739/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8858.0420 - val_loss: 20603.4656\n",
      "Epoch 1740/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9414.7783 - val_loss: 19179.9106\n",
      "Epoch 1741/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10510.4908 - val_loss: 20193.2834\n",
      "Epoch 1742/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8935.5083 - val_loss: 18587.0529\n",
      "Epoch 1743/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8513.3446 - val_loss: 18932.9594\n",
      "Epoch 1744/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8271.2202 - val_loss: 19604.5436\n",
      "Epoch 1745/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8861.3453 - val_loss: 18811.6492\n",
      "Epoch 1746/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8287.4570 - val_loss: 19657.0457\n",
      "Epoch 1747/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8607.3877 - val_loss: 18917.8219\n",
      "Epoch 1748/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8779.4213 - val_loss: 18792.8412\n",
      "Epoch 1749/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8442.2666 - val_loss: 18786.9569\n",
      "Epoch 1750/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8514.5858 - val_loss: 19252.7668\n",
      "Epoch 1751/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8954.6402 - val_loss: 19119.5084\n",
      "Epoch 1752/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8778.9051 - val_loss: 19007.0603\n",
      "Epoch 1753/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9005.5125 - val_loss: 18994.5131\n",
      "Epoch 1754/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8228.2439 - val_loss: 19148.4319\n",
      "Epoch 1755/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8248.1156 - val_loss: 18703.6132\n",
      "Epoch 1756/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7956.6819 - val_loss: 19425.1111\n",
      "Epoch 1757/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8060.9258 - val_loss: 20418.2868\n",
      "Epoch 1758/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 10195.1751 - val_loss: 18650.8239\n",
      "Epoch 1759/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9076.4877 - val_loss: 19980.1793\n",
      "Epoch 1760/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8911.5465 - val_loss: 18795.6172\n",
      "Epoch 1761/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8679.6030 - val_loss: 19365.6862\n",
      "Epoch 1762/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9081.6447 - val_loss: 18975.7716\n",
      "Epoch 1763/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8153.1050 - val_loss: 19004.4787\n",
      "Epoch 1764/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8389.6190 - val_loss: 18725.3744\n",
      "Epoch 1765/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8584.7083 - val_loss: 18795.6951\n",
      "Epoch 1766/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8741.1356 - val_loss: 18683.5894\n",
      "Epoch 1767/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8228.3938 - val_loss: 19001.3154\n",
      "Epoch 1768/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8268.6384 - val_loss: 19122.5271\n",
      "Epoch 1769/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 8614.8461 - val_loss: 19830.2331\n",
      "Epoch 1770/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8852.0491 - val_loss: 19803.4879\n",
      "Epoch 1771/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9546.0966 - val_loss: 18845.1594\n",
      "Epoch 1772/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8478.6910 - val_loss: 18692.9720\n",
      "Epoch 1773/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9226.0646 - val_loss: 18980.5194\n",
      "Epoch 1774/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9619.5720 - val_loss: 19340.2337\n",
      "Epoch 1775/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8412.1232 - val_loss: 19144.1743\n",
      "Epoch 1776/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8573.6232 - val_loss: 19118.0936\n",
      "Epoch 1777/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8543.2177 - val_loss: 18921.5165\n",
      "Epoch 1778/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8235.6200 - val_loss: 19358.1688\n",
      "Epoch 1779/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8692.1000 - val_loss: 21477.0935\n",
      "Epoch 1780/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9180.2592 - val_loss: 19282.6892\n",
      "Epoch 1781/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8204.6144 - val_loss: 19120.1034\n",
      "Epoch 1782/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8754.9107 - val_loss: 18760.1817\n",
      "Epoch 1783/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8569.0982 - val_loss: 18600.4316\n",
      "Epoch 1784/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8268.2171 - val_loss: 20129.2295\n",
      "Epoch 1785/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9337.5293 - val_loss: 19618.5723\n",
      "Epoch 1786/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9327.5272 - val_loss: 19258.5349\n",
      "Epoch 1787/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9038.9504 - val_loss: 18755.7969\n",
      "Epoch 1788/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8346.8458 - val_loss: 19252.2896\n",
      "Epoch 1789/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8552.8482 - val_loss: 19046.1778\n",
      "Epoch 1790/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8209.0821 - val_loss: 18967.5063\n",
      "Epoch 1791/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8965.6726 - val_loss: 18965.8145\n",
      "Epoch 1792/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8982.0820 - val_loss: 19218.4390\n",
      "Epoch 1793/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8105.9847 - val_loss: 18729.1708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1794/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9635.7406 - val_loss: 19200.7409\n",
      "Epoch 1795/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9267.0398 - val_loss: 18843.1244\n",
      "Epoch 1796/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9694.6789 - val_loss: 18686.6325\n",
      "Epoch 1797/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8302.9408 - val_loss: 18731.6743\n",
      "Epoch 1798/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8215.6879 - val_loss: 18767.9087\n",
      "Epoch 1799/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8317.2964 - val_loss: 19487.6489\n",
      "Epoch 1800/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8321.3450 - val_loss: 18721.1682\n",
      "Epoch 1801/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8329.4268 - val_loss: 19242.1546\n",
      "Epoch 1802/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8402.0917 - val_loss: 19665.5618\n",
      "Epoch 1803/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9758.2566 - val_loss: 19187.2128\n",
      "Epoch 1804/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9089.8486 - val_loss: 19224.8626\n",
      "Epoch 1805/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9394.3893 - val_loss: 19542.5996\n",
      "Epoch 1806/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9117.2033 - val_loss: 20517.8328\n",
      "Epoch 1807/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9637.5576 - val_loss: 19545.5156\n",
      "Epoch 1808/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8634.5293 - val_loss: 18980.0505\n",
      "Epoch 1809/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8027.5555 - val_loss: 18751.3486\n",
      "Epoch 1810/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9022.5672 - val_loss: 20447.0892\n",
      "Epoch 1811/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8687.4551 - val_loss: 19129.6521\n",
      "Epoch 1812/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8678.8009 - val_loss: 18957.8511\n",
      "Epoch 1813/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9092.0365 - val_loss: 19495.7418\n",
      "Epoch 1814/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9002.2388 - val_loss: 19036.3568\n",
      "Epoch 1815/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8788.5618 - val_loss: 19703.8669\n",
      "Epoch 1816/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9485.7753 - val_loss: 18919.9009\n",
      "Epoch 1817/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9151.8529 - val_loss: 18776.9603\n",
      "Epoch 1818/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8780.3074 - val_loss: 19214.6215\n",
      "Epoch 1819/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7922.1548 - val_loss: 19013.9926\n",
      "Epoch 1820/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8938.6070 - val_loss: 19165.8276\n",
      "Epoch 1821/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8446.3378 - val_loss: 18978.5095\n",
      "Epoch 1822/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8380.8003 - val_loss: 19317.5798\n",
      "Epoch 1823/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8646.6603 - val_loss: 18885.1240\n",
      "Epoch 1824/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8506.9500 - val_loss: 18868.8912\n",
      "Epoch 1825/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 8224.63 - 0s 137us/step - loss: 8204.8734 - val_loss: 19394.1402\n",
      "Epoch 1826/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8975.0381 - val_loss: 19521.7799\n",
      "Epoch 1827/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8582.2439 - val_loss: 19045.3711\n",
      "Epoch 1828/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8802.6903 - val_loss: 20658.2789\n",
      "Epoch 1829/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8401.7826 - val_loss: 19926.3278\n",
      "Epoch 1830/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8476.7040 - val_loss: 18497.6458\n",
      "Epoch 1831/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8699.2889 - val_loss: 19196.0915\n",
      "Epoch 1832/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8322.8204 - val_loss: 18884.2608\n",
      "Epoch 1833/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8416.8744 - val_loss: 19302.4253\n",
      "Epoch 1834/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8700.2141 - val_loss: 18666.0571\n",
      "Epoch 1835/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9299.2492 - val_loss: 19269.2724\n",
      "Epoch 1836/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8356.6828 - val_loss: 19042.9669\n",
      "Epoch 1837/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8469.1941 - val_loss: 19406.0759\n",
      "Epoch 1838/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8181.8095 - val_loss: 18782.4234\n",
      "Epoch 1839/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8084.3250 - val_loss: 19264.0102\n",
      "Epoch 1840/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8318.7185 - val_loss: 19279.3784\n",
      "Epoch 1841/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7934.5038 - val_loss: 18745.9217\n",
      "Epoch 1842/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8258.1480 - val_loss: 19323.5615\n",
      "Epoch 1843/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8225.0233 - val_loss: 19111.7713\n",
      "Epoch 1844/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9006.8375 - val_loss: 20734.0645\n",
      "Epoch 1845/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8525.4015 - val_loss: 18838.0601\n",
      "Epoch 1846/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8601.8316 - val_loss: 19005.8356\n",
      "Epoch 1847/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8519.8430 - val_loss: 19919.5721\n",
      "Epoch 1848/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8917.0479 - val_loss: 19090.5379\n",
      "Epoch 1849/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9142.7891 - val_loss: 19011.5634\n",
      "Epoch 1850/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7946.2347 - val_loss: 19635.3866\n",
      "Epoch 1851/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8470.8934 - val_loss: 18879.6420\n",
      "Epoch 1852/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8485.9729 - val_loss: 18839.6360\n",
      "Epoch 1853/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8311.2254 - val_loss: 18959.8894\n",
      "Epoch 1854/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9176.1251 - val_loss: 19191.9891\n",
      "Epoch 1855/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9130.6493 - val_loss: 18737.8210\n",
      "Epoch 1856/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8272.4944 - val_loss: 18833.1386\n",
      "Epoch 1857/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8243.4777 - val_loss: 18775.2864\n",
      "Epoch 1858/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8120.4553 - val_loss: 18857.3462\n",
      "Epoch 1859/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9060.9777 - val_loss: 18744.8942\n",
      "Epoch 1860/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9369.8202 - val_loss: 20546.0903\n",
      "Epoch 1861/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10047.0371 - val_loss: 19315.9381\n",
      "Epoch 1862/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8335.5083 - val_loss: 19191.9675\n",
      "Epoch 1863/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8872.9596 - val_loss: 19233.8161\n",
      "Epoch 1864/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9297.8938 - val_loss: 18995.7324\n",
      "Epoch 1865/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 145us/step - loss: 8799.2374 - val_loss: 19463.1785\n",
      "Epoch 1866/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9635.3350 - val_loss: 19045.0914\n",
      "Epoch 1867/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 11443.0547 - val_loss: 18947.5086\n",
      "Epoch 1868/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8474.5187 - val_loss: 19221.4191\n",
      "Epoch 1869/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8664.0378 - val_loss: 19877.6983\n",
      "Epoch 1870/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8384.6690 - val_loss: 18656.7370\n",
      "Epoch 1871/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8166.6034 - val_loss: 18937.3969\n",
      "Epoch 1872/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8421.1418 - val_loss: 19267.7812\n",
      "Epoch 1873/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8913.9968 - val_loss: 18801.6898\n",
      "Epoch 1874/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8011.7732 - val_loss: 19430.1326\n",
      "Epoch 1875/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9553.0233 - val_loss: 18991.0091\n",
      "Epoch 1876/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8179.6196 - val_loss: 18756.2837\n",
      "Epoch 1877/3000\n",
      "995/995 [==============================] - 0s 181us/step - loss: 8740.1640 - val_loss: 19020.6736\n",
      "Epoch 1878/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7856.0246 - val_loss: 20219.3202\n",
      "Epoch 1879/3000\n",
      "995/995 [==============================] - 0s 189us/step - loss: 8764.5729 - val_loss: 19634.3651\n",
      "Epoch 1880/3000\n",
      "995/995 [==============================] - 0s 209us/step - loss: 9186.5289 - val_loss: 19015.0331\n",
      "Epoch 1881/3000\n",
      "995/995 [==============================] - 0s 189us/step - loss: 9400.5360 - val_loss: 20539.6767\n",
      "Epoch 1882/3000\n",
      "995/995 [==============================] - 0s 189us/step - loss: 9402.8977 - val_loss: 18762.9579\n",
      "Epoch 1883/3000\n",
      "995/995 [==============================] - 0s 181us/step - loss: 8609.6737 - val_loss: 18708.6804\n",
      "Epoch 1884/3000\n",
      "995/995 [==============================] - 0s 177us/step - loss: 8516.1688 - val_loss: 20792.2349\n",
      "Epoch 1885/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 11799.9140 - val_loss: 19337.8517\n",
      "Epoch 1886/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8797.5849 - val_loss: 18796.0079\n",
      "Epoch 1887/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 8478.0507 - val_loss: 20473.4806\n",
      "Epoch 1888/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10042.3472 - val_loss: 19220.7327\n",
      "Epoch 1889/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9034.5004 - val_loss: 18738.8051\n",
      "Epoch 1890/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8969.6178 - val_loss: 19068.8079\n",
      "Epoch 1891/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8549.1752 - val_loss: 18937.8992\n",
      "Epoch 1892/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9180.2361 - val_loss: 20088.0111\n",
      "Epoch 1893/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8883.5811 - val_loss: 18872.0279\n",
      "Epoch 1894/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8102.9088 - val_loss: 19332.4667\n",
      "Epoch 1895/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8331.7947 - val_loss: 19491.6421\n",
      "Epoch 1896/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8143.9923 - val_loss: 20452.5240\n",
      "Epoch 1897/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11299.8000 - val_loss: 19009.8986\n",
      "Epoch 1898/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8984.2027 - val_loss: 19280.5914\n",
      "Epoch 1899/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 8322.35 - 0s 137us/step - loss: 8354.5643 - val_loss: 19033.6182\n",
      "Epoch 1900/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8192.5527 - val_loss: 18482.7751\n",
      "Epoch 1901/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8198.4925 - val_loss: 19260.0507\n",
      "Epoch 1902/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8142.2208 - val_loss: 20137.5297\n",
      "Epoch 1903/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9126.8708 - val_loss: 18519.0017\n",
      "Epoch 1904/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8433.2447 - val_loss: 19962.2333\n",
      "Epoch 1905/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8699.2098 - val_loss: 19293.7786\n",
      "Epoch 1906/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8507.8152 - val_loss: 21378.8750\n",
      "Epoch 1907/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9020.6005 - val_loss: 19032.0750\n",
      "Epoch 1908/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8250.4099 - val_loss: 19087.6748\n",
      "Epoch 1909/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7912.0793 - val_loss: 19008.1710\n",
      "Epoch 1910/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8001.3226 - val_loss: 18805.0030\n",
      "Epoch 1911/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9343.0562 - val_loss: 18777.0350\n",
      "Epoch 1912/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8300.3560 - val_loss: 18894.5467\n",
      "Epoch 1913/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8055.7430 - val_loss: 19756.5262\n",
      "Epoch 1914/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8651.6408 - val_loss: 18951.3172\n",
      "Epoch 1915/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8293.3730 - val_loss: 19205.2571\n",
      "Epoch 1916/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9394.9653 - val_loss: 18675.1400\n",
      "Epoch 1917/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8172.9959 - val_loss: 19255.8814\n",
      "Epoch 1918/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8569.1206 - val_loss: 19555.8302\n",
      "Epoch 1919/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8458.9417 - val_loss: 20006.9789\n",
      "Epoch 1920/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8224.4187 - val_loss: 19025.1742\n",
      "Epoch 1921/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8073.8802 - val_loss: 19038.7835\n",
      "Epoch 1922/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 9308.57 - 0s 141us/step - loss: 9285.6574 - val_loss: 18683.4345\n",
      "Epoch 1923/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8749.3054 - val_loss: 20267.0276\n",
      "Epoch 1924/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8322.6620 - val_loss: 19196.2970\n",
      "Epoch 1925/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9600.1494 - val_loss: 18853.0942\n",
      "Epoch 1926/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8592.7839 - val_loss: 18745.4373\n",
      "Epoch 1927/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9001.4792 - val_loss: 18867.5305\n",
      "Epoch 1928/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8760.1314 - val_loss: 18761.4640\n",
      "Epoch 1929/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8699.2908 - val_loss: 19053.3916\n",
      "Epoch 1930/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8344.3349 - val_loss: 19897.9885\n",
      "Epoch 1931/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8780.8979 - val_loss: 18467.1487\n",
      "Epoch 1932/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8198.9077 - val_loss: 20707.8436\n",
      "Epoch 1933/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9276.5268 - val_loss: 18771.6615\n",
      "Epoch 1934/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9070.9980 - val_loss: 19002.3922\n",
      "Epoch 1935/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 7979.3269 - val_loss: 19033.5270\n",
      "Epoch 1936/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 177us/step - loss: 8359.4066 - val_loss: 18945.6787\n",
      "Epoch 1937/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8496.7075 - val_loss: 19647.4760\n",
      "Epoch 1938/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8544.8643 - val_loss: 18518.7351\n",
      "Epoch 1939/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7921.3354 - val_loss: 18605.7426\n",
      "Epoch 1940/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7698.4221 - val_loss: 18700.9140\n",
      "Epoch 1941/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8384.5090 - val_loss: 19077.0095\n",
      "Epoch 1942/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9171.0986 - val_loss: 18995.3691\n",
      "Epoch 1943/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8808.9381 - val_loss: 19047.5972\n",
      "Epoch 1944/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7818.3343 - val_loss: 18715.2649\n",
      "Epoch 1945/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8189.2683 - val_loss: 18887.1731\n",
      "Epoch 1946/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9963.3331 - val_loss: 18693.8731\n",
      "Epoch 1947/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8414.3282 - val_loss: 18766.2937\n",
      "Epoch 1948/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8233.3753 - val_loss: 18821.4757\n",
      "Epoch 1949/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8453.7103 - val_loss: 18602.7833\n",
      "Epoch 1950/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8722.5979 - val_loss: 18679.2526\n",
      "Epoch 1951/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7868.8684 - val_loss: 18771.9279\n",
      "Epoch 1952/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8606.2238 - val_loss: 18609.1453\n",
      "Epoch 1953/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8217.0596 - val_loss: 19042.7347\n",
      "Epoch 1954/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9178.8062 - val_loss: 18724.7728\n",
      "Epoch 1955/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8309.6360 - val_loss: 18923.6256\n",
      "Epoch 1956/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8282.2853 - val_loss: 19861.8436\n",
      "Epoch 1957/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9839.6528 - val_loss: 19346.1349\n",
      "Epoch 1958/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9104.4315 - val_loss: 19327.2494\n",
      "Epoch 1959/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8482.3776 - val_loss: 19321.6183\n",
      "Epoch 1960/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8237.8359 - val_loss: 19309.7619\n",
      "Epoch 1961/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8237.1953 - val_loss: 19704.0655\n",
      "Epoch 1962/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9005.5481 - val_loss: 19128.6857\n",
      "Epoch 1963/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8175.0914 - val_loss: 18703.3967\n",
      "Epoch 1964/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7977.2575 - val_loss: 18910.8921\n",
      "Epoch 1965/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7972.5624 - val_loss: 20264.6607\n",
      "Epoch 1966/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9738.4633 - val_loss: 18908.5389\n",
      "Epoch 1967/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8316.5241 - val_loss: 18845.1665\n",
      "Epoch 1968/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9534.5478 - val_loss: 19575.4486\n",
      "Epoch 1969/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8403.5633 - val_loss: 18819.0675\n",
      "Epoch 1970/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8642.9377 - val_loss: 18836.5131\n",
      "Epoch 1971/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8545.7339 - val_loss: 18620.0362\n",
      "Epoch 1972/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7875.2821 - val_loss: 19434.9648\n",
      "Epoch 1973/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7903.3363 - val_loss: 18955.1838\n",
      "Epoch 1974/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8745.8134 - val_loss: 19148.1500\n",
      "Epoch 1975/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8332.6655 - val_loss: 19345.2303\n",
      "Epoch 1976/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8988.4331 - val_loss: 19107.4624\n",
      "Epoch 1977/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8347.6006 - val_loss: 19178.3761\n",
      "Epoch 1978/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8655.7967 - val_loss: 18633.0972\n",
      "Epoch 1979/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8315.7604 - val_loss: 18688.5711\n",
      "Epoch 1980/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7852.4967 - val_loss: 20450.7020\n",
      "Epoch 1981/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9255.3191 - val_loss: 19069.3303\n",
      "Epoch 1982/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 9796.6970 - val_loss: 18654.0886\n",
      "Epoch 1983/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 8575.5218 - val_loss: 18808.1228\n",
      "Epoch 1984/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 9024.1444 - val_loss: 19015.9815\n",
      "Epoch 1985/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7810.2704 - val_loss: 18623.0483\n",
      "Epoch 1986/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8044.2439 - val_loss: 18723.4109\n",
      "Epoch 1987/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7814.9710 - val_loss: 18715.2582\n",
      "Epoch 1988/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8498.6487 - val_loss: 18907.1147\n",
      "Epoch 1989/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10838.2973 - val_loss: 18830.7095\n",
      "Epoch 1990/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9215.0738 - val_loss: 18475.8484\n",
      "Epoch 1991/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9468.4443 - val_loss: 18950.1484\n",
      "Epoch 1992/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8142.0744 - val_loss: 18685.5474\n",
      "Epoch 1993/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9257.9301 - val_loss: 18299.7518\n",
      "Epoch 1994/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8242.2696 - val_loss: 18486.5472\n",
      "Epoch 1995/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8537.7877 - val_loss: 18910.4484\n",
      "Epoch 1996/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 7923.05 - 0s 149us/step - loss: 7835.9478 - val_loss: 18683.1359\n",
      "Epoch 1997/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7769.4115 - val_loss: 19042.1228\n",
      "Epoch 1998/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8050.5979 - val_loss: 19108.9734\n",
      "Epoch 1999/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8593.3772 - val_loss: 18658.0319\n",
      "Epoch 2000/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8501.3309 - val_loss: 18351.0051\n",
      "Epoch 2001/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8433.4251 - val_loss: 19475.3135\n",
      "Epoch 2002/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8445.4474 - val_loss: 18532.2461\n",
      "Epoch 2003/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8634.9596 - val_loss: 18535.2484\n",
      "Epoch 2004/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8519.3453 - val_loss: 18958.9346\n",
      "Epoch 2005/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7913.0323 - val_loss: 18698.6756\n",
      "Epoch 2006/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8274.1256 - val_loss: 18463.6764\n",
      "Epoch 2007/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8316.6630 - val_loss: 18598.8447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2008/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8859.5384 - val_loss: 18671.9035\n",
      "Epoch 2009/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8888.5076 - val_loss: 18385.3518\n",
      "Epoch 2010/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7930.4345 - val_loss: 18708.2136\n",
      "Epoch 2011/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8493.1076 - val_loss: 18654.5824\n",
      "Epoch 2012/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8119.6704 - val_loss: 18970.9905\n",
      "Epoch 2013/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7986.3130 - val_loss: 18921.4296\n",
      "Epoch 2014/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8755.7985 - val_loss: 18749.8566\n",
      "Epoch 2015/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7990.9496 - val_loss: 18628.9965\n",
      "Epoch 2016/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7866.0957 - val_loss: 18660.6328\n",
      "Epoch 2017/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8271.1194 - val_loss: 18529.1147\n",
      "Epoch 2018/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7934.7372 - val_loss: 18344.5959\n",
      "Epoch 2019/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7656.9892 - val_loss: 18731.4706\n",
      "Epoch 2020/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7793.6721 - val_loss: 18959.4202\n",
      "Epoch 2021/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8285.9327 - val_loss: 18776.2955\n",
      "Epoch 2022/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8500.2641 - val_loss: 18320.6369\n",
      "Epoch 2023/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8683.8269 - val_loss: 18775.0145\n",
      "Epoch 2024/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8193.7557 - val_loss: 19412.2272\n",
      "Epoch 2025/3000\n",
      "995/995 [==============================] - 0s 108us/step - loss: 8734.0685 - val_loss: 18691.2006\n",
      "Epoch 2026/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9173.6133 - val_loss: 18477.8210\n",
      "Epoch 2027/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7519.0534 - val_loss: 19741.7905\n",
      "Epoch 2028/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8283.3002 - val_loss: 19592.8471\n",
      "Epoch 2029/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8795.1774 - val_loss: 18717.4345\n",
      "Epoch 2030/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8289.4893 - val_loss: 18676.9718\n",
      "Epoch 2031/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7795.5831 - val_loss: 18389.8410\n",
      "Epoch 2032/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7899.1766 - val_loss: 18744.2380\n",
      "Epoch 2033/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8669.6015 - val_loss: 18522.3021\n",
      "Epoch 2034/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7835.1989 - val_loss: 18224.3536\n",
      "Epoch 2035/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9824.7560 - val_loss: 18353.3966\n",
      "Epoch 2036/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8078.2606 - val_loss: 18357.5063\n",
      "Epoch 2037/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8050.0602 - val_loss: 18769.9143\n",
      "Epoch 2038/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8972.4294 - val_loss: 22120.5764\n",
      "Epoch 2039/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10110.3060 - val_loss: 18476.1775\n",
      "Epoch 2040/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8463.9138 - val_loss: 20023.0054\n",
      "Epoch 2041/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8565.7008 - val_loss: 20467.5465\n",
      "Epoch 2042/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10132.4299 - val_loss: 18768.6473\n",
      "Epoch 2043/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7896.1317 - val_loss: 18760.2033\n",
      "Epoch 2044/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8225.2287 - val_loss: 19766.2677\n",
      "Epoch 2045/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9454.5114 - val_loss: 19114.6579\n",
      "Epoch 2046/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8450.4242 - val_loss: 19006.4363\n",
      "Epoch 2047/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7962.1353 - val_loss: 18938.2352\n",
      "Epoch 2048/3000\n",
      "995/995 [==============================] - 0s 183us/step - loss: 8045.1446 - val_loss: 18548.5379\n",
      "Epoch 2049/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7837.4068 - val_loss: 18844.6300\n",
      "Epoch 2050/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7950.8786 - val_loss: 19328.0167\n",
      "Epoch 2051/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8942.2234 - val_loss: 18499.0092\n",
      "Epoch 2052/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7792.4395 - val_loss: 20862.8210\n",
      "Epoch 2053/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9845.7523 - val_loss: 18647.0707\n",
      "Epoch 2054/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8336.7034 - val_loss: 18510.5775\n",
      "Epoch 2055/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7744.2367 - val_loss: 18661.8849\n",
      "Epoch 2056/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8354.7005 - val_loss: 18971.1819\n",
      "Epoch 2057/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8166.2537 - val_loss: 18567.8184\n",
      "Epoch 2058/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7618.9518 - val_loss: 19000.2004\n",
      "Epoch 2059/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8376.5053 - val_loss: 18715.6175\n",
      "Epoch 2060/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7618.5275 - val_loss: 18708.1531\n",
      "Epoch 2061/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8056.7995 - val_loss: 20529.3548\n",
      "Epoch 2062/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8788.4094 - val_loss: 18582.3694\n",
      "Epoch 2063/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8505.3263 - val_loss: 18648.6971\n",
      "Epoch 2064/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7963.0108 - val_loss: 19799.0028\n",
      "Epoch 2065/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8880.1359 - val_loss: 19160.2465\n",
      "Epoch 2066/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8181.8862 - val_loss: 18626.3697\n",
      "Epoch 2067/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9009.9605 - val_loss: 18707.3395\n",
      "Epoch 2068/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9070.9402 - val_loss: 18723.2742\n",
      "Epoch 2069/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8305.0911 - val_loss: 21814.5804\n",
      "Epoch 2070/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9301.2600 - val_loss: 18686.5126\n",
      "Epoch 2071/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7796.3457 - val_loss: 19558.2743\n",
      "Epoch 2072/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 9016.3289 - val_loss: 18999.9365\n",
      "Epoch 2073/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8412.4932 - val_loss: 19053.3633\n",
      "Epoch 2074/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8573.8112 - val_loss: 18906.3396\n",
      "Epoch 2075/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7912.1200 - val_loss: 18823.0470\n",
      "Epoch 2076/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7917.3644 - val_loss: 18505.5012\n",
      "Epoch 2077/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7587.9138 - val_loss: 18941.8421\n",
      "Epoch 2078/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8196.3658 - val_loss: 19250.2330\n",
      "Epoch 2079/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9218.9137 - val_loss: 18435.4452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2080/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8372.9251 - val_loss: 18872.0903\n",
      "Epoch 2081/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8166.0202 - val_loss: 18687.7125\n",
      "Epoch 2082/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7970.9700 - val_loss: 19537.7263\n",
      "Epoch 2083/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8106.7806 - val_loss: 18684.1986\n",
      "Epoch 2084/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7996.7992 - val_loss: 18881.8253\n",
      "Epoch 2085/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7910.1283 - val_loss: 19228.3682\n",
      "Epoch 2086/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9988.9800 - val_loss: 18933.1166\n",
      "Epoch 2087/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8597.5214 - val_loss: 19102.0561\n",
      "Epoch 2088/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7986.5335 - val_loss: 18682.4198\n",
      "Epoch 2089/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8170.2048 - val_loss: 19033.2483\n",
      "Epoch 2090/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8355.4760 - val_loss: 19522.9849\n",
      "Epoch 2091/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9459.2430 - val_loss: 19075.1356\n",
      "Epoch 2092/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8804.5078 - val_loss: 18502.4717\n",
      "Epoch 2093/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8200.8925 - val_loss: 20267.7304\n",
      "Epoch 2094/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9306.6644 - val_loss: 19251.6770\n",
      "Epoch 2095/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9314.5697 - val_loss: 18899.8260\n",
      "Epoch 2096/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7662.1010 - val_loss: 19299.9920\n",
      "Epoch 2097/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7930.2893 - val_loss: 19554.3063\n",
      "Epoch 2098/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8268.3612 - val_loss: 18729.6938\n",
      "Epoch 2099/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7893.6709 - val_loss: 18901.8438\n",
      "Epoch 2100/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8187.7921 - val_loss: 18782.4663\n",
      "Epoch 2101/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8591.3213 - val_loss: 18575.9886\n",
      "Epoch 2102/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7897.2040 - val_loss: 18796.8818\n",
      "Epoch 2103/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9220.8262 - val_loss: 18448.2569\n",
      "Epoch 2104/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7837.0652 - val_loss: 18855.8370\n",
      "Epoch 2105/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7430.6328 - val_loss: 18810.0352\n",
      "Epoch 2106/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8056.0238 - val_loss: 18947.3313\n",
      "Epoch 2107/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8015.8166 - val_loss: 18911.2856\n",
      "Epoch 2108/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8528.3334 - val_loss: 18502.8283\n",
      "Epoch 2109/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7620.7125 - val_loss: 20333.8051\n",
      "Epoch 2110/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8980.9467 - val_loss: 19484.1899\n",
      "Epoch 2111/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9203.7001 - val_loss: 18998.9466\n",
      "Epoch 2112/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8135.0030 - val_loss: 18541.9828\n",
      "Epoch 2113/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8369.6593 - val_loss: 18489.9916\n",
      "Epoch 2114/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8284.5602 - val_loss: 18627.6012\n",
      "Epoch 2115/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7846.7352 - val_loss: 18343.3402\n",
      "Epoch 2116/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8585.7522 - val_loss: 18734.3581\n",
      "Epoch 2117/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8465.7322 - val_loss: 18930.2555\n",
      "Epoch 2118/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8882.8491 - val_loss: 19940.4772\n",
      "Epoch 2119/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8406.3986 - val_loss: 18970.2887\n",
      "Epoch 2120/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8576.5296 - val_loss: 18650.3345\n",
      "Epoch 2121/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7850.9558 - val_loss: 18686.6877\n",
      "Epoch 2122/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7887.3929 - val_loss: 18752.5471\n",
      "Epoch 2123/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7985.1557 - val_loss: 19342.8677\n",
      "Epoch 2124/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7580.9125 - val_loss: 18757.9108\n",
      "Epoch 2125/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7798.5236 - val_loss: 19304.1851\n",
      "Epoch 2126/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9720.2577 - val_loss: 18708.5036\n",
      "Epoch 2127/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10615.1736 - val_loss: 18148.5364\n",
      "Epoch 2128/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8229.4446 - val_loss: 18864.4047\n",
      "Epoch 2129/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8504.5366 - val_loss: 18855.4848\n",
      "Epoch 2130/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8862.0816 - val_loss: 18756.9917\n",
      "Epoch 2131/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8195.3083 - val_loss: 18802.4300\n",
      "Epoch 2132/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8418.4076 - val_loss: 18898.7711\n",
      "Epoch 2133/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8607.5652 - val_loss: 18653.2475\n",
      "Epoch 2134/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8482.7905 - val_loss: 19065.7992\n",
      "Epoch 2135/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8126.6236 - val_loss: 19100.4628\n",
      "Epoch 2136/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 10447.8311 - val_loss: 18949.6810\n",
      "Epoch 2137/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7609.8221 - val_loss: 18838.9739\n",
      "Epoch 2138/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7865.1795 - val_loss: 18813.2062\n",
      "Epoch 2139/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8081.5662 - val_loss: 19489.4105\n",
      "Epoch 2140/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8013.8364 - val_loss: 18678.1327\n",
      "Epoch 2141/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8784.8762 - val_loss: 18833.1132\n",
      "Epoch 2142/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9280.2991 - val_loss: 18502.5401\n",
      "Epoch 2143/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7460.6684 - val_loss: 18671.5227\n",
      "Epoch 2144/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7637.3907 - val_loss: 18955.2975\n",
      "Epoch 2145/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7737.4432 - val_loss: 18822.3203\n",
      "Epoch 2146/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8140.2231 - val_loss: 18513.6422\n",
      "Epoch 2147/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7698.8194 - val_loss: 18529.1303\n",
      "Epoch 2148/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8102.3870 - val_loss: 18584.0854\n",
      "Epoch 2149/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7690.1269 - val_loss: 18754.6251\n",
      "Epoch 2150/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7990.2674 - val_loss: 18486.1200\n",
      "Epoch 2151/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7876.0913 - val_loss: 19059.3989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2152/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8380.3586 - val_loss: 18422.5009\n",
      "Epoch 2153/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7871.3192 - val_loss: 18671.2688\n",
      "Epoch 2154/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7685.8919 - val_loss: 19439.5110\n",
      "Epoch 2155/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9860.0508 - val_loss: 20700.3361\n",
      "Epoch 2156/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8550.5968 - val_loss: 18601.3797\n",
      "Epoch 2157/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7897.7083 - val_loss: 18452.9821\n",
      "Epoch 2158/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7603.8517 - val_loss: 18561.3707\n",
      "Epoch 2159/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7854.9212 - val_loss: 19243.9098\n",
      "Epoch 2160/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8292.2850 - val_loss: 18955.4461\n",
      "Epoch 2161/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9048.0923 - val_loss: 19732.2421\n",
      "Epoch 2162/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9206.1053 - val_loss: 19220.6845\n",
      "Epoch 2163/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8037.2273 - val_loss: 18651.1084\n",
      "Epoch 2164/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7697.0355 - val_loss: 19607.9602\n",
      "Epoch 2165/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8984.4767 - val_loss: 18531.3468\n",
      "Epoch 2166/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7903.6370 - val_loss: 19193.9572\n",
      "Epoch 2167/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7798.7547 - val_loss: 18608.5857\n",
      "Epoch 2168/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7706.5912 - val_loss: 18654.4956\n",
      "Epoch 2169/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7788.9254 - val_loss: 18737.0259\n",
      "Epoch 2170/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8130.2188 - val_loss: 18936.4522\n",
      "Epoch 2171/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8860.5536 - val_loss: 18779.3049\n",
      "Epoch 2172/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8704.5872 - val_loss: 18839.9911\n",
      "Epoch 2173/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8377.2458 - val_loss: 18682.8127\n",
      "Epoch 2174/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8038.0960 - val_loss: 19826.6243\n",
      "Epoch 2175/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8856.5806 - val_loss: 19164.9858\n",
      "Epoch 2176/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8825.2922 - val_loss: 18651.4670\n",
      "Epoch 2177/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8100.0941 - val_loss: 18578.2380\n",
      "Epoch 2178/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9427.2218 - val_loss: 18797.7539\n",
      "Epoch 2179/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8294.5218 - val_loss: 19042.6783\n",
      "Epoch 2180/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8098.9968 - val_loss: 18569.8980\n",
      "Epoch 2181/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8672.5998 - val_loss: 20976.5971\n",
      "Epoch 2182/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 10910.9409 - val_loss: 20824.5114\n",
      "Epoch 2183/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 10630.4978 - val_loss: 18523.8414\n",
      "Epoch 2184/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 9151.3346 - val_loss: 18682.6970\n",
      "Epoch 2185/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8397.9229 - val_loss: 19422.5200\n",
      "Epoch 2186/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8850.6045 - val_loss: 18370.4971\n",
      "Epoch 2187/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7435.2201 - val_loss: 18771.0151\n",
      "Epoch 2188/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7934.3884 - val_loss: 18854.7955\n",
      "Epoch 2189/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7470.1862 - val_loss: 19308.8286\n",
      "Epoch 2190/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8205.5819 - val_loss: 18587.7925\n",
      "Epoch 2191/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7693.1537 - val_loss: 18318.8591\n",
      "Epoch 2192/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7569.9112 - val_loss: 18555.0876\n",
      "Epoch 2193/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7780.9608 - val_loss: 19196.4633\n",
      "Epoch 2194/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7997.7351 - val_loss: 18838.4342\n",
      "Epoch 2195/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7723.2204 - val_loss: 19586.5070\n",
      "Epoch 2196/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9000.1299 - val_loss: 18734.1617\n",
      "Epoch 2197/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9034.5573 - val_loss: 22426.2553\n",
      "Epoch 2198/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9631.5661 - val_loss: 18583.4137\n",
      "Epoch 2199/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8184.0641 - val_loss: 18579.2067\n",
      "Epoch 2200/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7782.9528 - val_loss: 18881.0897\n",
      "Epoch 2201/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8095.9139 - val_loss: 18333.7328\n",
      "Epoch 2202/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9754.4919 - val_loss: 19096.0264\n",
      "Epoch 2203/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8803.3905 - val_loss: 18592.6136\n",
      "Epoch 2204/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8076.6807 - val_loss: 18336.8425\n",
      "Epoch 2205/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7722.6241 - val_loss: 19062.5648\n",
      "Epoch 2206/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8685.9616 - val_loss: 18725.5560\n",
      "Epoch 2207/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8573.8538 - val_loss: 18892.1683\n",
      "Epoch 2208/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7451.8093 - val_loss: 18623.4079\n",
      "Epoch 2209/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7505.3922 - val_loss: 19040.9156\n",
      "Epoch 2210/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7863.0310 - val_loss: 19586.1259\n",
      "Epoch 2211/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7707.1562 - val_loss: 18639.1853\n",
      "Epoch 2212/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7494.0517 - val_loss: 18507.8964\n",
      "Epoch 2213/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7668.0855 - val_loss: 19121.7860\n",
      "Epoch 2214/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8260.7000 - val_loss: 19166.5253\n",
      "Epoch 2215/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8024.5997 - val_loss: 19310.3087\n",
      "Epoch 2216/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8464.2462 - val_loss: 19029.0273\n",
      "Epoch 2217/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8229.7343 - val_loss: 18464.5850\n",
      "Epoch 2218/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8357.3545 - val_loss: 18830.3498\n",
      "Epoch 2219/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8048.3941 - val_loss: 18576.1013\n",
      "Epoch 2220/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7759.6715 - val_loss: 18814.9711\n",
      "Epoch 2221/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8170.6840 - val_loss: 18485.4374\n",
      "Epoch 2222/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8119.3753 - val_loss: 18515.2442\n",
      "Epoch 2223/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7489.0276 - val_loss: 18465.6599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2224/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7593.0459 - val_loss: 18700.1442\n",
      "Epoch 2225/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7814.1369 - val_loss: 19196.3057\n",
      "Epoch 2226/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8589.0031 - val_loss: 18682.7770\n",
      "Epoch 2227/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8141.9975 - val_loss: 18712.8933\n",
      "Epoch 2228/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9074.7965 - val_loss: 18358.5421\n",
      "Epoch 2229/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8463.4230 - val_loss: 19311.0174\n",
      "Epoch 2230/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8464.5808 - val_loss: 18695.6216\n",
      "Epoch 2231/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9061.3109 - val_loss: 20034.9405\n",
      "Epoch 2232/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9237.9407 - val_loss: 18592.9750\n",
      "Epoch 2233/3000\n",
      "995/995 [==============================] - 0s 104us/step - loss: 7909.9247 - val_loss: 18937.6658\n",
      "Epoch 2234/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8260.4709 - val_loss: 18541.1315\n",
      "Epoch 2235/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8819.5598 - val_loss: 18622.7642\n",
      "Epoch 2236/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8331.0000 - val_loss: 18696.1121\n",
      "Epoch 2237/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8843.7994 - val_loss: 18733.4878\n",
      "Epoch 2238/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7502.2091 - val_loss: 18573.5313\n",
      "Epoch 2239/3000\n",
      "995/995 [==============================] - 0s 181us/step - loss: 7562.2393 - val_loss: 19325.5905\n",
      "Epoch 2240/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8959.1629 - val_loss: 18990.5173\n",
      "Epoch 2241/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8525.4314 - val_loss: 18490.9972\n",
      "Epoch 2242/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8432.6581 - val_loss: 18617.1914\n",
      "Epoch 2243/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8625.2784 - val_loss: 19575.1876\n",
      "Epoch 2244/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8474.2735 - val_loss: 19856.1882\n",
      "Epoch 2245/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8550.4627 - val_loss: 18735.7047\n",
      "Epoch 2246/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7385.8507 - val_loss: 18513.0374\n",
      "Epoch 2247/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7532.7448 - val_loss: 18540.4621\n",
      "Epoch 2248/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7957.1038 - val_loss: 18578.6838\n",
      "Epoch 2249/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7797.7100 - val_loss: 18757.8170\n",
      "Epoch 2250/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9045.8054 - val_loss: 19223.5631\n",
      "Epoch 2251/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7413.1686 - val_loss: 18257.5545\n",
      "Epoch 2252/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8398.8713 - val_loss: 19551.7624\n",
      "Epoch 2253/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7664.5342 - val_loss: 18893.4374\n",
      "Epoch 2254/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7691.1641 - val_loss: 18619.6258\n",
      "Epoch 2255/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7268.9490 - val_loss: 18542.1527\n",
      "Epoch 2256/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8023.1840 - val_loss: 18425.1213\n",
      "Epoch 2257/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 8159.7024 - val_loss: 18815.6792\n",
      "Epoch 2258/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8216.6350 - val_loss: 18765.9319\n",
      "Epoch 2259/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7734.8596 - val_loss: 18775.2790\n",
      "Epoch 2260/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7663.7302 - val_loss: 18680.4924\n",
      "Epoch 2261/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7994.0848 - val_loss: 18727.5425\n",
      "Epoch 2262/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7734.4938 - val_loss: 19206.0514\n",
      "Epoch 2263/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9061.6597 - val_loss: 18564.1732\n",
      "Epoch 2264/3000\n",
      "995/995 [==============================] - 0s 108us/step - loss: 7345.3605 - val_loss: 18330.0807\n",
      "Epoch 2265/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7858.2479 - val_loss: 20478.9688\n",
      "Epoch 2266/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8318.8693 - val_loss: 18805.1180\n",
      "Epoch 2267/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7751.4773 - val_loss: 18937.5411\n",
      "Epoch 2268/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9093.7075 - val_loss: 21225.5872\n",
      "Epoch 2269/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8909.2708 - val_loss: 19612.7486\n",
      "Epoch 2270/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9012.0810 - val_loss: 19027.2962\n",
      "Epoch 2271/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9130.5615 - val_loss: 19098.6447\n",
      "Epoch 2272/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8430.3490 - val_loss: 18805.2912\n",
      "Epoch 2273/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8014.0708 - val_loss: 18742.2663\n",
      "Epoch 2274/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8450.4253 - val_loss: 18218.0228\n",
      "Epoch 2275/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8329.7524 - val_loss: 18798.4002\n",
      "Epoch 2276/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8947.4317 - val_loss: 18242.6982\n",
      "Epoch 2277/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7879.2659 - val_loss: 18440.1301\n",
      "Epoch 2278/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7902.6885 - val_loss: 18418.2659\n",
      "Epoch 2279/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8031.0810 - val_loss: 20378.4638\n",
      "Epoch 2280/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10070.6583 - val_loss: 18472.4354\n",
      "Epoch 2281/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8204.8821 - val_loss: 18738.4972\n",
      "Epoch 2282/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7372.2805 - val_loss: 18616.8693\n",
      "Epoch 2283/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7290.1540 - val_loss: 19435.3234\n",
      "Epoch 2284/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8176.1686 - val_loss: 18393.2713\n",
      "Epoch 2285/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8532.5636 - val_loss: 18893.6215\n",
      "Epoch 2286/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7750.5174 - val_loss: 18944.3584\n",
      "Epoch 2287/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7988.3058 - val_loss: 18901.0655\n",
      "Epoch 2288/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8220.4043 - val_loss: 18758.6462\n",
      "Epoch 2289/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8383.8459 - val_loss: 20330.5655\n",
      "Epoch 2290/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9579.0602 - val_loss: 18470.7866\n",
      "Epoch 2291/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8158.5219 - val_loss: 18359.0402\n",
      "Epoch 2292/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7963.4098 - val_loss: 19001.5481\n",
      "Epoch 2293/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8824.6531 - val_loss: 18979.5779\n",
      "Epoch 2294/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7517.6172 - val_loss: 18674.6773\n",
      "Epoch 2295/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7575.3959 - val_loss: 18910.4311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2296/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8422.6813 - val_loss: 18792.6671\n",
      "Epoch 2297/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7855.5081 - val_loss: 18377.6440\n",
      "Epoch 2298/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8527.2097 - val_loss: 19332.3087\n",
      "Epoch 2299/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7794.2083 - val_loss: 18899.1691\n",
      "Epoch 2300/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7836.1699 - val_loss: 19120.1242\n",
      "Epoch 2301/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7649.9445 - val_loss: 18545.8859\n",
      "Epoch 2302/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8923.6465 - val_loss: 18305.0775\n",
      "Epoch 2303/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7968.5974 - val_loss: 18444.7332\n",
      "Epoch 2304/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8296.7037 - val_loss: 20093.6743\n",
      "Epoch 2305/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 10513.9187 - val_loss: 19584.2636\n",
      "Epoch 2306/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9928.0913 - val_loss: 18717.5125\n",
      "Epoch 2307/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8432.9148 - val_loss: 19593.6168\n",
      "Epoch 2308/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8508.7482 - val_loss: 19554.2742\n",
      "Epoch 2309/3000\n",
      "995/995 [==============================] - 0s 96us/step - loss: 9532.5896 - val_loss: 18783.7162\n",
      "Epoch 2310/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8421.1929 - val_loss: 18104.6102\n",
      "Epoch 2311/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7696.8405 - val_loss: 18563.4036\n",
      "Epoch 2312/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7673.0934 - val_loss: 18304.4303\n",
      "Epoch 2313/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7540.2370 - val_loss: 18251.1186\n",
      "Epoch 2314/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8179.9858 - val_loss: 18443.3406\n",
      "Epoch 2315/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8955.0973 - val_loss: 19324.9357\n",
      "Epoch 2316/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8808.3496 - val_loss: 18953.9234\n",
      "Epoch 2317/3000\n",
      "995/995 [==============================] - 0s 96us/step - loss: 7402.0787 - val_loss: 18920.8277\n",
      "Epoch 2318/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7819.1188 - val_loss: 19026.2528\n",
      "Epoch 2319/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7550.0192 - val_loss: 19905.0737\n",
      "Epoch 2320/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8980.9679 - val_loss: 18790.6848\n",
      "Epoch 2321/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8059.9122 - val_loss: 18662.8572\n",
      "Epoch 2322/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7776.4226 - val_loss: 19215.6188\n",
      "Epoch 2323/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8436.7683 - val_loss: 18647.9924\n",
      "Epoch 2324/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7589.4041 - val_loss: 19817.6909\n",
      "Epoch 2325/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8534.1856 - val_loss: 18286.1846\n",
      "Epoch 2326/3000\n",
      "995/995 [==============================] - 0s 185us/step - loss: 7514.0133 - val_loss: 18587.0033\n",
      "Epoch 2327/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7257.9963 - val_loss: 18572.4146\n",
      "Epoch 2328/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7305.9177 - val_loss: 18607.6306\n",
      "Epoch 2329/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8133.9108 - val_loss: 18556.9144\n",
      "Epoch 2330/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8414.4217 - val_loss: 19771.6646\n",
      "Epoch 2331/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8765.2751 - val_loss: 18362.6705\n",
      "Epoch 2332/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7124.4661 - val_loss: 18370.0880\n",
      "Epoch 2333/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7304.1522 - val_loss: 18444.1597\n",
      "Epoch 2334/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7559.2286 - val_loss: 18785.0401\n",
      "Epoch 2335/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8314.4112 - val_loss: 21021.9654\n",
      "Epoch 2336/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8170.4965 - val_loss: 18443.8642\n",
      "Epoch 2337/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8098.6309 - val_loss: 19372.2867\n",
      "Epoch 2338/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8331.9660 - val_loss: 18807.1809\n",
      "Epoch 2339/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8411.2193 - val_loss: 18799.7401\n",
      "Epoch 2340/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8545.1997 - val_loss: 19734.6167\n",
      "Epoch 2341/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8607.7487 - val_loss: 18580.8619\n",
      "Epoch 2342/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9030.1180 - val_loss: 19429.1077\n",
      "Epoch 2343/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 9496.6898 - val_loss: 19173.4716\n",
      "Epoch 2344/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8343.4136 - val_loss: 18409.7238\n",
      "Epoch 2345/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8589.4124 - val_loss: 18516.8812\n",
      "Epoch 2346/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7548.4755 - val_loss: 18284.4539\n",
      "Epoch 2347/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 7760.8856 - val_loss: 18521.9749\n",
      "Epoch 2348/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7956.4334 - val_loss: 18549.3306\n",
      "Epoch 2349/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8119.8733 - val_loss: 19023.9221\n",
      "Epoch 2350/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8395.6012 - val_loss: 18319.9409\n",
      "Epoch 2351/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7496.8823 - val_loss: 19146.1844\n",
      "Epoch 2352/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9011.8904 - val_loss: 20325.4966\n",
      "Epoch 2353/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9759.3545 - val_loss: 21735.7647\n",
      "Epoch 2354/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9663.6356 - val_loss: 18672.5472\n",
      "Epoch 2355/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7633.3177 - val_loss: 18617.8324\n",
      "Epoch 2356/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7639.3040 - val_loss: 18414.5631\n",
      "Epoch 2357/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9219.3273 - val_loss: 18936.6766\n",
      "Epoch 2358/3000\n",
      "995/995 [==============================] - 0s 96us/step - loss: 8900.2106 - val_loss: 19254.6454\n",
      "Epoch 2359/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8311.9082 - val_loss: 18574.7685\n",
      "Epoch 2360/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8779.4063 - val_loss: 19118.6702\n",
      "Epoch 2361/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8198.2249 - val_loss: 18911.9285\n",
      "Epoch 2362/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8424.0079 - val_loss: 18429.1326\n",
      "Epoch 2363/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8703.6830 - val_loss: 20207.3382\n",
      "Epoch 2364/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9085.3295 - val_loss: 21480.4656\n",
      "Epoch 2365/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9905.0049 - val_loss: 18240.7477\n",
      "Epoch 2366/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7297.8409 - val_loss: 18418.3395\n",
      "Epoch 2367/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 7635.9920 - val_loss: 18639.6769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2368/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8181.4132 - val_loss: 21692.5227\n",
      "Epoch 2369/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 11027.3245 - val_loss: 18467.9458\n",
      "Epoch 2370/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8485.1637 - val_loss: 20176.1505\n",
      "Epoch 2371/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9980.1380 - val_loss: 18629.9185\n",
      "Epoch 2372/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7863.8674 - val_loss: 18378.8420\n",
      "Epoch 2373/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7467.2219 - val_loss: 18603.4341\n",
      "Epoch 2374/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7300.6160 - val_loss: 18887.9643\n",
      "Epoch 2375/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7907.5038 - val_loss: 18542.8156\n",
      "Epoch 2376/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8294.6499 - val_loss: 18529.6628\n",
      "Epoch 2377/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8502.0856 - val_loss: 18357.6199\n",
      "Epoch 2378/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 10338.6356 - val_loss: 18602.6056\n",
      "Epoch 2379/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7721.1234 - val_loss: 18450.5594\n",
      "Epoch 2380/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7614.5655 - val_loss: 19158.2244\n",
      "Epoch 2381/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8969.3349 - val_loss: 18585.6381\n",
      "Epoch 2382/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7771.5997 - val_loss: 18497.9614\n",
      "Epoch 2383/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7348.5766 - val_loss: 18363.4452\n",
      "Epoch 2384/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7379.2720 - val_loss: 18664.3097\n",
      "Epoch 2385/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8263.6967 - val_loss: 18638.7128\n",
      "Epoch 2386/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7327.1017 - val_loss: 18736.3618\n",
      "Epoch 2387/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8001.3818 - val_loss: 20180.9665\n",
      "Epoch 2388/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9004.4741 - val_loss: 18539.9541\n",
      "Epoch 2389/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9295.7073 - val_loss: 19291.7083\n",
      "Epoch 2390/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7712.5152 - val_loss: 18515.4958\n",
      "Epoch 2391/3000\n",
      "995/995 [==============================] - 0s 84us/step - loss: 7476.4663 - val_loss: 18676.9133\n",
      "Epoch 2392/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7571.1266 - val_loss: 18603.7424\n",
      "Epoch 2393/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8857.3149 - val_loss: 18432.9854\n",
      "Epoch 2394/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7686.5733 - val_loss: 18641.3343\n",
      "Epoch 2395/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8419.4936 - val_loss: 19431.3339\n",
      "Epoch 2396/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 7765.76 - 0s 124us/step - loss: 7723.3597 - val_loss: 18710.2911\n",
      "Epoch 2397/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8890.5666 - val_loss: 20844.4080\n",
      "Epoch 2398/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 8611.2028 - val_loss: 18706.2081\n",
      "Epoch 2399/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7492.5757 - val_loss: 18525.7462\n",
      "Epoch 2400/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8205.5261 - val_loss: 18783.0670\n",
      "Epoch 2401/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8854.0873 - val_loss: 18404.3427\n",
      "Epoch 2402/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7817.2713 - val_loss: 18871.9758\n",
      "Epoch 2403/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7703.5053 - val_loss: 19057.8308\n",
      "Epoch 2404/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7774.9564 - val_loss: 18540.7995\n",
      "Epoch 2405/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7377.0846 - val_loss: 18945.8717\n",
      "Epoch 2406/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8115.2931 - val_loss: 18679.1842\n",
      "Epoch 2407/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7789.4909 - val_loss: 19159.8380\n",
      "Epoch 2408/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8010.3263 - val_loss: 18868.0391\n",
      "Epoch 2409/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7631.1175 - val_loss: 18813.1462\n",
      "Epoch 2410/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7747.4870 - val_loss: 18569.6062\n",
      "Epoch 2411/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7195.1817 - val_loss: 19373.3004\n",
      "Epoch 2412/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8028.3833 - val_loss: 19280.1115\n",
      "Epoch 2413/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8883.1455 - val_loss: 18488.4220\n",
      "Epoch 2414/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8112.4553 - val_loss: 18452.2262\n",
      "Epoch 2415/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7834.0161 - val_loss: 19420.9110\n",
      "Epoch 2416/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8120.7295 - val_loss: 20188.9226\n",
      "Epoch 2417/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8013.4159 - val_loss: 18569.2019\n",
      "Epoch 2418/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7431.9965 - val_loss: 19830.6600\n",
      "Epoch 2419/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8239.9023 - val_loss: 18996.0453\n",
      "Epoch 2420/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8003.4334 - val_loss: 18120.4985\n",
      "Epoch 2421/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7752.6975 - val_loss: 18706.2838\n",
      "Epoch 2422/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7742.5194 - val_loss: 18693.8676\n",
      "Epoch 2423/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8053.5669 - val_loss: 18611.8589\n",
      "Epoch 2424/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7557.8048 - val_loss: 19592.8721\n",
      "Epoch 2425/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8366.0256 - val_loss: 18749.9896\n",
      "Epoch 2426/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7933.9761 - val_loss: 18687.9354\n",
      "Epoch 2427/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8008.0534 - val_loss: 18675.0548\n",
      "Epoch 2428/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8250.3656 - val_loss: 18505.1179\n",
      "Epoch 2429/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8130.6535 - val_loss: 18410.8058\n",
      "Epoch 2430/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8524.2883 - val_loss: 18590.1693\n",
      "Epoch 2431/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 7667.79 - 0s 149us/step - loss: 7639.7779 - val_loss: 18689.8430\n",
      "Epoch 2432/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8184.1250 - val_loss: 18731.5667\n",
      "Epoch 2433/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7289.6394 - val_loss: 18598.8173\n",
      "Epoch 2434/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7776.9941 - val_loss: 19342.3504\n",
      "Epoch 2435/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8449.0269 - val_loss: 18550.5620\n",
      "Epoch 2436/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8157.7849 - val_loss: 18540.5154\n",
      "Epoch 2437/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8294.0501 - val_loss: 18327.9299\n",
      "Epoch 2438/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7170.3420 - val_loss: 18845.3926\n",
      "Epoch 2439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 149us/step - loss: 8196.2377 - val_loss: 18572.9947\n",
      "Epoch 2440/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8535.8435 - val_loss: 19303.8265\n",
      "Epoch 2441/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8300.0170 - val_loss: 18625.6489\n",
      "Epoch 2442/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7576.3261 - val_loss: 18953.9465\n",
      "Epoch 2443/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7300.8052 - val_loss: 18491.5251\n",
      "Epoch 2444/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7768.1198 - val_loss: 18512.5228\n",
      "Epoch 2445/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8944.9099 - val_loss: 18279.7939\n",
      "Epoch 2446/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8362.4239 - val_loss: 18370.1686\n",
      "Epoch 2447/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9014.4273 - val_loss: 19155.0007\n",
      "Epoch 2448/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8768.4607 - val_loss: 18955.1134\n",
      "Epoch 2449/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8796.2093 - val_loss: 19316.1055\n",
      "Epoch 2450/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7936.7107 - val_loss: 19123.0246\n",
      "Epoch 2451/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7648.2318 - val_loss: 18684.8089\n",
      "Epoch 2452/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7985.2562 - val_loss: 18523.4436\n",
      "Epoch 2453/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8011.9159 - val_loss: 19188.5126\n",
      "Epoch 2454/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7807.8434 - val_loss: 18639.2712\n",
      "Epoch 2455/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8010.1119 - val_loss: 18852.9871\n",
      "Epoch 2456/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7475.1838 - val_loss: 18483.1478\n",
      "Epoch 2457/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7392.8836 - val_loss: 19022.0477\n",
      "Epoch 2458/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7562.5678 - val_loss: 19312.5654\n",
      "Epoch 2459/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8050.6935 - val_loss: 18763.7741\n",
      "Epoch 2460/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7180.8193 - val_loss: 18796.9406\n",
      "Epoch 2461/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7341.4141 - val_loss: 18470.8407\n",
      "Epoch 2462/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8495.9806 - val_loss: 18286.7584\n",
      "Epoch 2463/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8645.8259 - val_loss: 18286.3058\n",
      "Epoch 2464/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7535.5369 - val_loss: 19076.5907\n",
      "Epoch 2465/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7681.2435 - val_loss: 18566.8754\n",
      "Epoch 2466/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8245.5888 - val_loss: 19741.4642\n",
      "Epoch 2467/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8676.1312 - val_loss: 18089.3313\n",
      "Epoch 2468/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7482.6500 - val_loss: 18590.8962\n",
      "Epoch 2469/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7346.1588 - val_loss: 18712.1381\n",
      "Epoch 2470/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7591.9302 - val_loss: 19412.5626\n",
      "Epoch 2471/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8856.0141 - val_loss: 19221.3477\n",
      "Epoch 2472/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7740.0851 - val_loss: 19264.7229\n",
      "Epoch 2473/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8199.3316 - val_loss: 20760.1780\n",
      "Epoch 2474/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 9196.6431 - val_loss: 18618.6047\n",
      "Epoch 2475/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7485.1201 - val_loss: 18290.3339\n",
      "Epoch 2476/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7099.2581 - val_loss: 18611.2791\n",
      "Epoch 2477/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8108.4408 - val_loss: 18525.3400\n",
      "Epoch 2478/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7525.9524 - val_loss: 19202.9088\n",
      "Epoch 2479/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 9207.3495 - val_loss: 19141.3459\n",
      "Epoch 2480/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8415.9469 - val_loss: 19039.6201\n",
      "Epoch 2481/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8202.3014 - val_loss: 18271.4926\n",
      "Epoch 2482/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7716.3497 - val_loss: 18677.4156\n",
      "Epoch 2483/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8037.6012 - val_loss: 18221.8744\n",
      "Epoch 2484/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7963.6861 - val_loss: 18319.6641\n",
      "Epoch 2485/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7772.5785 - val_loss: 18439.7658\n",
      "Epoch 2486/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7767.2526 - val_loss: 18714.0790\n",
      "Epoch 2487/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7743.2952 - val_loss: 19441.1950\n",
      "Epoch 2488/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8288.4670 - val_loss: 18972.2654\n",
      "Epoch 2489/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7538.8603 - val_loss: 18466.9175\n",
      "Epoch 2490/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7929.9960 - val_loss: 19305.4376\n",
      "Epoch 2491/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8811.3766 - val_loss: 18171.1622\n",
      "Epoch 2492/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7346.7652 - val_loss: 18435.1173\n",
      "Epoch 2493/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7921.7193 - val_loss: 18498.6901\n",
      "Epoch 2494/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7301.5418 - val_loss: 18316.0186\n",
      "Epoch 2495/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8399.4667 - val_loss: 18417.4043\n",
      "Epoch 2496/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9994.9775 - val_loss: 18837.5287\n",
      "Epoch 2497/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7748.1478 - val_loss: 18524.7127\n",
      "Epoch 2498/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7406.0934 - val_loss: 18528.7051\n",
      "Epoch 2499/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7608.6870 - val_loss: 19403.9979\n",
      "Epoch 2500/3000\n",
      "995/995 [==============================] - 0s 76us/step - loss: 7612.2919 - val_loss: 19000.1886\n",
      "Epoch 2501/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7611.7596 - val_loss: 18762.9074\n",
      "Epoch 2502/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7271.0611 - val_loss: 18889.3387\n",
      "Epoch 2503/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7900.1725 - val_loss: 18782.7655\n",
      "Epoch 2504/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7573.6120 - val_loss: 19023.5011\n",
      "Epoch 2505/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7787.7325 - val_loss: 18813.0706\n",
      "Epoch 2506/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8463.5226 - val_loss: 18789.3209\n",
      "Epoch 2507/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7892.1765 - val_loss: 19199.2001\n",
      "Epoch 2508/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7802.7155 - val_loss: 18602.9302\n",
      "Epoch 2509/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 7966.78 - 0s 137us/step - loss: 7950.6659 - val_loss: 18832.8694\n",
      "Epoch 2510/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7962.9004 - val_loss: 18571.2060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2511/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8129.5878 - val_loss: 19142.3254\n",
      "Epoch 2512/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7922.5940 - val_loss: 18321.5342\n",
      "Epoch 2513/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7546.9865 - val_loss: 18778.1779\n",
      "Epoch 2514/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8356.2698 - val_loss: 19254.5563\n",
      "Epoch 2515/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7728.9504 - val_loss: 18499.8902\n",
      "Epoch 2516/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7227.2648 - val_loss: 18542.1345\n",
      "Epoch 2517/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7733.5871 - val_loss: 18344.4577\n",
      "Epoch 2518/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7581.8051 - val_loss: 18180.7594\n",
      "Epoch 2519/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7262.9627 - val_loss: 18556.7382\n",
      "Epoch 2520/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7186.1419 - val_loss: 19299.0145\n",
      "Epoch 2521/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7431.6648 - val_loss: 18488.5063\n",
      "Epoch 2522/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7276.6135 - val_loss: 18605.1279\n",
      "Epoch 2523/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7507.9194 - val_loss: 18602.2474\n",
      "Epoch 2524/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8283.5713 - val_loss: 18878.6608\n",
      "Epoch 2525/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8494.6087 - val_loss: 19754.6813\n",
      "Epoch 2526/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9640.1238 - val_loss: 18760.0431\n",
      "Epoch 2527/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7686.1848 - val_loss: 18504.8626\n",
      "Epoch 2528/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7338.3132 - val_loss: 18921.3178\n",
      "Epoch 2529/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7982.5808 - val_loss: 18930.3814\n",
      "Epoch 2530/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8954.8546 - val_loss: 18989.0691\n",
      "Epoch 2531/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8617.4411 - val_loss: 18654.0581\n",
      "Epoch 2532/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7325.2595 - val_loss: 18659.6652\n",
      "Epoch 2533/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7484.8896 - val_loss: 18527.1747\n",
      "Epoch 2534/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8278.1665 - val_loss: 18452.2140\n",
      "Epoch 2535/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8345.0122 - val_loss: 18387.3580\n",
      "Epoch 2536/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7187.1266 - val_loss: 18529.3338\n",
      "Epoch 2537/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7393.8806 - val_loss: 18556.1253\n",
      "Epoch 2538/3000\n",
      "995/995 [==============================] - 0s 96us/step - loss: 7902.2356 - val_loss: 18575.1430\n",
      "Epoch 2539/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7442.0047 - val_loss: 18748.9397\n",
      "Epoch 2540/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8415.2522 - val_loss: 19908.6709\n",
      "Epoch 2541/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8771.4957 - val_loss: 18780.4195\n",
      "Epoch 2542/3000\n",
      "995/995 [==============================] - 0s 108us/step - loss: 8237.1506 - val_loss: 18738.8635\n",
      "Epoch 2543/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7348.6515 - val_loss: 18615.0152\n",
      "Epoch 2544/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7272.5959 - val_loss: 18404.6783\n",
      "Epoch 2545/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 7905.1342 - val_loss: 18707.8516\n",
      "Epoch 2546/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7224.8736 - val_loss: 18418.1143\n",
      "Epoch 2547/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7269.4844 - val_loss: 19059.1274\n",
      "Epoch 2548/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 8212.6975 - val_loss: 18509.3547\n",
      "Epoch 2549/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7652.3099 - val_loss: 18625.3534\n",
      "Epoch 2550/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7569.3180 - val_loss: 18601.9484\n",
      "Epoch 2551/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7172.5155 - val_loss: 18241.1719\n",
      "Epoch 2552/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7082.5560 - val_loss: 18768.1755\n",
      "Epoch 2553/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7292.7439 - val_loss: 18657.9541\n",
      "Epoch 2554/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7646.2068 - val_loss: 18950.9940\n",
      "Epoch 2555/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8747.3634 - val_loss: 20504.7097\n",
      "Epoch 2556/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8130.9010 - val_loss: 18799.5086\n",
      "Epoch 2557/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7566.4628 - val_loss: 18584.1422\n",
      "Epoch 2558/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7664.4666 - val_loss: 19170.4371\n",
      "Epoch 2559/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8015.6397 - val_loss: 18535.5389\n",
      "Epoch 2560/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7770.8233 - val_loss: 18771.6257\n",
      "Epoch 2561/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7650.1483 - val_loss: 19800.6569\n",
      "Epoch 2562/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7619.3628 - val_loss: 18791.4683\n",
      "Epoch 2563/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7767.4774 - val_loss: 18885.5035\n",
      "Epoch 2564/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7886.9412 - val_loss: 19402.2820\n",
      "Epoch 2565/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8008.8973 - val_loss: 18651.5870\n",
      "Epoch 2566/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7853.2677 - val_loss: 21203.1637\n",
      "Epoch 2567/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8193.5866 - val_loss: 18585.1400\n",
      "Epoch 2568/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7823.7841 - val_loss: 18296.9931\n",
      "Epoch 2569/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8774.7359 - val_loss: 18595.0567\n",
      "Epoch 2570/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8002.0406 - val_loss: 20060.4935\n",
      "Epoch 2571/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8035.2206 - val_loss: 18804.4298\n",
      "Epoch 2572/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8307.8886 - val_loss: 18689.6649\n",
      "Epoch 2573/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7943.9040 - val_loss: 18380.7621\n",
      "Epoch 2574/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7765.1701 - val_loss: 18476.4456\n",
      "Epoch 2575/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8159.1891 - val_loss: 18621.4541\n",
      "Epoch 2576/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7522.9862 - val_loss: 18552.1404\n",
      "Epoch 2577/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7579.0080 - val_loss: 19424.9409\n",
      "Epoch 2578/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8629.8308 - val_loss: 18362.5672\n",
      "Epoch 2579/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 8140.1137 - val_loss: 18565.8418\n",
      "Epoch 2580/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8451.2047 - val_loss: 18876.3575\n",
      "Epoch 2581/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8884.8709 - val_loss: 18577.0673\n",
      "Epoch 2582/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7708.6457 - val_loss: 19561.5241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2583/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9262.8154 - val_loss: 18528.0479\n",
      "Epoch 2584/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8090.9435 - val_loss: 19339.5011\n",
      "Epoch 2585/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8369.4771 - val_loss: 18940.1947\n",
      "Epoch 2586/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7770.7492 - val_loss: 18572.1308\n",
      "Epoch 2587/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7294.6147 - val_loss: 18638.2244\n",
      "Epoch 2588/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7738.0986 - val_loss: 18623.6265\n",
      "Epoch 2589/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7533.7610 - val_loss: 18271.1460\n",
      "Epoch 2590/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7967.1883 - val_loss: 18534.8718\n",
      "Epoch 2591/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7866.0115 - val_loss: 18490.4636\n",
      "Epoch 2592/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7218.5398 - val_loss: 18148.9171\n",
      "Epoch 2593/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7590.8038 - val_loss: 18955.5947\n",
      "Epoch 2594/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7374.4442 - val_loss: 18562.8629\n",
      "Epoch 2595/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7906.0490 - val_loss: 18599.6781\n",
      "Epoch 2596/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7577.4409 - val_loss: 18503.9179\n",
      "Epoch 2597/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8319.0583 - val_loss: 19742.6063\n",
      "Epoch 2598/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9966.3565 - val_loss: 18327.0037\n",
      "Epoch 2599/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7587.6296 - val_loss: 18482.4326\n",
      "Epoch 2600/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8488.4897 - val_loss: 18711.8451\n",
      "Epoch 2601/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8054.8649 - val_loss: 18168.4846\n",
      "Epoch 2602/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7431.1002 - val_loss: 18868.6643\n",
      "Epoch 2603/3000\n",
      "995/995 [==============================] - 0s 104us/step - loss: 8859.3986 - val_loss: 20091.2833\n",
      "Epoch 2604/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8305.2943 - val_loss: 19439.9420\n",
      "Epoch 2605/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 9132.1966 - val_loss: 19398.6971\n",
      "Epoch 2606/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8319.9583 - val_loss: 18581.7741\n",
      "Epoch 2607/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7745.3955 - val_loss: 18320.4306\n",
      "Epoch 2608/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7648.0920 - val_loss: 18995.5743\n",
      "Epoch 2609/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8178.1680 - val_loss: 18968.0222\n",
      "Epoch 2610/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8052.5788 - val_loss: 18973.9759\n",
      "Epoch 2611/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8242.6721 - val_loss: 19629.6077\n",
      "Epoch 2612/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8987.9837 - val_loss: 21173.6166\n",
      "Epoch 2613/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 11350.7620 - val_loss: 18564.4117\n",
      "Epoch 2614/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8536.3248 - val_loss: 18373.7712\n",
      "Epoch 2615/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7273.3847 - val_loss: 18753.4050\n",
      "Epoch 2616/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7764.0176 - val_loss: 18546.6282\n",
      "Epoch 2617/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7269.2797 - val_loss: 18555.0622\n",
      "Epoch 2618/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7729.1957 - val_loss: 18505.5059\n",
      "Epoch 2619/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7241.8401 - val_loss: 18532.2310\n",
      "Epoch 2620/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7399.8614 - val_loss: 18267.2454\n",
      "Epoch 2621/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7640.4311 - val_loss: 18538.9146\n",
      "Epoch 2622/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7928.2333 - val_loss: 18739.1737\n",
      "Epoch 2623/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7901.3802 - val_loss: 18292.2448\n",
      "Epoch 2624/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7366.1177 - val_loss: 18891.1493\n",
      "Epoch 2625/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7850.0539 - val_loss: 18208.2147\n",
      "Epoch 2626/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7200.6155 - val_loss: 18555.4571\n",
      "Epoch 2627/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7373.9836 - val_loss: 18477.5075\n",
      "Epoch 2628/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8096.5708 - val_loss: 18586.0911\n",
      "Epoch 2629/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7395.9366 - val_loss: 18760.2724\n",
      "Epoch 2630/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7907.3630 - val_loss: 18420.1394\n",
      "Epoch 2631/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7250.4192 - val_loss: 18587.2438\n",
      "Epoch 2632/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8033.5151 - val_loss: 18557.4712\n",
      "Epoch 2633/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7294.5100 - val_loss: 18370.6960\n",
      "Epoch 2634/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7300.9201 - val_loss: 18890.9589\n",
      "Epoch 2635/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7191.1442 - val_loss: 19075.2133\n",
      "Epoch 2636/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8793.6561 - val_loss: 18839.1668\n",
      "Epoch 2637/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8276.8914 - val_loss: 18433.0286\n",
      "Epoch 2638/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8232.5231 - val_loss: 18525.2189\n",
      "Epoch 2639/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8731.1215 - val_loss: 18172.4560\n",
      "Epoch 2640/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7895.6054 - val_loss: 18461.6120\n",
      "Epoch 2641/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7029.3609 - val_loss: 18609.8718\n",
      "Epoch 2642/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7436.6226 - val_loss: 18710.3298\n",
      "Epoch 2643/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7376.0204 - val_loss: 18957.1270\n",
      "Epoch 2644/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8672.4768 - val_loss: 18177.8025\n",
      "Epoch 2645/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7717.6438 - val_loss: 18896.7262\n",
      "Epoch 2646/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7406.9739 - val_loss: 18617.8541\n",
      "Epoch 2647/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8441.6980 - val_loss: 18610.5457\n",
      "Epoch 2648/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7284.6269 - val_loss: 18432.3395\n",
      "Epoch 2649/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9314.9029 - val_loss: 18785.7248\n",
      "Epoch 2650/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 10242.3087 - val_loss: 20494.3432\n",
      "Epoch 2651/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8552.0230 - val_loss: 18853.9420\n",
      "Epoch 2652/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7091.8518 - val_loss: 18685.4014\n",
      "Epoch 2653/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7572.7153 - val_loss: 18296.8211\n",
      "Epoch 2654/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7287.8967 - val_loss: 19165.5659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2655/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8933.0493 - val_loss: 18507.2312\n",
      "Epoch 2656/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7841.7136 - val_loss: 18775.0242\n",
      "Epoch 2657/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8112.3824 - val_loss: 18575.6362\n",
      "Epoch 2658/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8510.6576 - val_loss: 19461.9770\n",
      "Epoch 2659/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7687.6218 - val_loss: 18273.1116\n",
      "Epoch 2660/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7086.1106 - val_loss: 18378.7302\n",
      "Epoch 2661/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7535.0356 - val_loss: 18836.4812\n",
      "Epoch 2662/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7388.6630 - val_loss: 19566.2664\n",
      "Epoch 2663/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8679.2149 - val_loss: 18568.6328\n",
      "Epoch 2664/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7430.8481 - val_loss: 18749.9156\n",
      "Epoch 2665/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7087.8298 - val_loss: 18961.9276\n",
      "Epoch 2666/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 7268.9651 - val_loss: 18707.6032\n",
      "Epoch 2667/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7808.1833 - val_loss: 18377.4326\n",
      "Epoch 2668/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7326.4187 - val_loss: 19212.0211\n",
      "Epoch 2669/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7916.7827 - val_loss: 18725.5037\n",
      "Epoch 2670/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8798.6244 - val_loss: 18481.8724\n",
      "Epoch 2671/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7456.4883 - val_loss: 18377.5342\n",
      "Epoch 2672/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7288.2620 - val_loss: 18525.5710\n",
      "Epoch 2673/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7252.1982 - val_loss: 18465.1214\n",
      "Epoch 2674/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7648.4695 - val_loss: 18570.0367\n",
      "Epoch 2675/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7407.8023 - val_loss: 19156.9772\n",
      "Epoch 2676/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8640.6844 - val_loss: 18652.4913\n",
      "Epoch 2677/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8468.6336 - val_loss: 19502.2318\n",
      "Epoch 2678/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7636.7609 - val_loss: 18647.6373\n",
      "Epoch 2679/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7328.3747 - val_loss: 18474.4862\n",
      "Epoch 2680/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8870.3965 - val_loss: 18579.8295\n",
      "Epoch 2681/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8328.5592 - val_loss: 19159.5379\n",
      "Epoch 2682/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7457.7195 - val_loss: 18869.6865\n",
      "Epoch 2683/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7233.0889 - val_loss: 19076.6347\n",
      "Epoch 2684/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7352.8958 - val_loss: 18261.1007\n",
      "Epoch 2685/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7176.0667 - val_loss: 18353.7378\n",
      "Epoch 2686/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7845.5796 - val_loss: 18545.0872\n",
      "Epoch 2687/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7701.0323 - val_loss: 18150.6750\n",
      "Epoch 2688/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7615.3338 - val_loss: 18440.3911\n",
      "Epoch 2689/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7563.3904 - val_loss: 18395.7872\n",
      "Epoch 2690/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7223.0694 - val_loss: 19295.3375\n",
      "Epoch 2691/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8492.8210 - val_loss: 18425.1383\n",
      "Epoch 2692/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8301.7817 - val_loss: 18968.1410\n",
      "Epoch 2693/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7501.2209 - val_loss: 18441.4841\n",
      "Epoch 2694/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7395.0132 - val_loss: 18859.9361\n",
      "Epoch 2695/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7474.8811 - val_loss: 19070.7024\n",
      "Epoch 2696/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7416.4698 - val_loss: 18305.0561\n",
      "Epoch 2697/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 6917.5056 - val_loss: 18453.1210\n",
      "Epoch 2698/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7372.4020 - val_loss: 18990.5906\n",
      "Epoch 2699/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7623.4741 - val_loss: 18973.8212\n",
      "Epoch 2700/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7688.7122 - val_loss: 19176.4048\n",
      "Epoch 2701/3000\n",
      "995/995 [==============================] - 0s 104us/step - loss: 8463.3916 - val_loss: 19230.8375\n",
      "Epoch 2702/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7796.5930 - val_loss: 18333.0111\n",
      "Epoch 2703/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9199.7988 - val_loss: 18542.9898\n",
      "Epoch 2704/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9919.7801 - val_loss: 18379.7498\n",
      "Epoch 2705/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 8296.3059 - val_loss: 18711.4902\n",
      "Epoch 2706/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8383.9319 - val_loss: 18493.2028\n",
      "Epoch 2707/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8539.6520 - val_loss: 18695.5500\n",
      "Epoch 2708/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8356.1802 - val_loss: 18421.2468\n",
      "Epoch 2709/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7690.4295 - val_loss: 19405.3996\n",
      "Epoch 2710/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8255.5669 - val_loss: 19274.6162\n",
      "Epoch 2711/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7649.3059 - val_loss: 18916.0567\n",
      "Epoch 2712/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8320.0723 - val_loss: 18272.0990\n",
      "Epoch 2713/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7107.8271 - val_loss: 18517.5550\n",
      "Epoch 2714/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7634.0941 - val_loss: 19193.0949\n",
      "Epoch 2715/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7614.0750 - val_loss: 18854.8773\n",
      "Epoch 2716/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7255.7454 - val_loss: 18526.4352\n",
      "Epoch 2717/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7087.4135 - val_loss: 18509.2348\n",
      "Epoch 2718/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7307.6006 - val_loss: 18304.4379\n",
      "Epoch 2719/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6969.8477 - val_loss: 18463.8207\n",
      "Epoch 2720/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 6960.8046 - val_loss: 18622.5053\n",
      "Epoch 2721/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7012.2620 - val_loss: 18435.4549\n",
      "Epoch 2722/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8120.0689 - val_loss: 18946.2334\n",
      "Epoch 2723/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8855.2295 - val_loss: 18746.7951\n",
      "Epoch 2724/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7756.5571 - val_loss: 18462.8529\n",
      "Epoch 2725/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7266.1204 - val_loss: 18597.5468\n",
      "Epoch 2726/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7773.8532 - val_loss: 21005.1430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2727/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10407.4956 - val_loss: 18524.6436\n",
      "Epoch 2728/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7841.3180 - val_loss: 18698.2772\n",
      "Epoch 2729/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7789.4109 - val_loss: 19452.3761\n",
      "Epoch 2730/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8553.0957 - val_loss: 18581.8629\n",
      "Epoch 2731/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7877.1476 - val_loss: 18831.3147\n",
      "Epoch 2732/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 9126.37 - 0s 116us/step - loss: 8491.0571 - val_loss: 18528.8766\n",
      "Epoch 2733/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7435.1425 - val_loss: 18792.4269\n",
      "Epoch 2734/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7364.2537 - val_loss: 19042.4810\n",
      "Epoch 2735/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8485.9478 - val_loss: 18569.7109\n",
      "Epoch 2736/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8189.8674 - val_loss: 18524.5486\n",
      "Epoch 2737/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7693.8091 - val_loss: 18614.5539\n",
      "Epoch 2738/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7747.6181 - val_loss: 18838.8756\n",
      "Epoch 2739/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7356.7707 - val_loss: 19340.3457\n",
      "Epoch 2740/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8042.7193 - val_loss: 18118.2211\n",
      "Epoch 2741/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7497.6999 - val_loss: 18415.4479\n",
      "Epoch 2742/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8088.5562 - val_loss: 18557.2845\n",
      "Epoch 2743/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7543.3432 - val_loss: 18628.6735\n",
      "Epoch 2744/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7566.3016 - val_loss: 19207.3729\n",
      "Epoch 2745/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7546.5134 - val_loss: 19384.8066\n",
      "Epoch 2746/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8185.8848 - val_loss: 18558.6478\n",
      "Epoch 2747/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7576.8906 - val_loss: 18369.8881\n",
      "Epoch 2748/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7750.8953 - val_loss: 19127.4659\n",
      "Epoch 2749/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 9022.7075 - val_loss: 18585.8263\n",
      "Epoch 2750/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8470.8710 - val_loss: 18237.2542\n",
      "Epoch 2751/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 8427.4558 - val_loss: 18432.4480\n",
      "Epoch 2752/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8302.5680 - val_loss: 18570.0951\n",
      "Epoch 2753/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6958.7826 - val_loss: 18595.0394\n",
      "Epoch 2754/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7124.5547 - val_loss: 18329.1340\n",
      "Epoch 2755/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7978.6846 - val_loss: 18578.3597\n",
      "Epoch 2756/3000\n",
      "995/995 [==============================] - 0s 100us/step - loss: 7456.0393 - val_loss: 18405.6412\n",
      "Epoch 2757/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7297.9658 - val_loss: 18503.4339\n",
      "Epoch 2758/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7154.0497 - val_loss: 20119.8994\n",
      "Epoch 2759/3000\n",
      "995/995 [==============================] - 0s 140us/step - loss: 7279.1153 - val_loss: 18883.9497\n",
      "Epoch 2760/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7781.0449 - val_loss: 18570.6939\n",
      "Epoch 2761/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7611.8925 - val_loss: 18418.3534\n",
      "Epoch 2762/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7077.0849 - val_loss: 18748.1910\n",
      "Epoch 2763/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7406.5079 - val_loss: 18599.1441\n",
      "Epoch 2764/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7576.6182 - val_loss: 20317.7400\n",
      "Epoch 2765/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 9650.2812 - val_loss: 19727.9830\n",
      "Epoch 2766/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8670.5636 - val_loss: 19369.1076\n",
      "Epoch 2767/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7138.6031 - val_loss: 18510.6986\n",
      "Epoch 2768/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7198.8373 - val_loss: 19372.0198\n",
      "Epoch 2769/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7401.3582 - val_loss: 18743.5512\n",
      "Epoch 2770/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7995.7206 - val_loss: 18486.3268\n",
      "Epoch 2771/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7092.7557 - val_loss: 18422.0216\n",
      "Epoch 2772/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8398.9775 - val_loss: 18907.8359\n",
      "Epoch 2773/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9323.4671 - val_loss: 19373.2205\n",
      "Epoch 2774/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7970.0390 - val_loss: 18845.4806\n",
      "Epoch 2775/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7566.7108 - val_loss: 18553.1502\n",
      "Epoch 2776/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7809.6545 - val_loss: 18842.0204\n",
      "Epoch 2777/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7441.3123 - val_loss: 18601.3030\n",
      "Epoch 2778/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 7102.0202 - val_loss: 19071.4202\n",
      "Epoch 2779/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7487.1889 - val_loss: 18842.9856\n",
      "Epoch 2780/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8844.3402 - val_loss: 18320.0502\n",
      "Epoch 2781/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7162.2268 - val_loss: 19489.2309\n",
      "Epoch 2782/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8645.8243 - val_loss: 18380.0276\n",
      "Epoch 2783/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7143.8200 - val_loss: 19000.3335\n",
      "Epoch 2784/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7598.8448 - val_loss: 18897.0515\n",
      "Epoch 2785/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7273.2416 - val_loss: 18703.5527\n",
      "Epoch 2786/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 8195.5326 - val_loss: 18668.3113\n",
      "Epoch 2787/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7234.5696 - val_loss: 18482.3867\n",
      "Epoch 2788/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7610.2834 - val_loss: 18250.8653\n",
      "Epoch 2789/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8081.6498 - val_loss: 18788.0223\n",
      "Epoch 2790/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 8231.8948 - val_loss: 18426.7186\n",
      "Epoch 2791/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7391.9020 - val_loss: 18297.8059\n",
      "Epoch 2792/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7577.8726 - val_loss: 19047.5329\n",
      "Epoch 2793/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7404.2559 - val_loss: 19039.2165\n",
      "Epoch 2794/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7896.3035 - val_loss: 18495.5922\n",
      "Epoch 2795/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7463.6960 - val_loss: 18305.3348\n",
      "Epoch 2796/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7213.9234 - val_loss: 18254.0814\n",
      "Epoch 2797/3000\n",
      "995/995 [==============================] - 0s 169us/step - loss: 7510.5721 - val_loss: 18381.4641\n",
      "Epoch 2798/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 149us/step - loss: 7642.9254 - val_loss: 18175.8672\n",
      "Epoch 2799/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7378.4753 - val_loss: 18176.5044\n",
      "Epoch 2800/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7003.9567 - val_loss: 18464.4649\n",
      "Epoch 2801/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7937.3502 - val_loss: 19638.1713\n",
      "Epoch 2802/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7750.9875 - val_loss: 18513.4177\n",
      "Epoch 2803/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7783.2017 - val_loss: 18929.7703\n",
      "Epoch 2804/3000\n",
      "995/995 [==============================] - 0s 173us/step - loss: 8103.8254 - val_loss: 18460.5067\n",
      "Epoch 2805/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7312.1811 - val_loss: 18378.7237\n",
      "Epoch 2806/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7517.0769 - val_loss: 18402.7477\n",
      "Epoch 2807/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7491.5276 - val_loss: 19022.4952\n",
      "Epoch 2808/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8235.5284 - val_loss: 18462.2214\n",
      "Epoch 2809/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7499.1034 - val_loss: 18500.7531\n",
      "Epoch 2810/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7860.9596 - val_loss: 18409.0330\n",
      "Epoch 2811/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 6882.7556 - val_loss: 18436.8805\n",
      "Epoch 2812/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8718.8497 - val_loss: 20546.3455\n",
      "Epoch 2813/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 9571.9762 - val_loss: 18402.3175\n",
      "Epoch 2814/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 6942.0636 - val_loss: 18545.2931\n",
      "Epoch 2815/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7283.5320 - val_loss: 18669.9374\n",
      "Epoch 2816/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8101.8677 - val_loss: 18722.9780\n",
      "Epoch 2817/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8181.0115 - val_loss: 18377.6289\n",
      "Epoch 2818/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7344.0084 - val_loss: 18918.7075\n",
      "Epoch 2819/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8410.2738 - val_loss: 18654.0289\n",
      "Epoch 2820/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7421.5028 - val_loss: 18418.1110\n",
      "Epoch 2821/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7433.9660 - val_loss: 18664.4124\n",
      "Epoch 2822/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7787.3860 - val_loss: 18871.5059\n",
      "Epoch 2823/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7131.7447 - val_loss: 18337.2781\n",
      "Epoch 2824/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7368.1983 - val_loss: 20333.7574\n",
      "Epoch 2825/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9755.2610 - val_loss: 18499.6836\n",
      "Epoch 2826/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7497.1556 - val_loss: 20698.8429\n",
      "Epoch 2827/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 15359.4292 - val_loss: 18527.2456\n",
      "Epoch 2828/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7465.5062 - val_loss: 18695.3927\n",
      "Epoch 2829/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7390.5821 - val_loss: 18585.2801\n",
      "Epoch 2830/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7258.4498 - val_loss: 18162.4540\n",
      "Epoch 2831/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6792.2473 - val_loss: 18471.0938\n",
      "Epoch 2832/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8303.5609 - val_loss: 18488.2481\n",
      "Epoch 2833/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8067.7211 - val_loss: 18712.2087\n",
      "Epoch 2834/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7757.2843 - val_loss: 18556.6391\n",
      "Epoch 2835/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7110.4611 - val_loss: 18751.0597\n",
      "Epoch 2836/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8204.2108 - val_loss: 18571.1304\n",
      "Epoch 2837/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7996.8987 - val_loss: 18258.0932\n",
      "Epoch 2838/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7840.1887 - val_loss: 18753.9065\n",
      "Epoch 2839/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7349.5132 - val_loss: 18400.0915\n",
      "Epoch 2840/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7519.1226 - val_loss: 18639.2798\n",
      "Epoch 2841/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7399.3013 - val_loss: 18768.3538\n",
      "Epoch 2842/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7721.9759 - val_loss: 18935.0909\n",
      "Epoch 2843/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7438.0336 - val_loss: 18583.9217\n",
      "Epoch 2844/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7043.0062 - val_loss: 18629.8883\n",
      "Epoch 2845/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7256.9831 - val_loss: 18568.3277\n",
      "Epoch 2846/3000\n",
      "995/995 [==============================] - 0s 112us/step - loss: 7021.0347 - val_loss: 19092.9005\n",
      "Epoch 2847/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8059.7706 - val_loss: 18464.6361\n",
      "Epoch 2848/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 6953.4946 - val_loss: 18325.9040\n",
      "Epoch 2849/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7079.3703 - val_loss: 18329.9946\n",
      "Epoch 2850/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7131.2622 - val_loss: 18688.2174\n",
      "Epoch 2851/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8135.0940 - val_loss: 18438.8824\n",
      "Epoch 2852/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7452.5670 - val_loss: 18122.0699\n",
      "Epoch 2853/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8042.4770 - val_loss: 19842.2624\n",
      "Epoch 2854/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8172.1652 - val_loss: 18562.3737\n",
      "Epoch 2855/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7457.1471 - val_loss: 18490.4840\n",
      "Epoch 2856/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7403.4199 - val_loss: 18532.5629\n",
      "Epoch 2857/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7603.1583 - val_loss: 18369.3425\n",
      "Epoch 2858/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7423.5718 - val_loss: 18471.7527\n",
      "Epoch 2859/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 6972.1671 - val_loss: 19257.0614\n",
      "Epoch 2860/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 9262.0882 - val_loss: 19002.5510\n",
      "Epoch 2861/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8281.7862 - val_loss: 17974.8490\n",
      "Epoch 2862/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 6972.2781 - val_loss: 18496.7388\n",
      "Epoch 2863/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7917.8932 - val_loss: 19151.6654\n",
      "Epoch 2864/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7920.2607 - val_loss: 18182.8173\n",
      "Epoch 2865/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7322.7610 - val_loss: 18353.2182\n",
      "Epoch 2866/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7179.3311 - val_loss: 18270.4462\n",
      "Epoch 2867/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7567.6197 - val_loss: 18604.8858\n",
      "Epoch 2868/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 6995.0491 - val_loss: 18223.5672\n",
      "Epoch 2869/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7057.4639 - val_loss: 18569.4909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2870/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7122.4575 - val_loss: 19494.3525\n",
      "Epoch 2871/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7873.5114 - val_loss: 18843.9946\n",
      "Epoch 2872/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7430.1319 - val_loss: 18963.4606\n",
      "Epoch 2873/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7141.9225 - val_loss: 20710.0727\n",
      "Epoch 2874/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8024.5245 - val_loss: 18525.7480\n",
      "Epoch 2875/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7331.3170 - val_loss: 18497.6990\n",
      "Epoch 2876/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7490.3348 - val_loss: 18217.6165\n",
      "Epoch 2877/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7063.4910 - val_loss: 18348.7290\n",
      "Epoch 2878/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7378.3378 - val_loss: 18411.1476\n",
      "Epoch 2879/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7142.2459 - val_loss: 18662.5474\n",
      "Epoch 2880/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7958.1574 - val_loss: 18131.9889\n",
      "Epoch 2881/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7411.6764 - val_loss: 18844.6570\n",
      "Epoch 2882/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7787.3322 - val_loss: 18207.6084\n",
      "Epoch 2883/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7151.5315 - val_loss: 18264.5989\n",
      "Epoch 2884/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7380.2358 - val_loss: 18603.2264\n",
      "Epoch 2885/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6972.7794 - val_loss: 18647.0688\n",
      "Epoch 2886/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8205.3602 - val_loss: 19049.7952\n",
      "Epoch 2887/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7658.6844 - val_loss: 18316.7776\n",
      "Epoch 2888/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8284.2143 - val_loss: 18451.4407\n",
      "Epoch 2889/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8881.4234 - val_loss: 20684.2213\n",
      "Epoch 2890/3000\n",
      "995/995 [==============================] - 0s 92us/step - loss: 7985.4377 - val_loss: 18349.5089\n",
      "Epoch 2891/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7393.8471 - val_loss: 18677.4537\n",
      "Epoch 2892/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7255.8388 - val_loss: 18274.0610\n",
      "Epoch 2893/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8781.5355 - val_loss: 18269.7379\n",
      "Epoch 2894/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7639.2479 - val_loss: 18497.3973\n",
      "Epoch 2895/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7319.0414 - val_loss: 18745.3120\n",
      "Epoch 2896/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8508.4162 - val_loss: 18031.4103\n",
      "Epoch 2897/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 6923.1574 - val_loss: 18189.0218\n",
      "Epoch 2898/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7345.7246 - val_loss: 18401.8394\n",
      "Epoch 2899/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7327.2466 - val_loss: 18319.1844\n",
      "Epoch 2900/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 8228.7820 - val_loss: 18817.4765\n",
      "Epoch 2901/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9472.7803 - val_loss: 18516.2101\n",
      "Epoch 2902/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7861.3936 - val_loss: 18261.4732\n",
      "Epoch 2903/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7368.1950 - val_loss: 20626.6697\n",
      "Epoch 2904/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8285.0069 - val_loss: 18553.9335\n",
      "Epoch 2905/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8146.0593 - val_loss: 18373.8604\n",
      "Epoch 2906/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 6979.6895 - val_loss: 19185.8084\n",
      "Epoch 2907/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7467.4892 - val_loss: 18027.4339\n",
      "Epoch 2908/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7138.9202 - val_loss: 18487.5036\n",
      "Epoch 2909/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7347.4675 - val_loss: 18421.0902\n",
      "Epoch 2910/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 7248.4044 - val_loss: 18870.1563\n",
      "Epoch 2911/3000\n",
      "995/995 [==============================] - 0s 157us/step - loss: 7170.4753 - val_loss: 18444.6421\n",
      "Epoch 2912/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7401.7592 - val_loss: 18167.1766\n",
      "Epoch 2913/3000\n",
      "995/995 [==============================] - 0s 161us/step - loss: 8367.7642 - val_loss: 18252.1001\n",
      "Epoch 2914/3000\n",
      "995/995 [==============================] - 0s 165us/step - loss: 7540.3268 - val_loss: 18321.4512\n",
      "Epoch 2915/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6929.8097 - val_loss: 18464.7801\n",
      "Epoch 2916/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7369.7527 - val_loss: 18328.9439\n",
      "Epoch 2917/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7362.7390 - val_loss: 19037.6350\n",
      "Epoch 2918/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7629.7823 - val_loss: 18588.1600\n",
      "Epoch 2919/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7123.0144 - val_loss: 18248.5267\n",
      "Epoch 2920/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7860.3267 - val_loss: 18504.5849\n",
      "Epoch 2921/3000\n",
      "995/995 [==============================] - 0s 136us/step - loss: 8322.7390 - val_loss: 18657.1040\n",
      "Epoch 2922/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7348.1386 - val_loss: 18148.1507\n",
      "Epoch 2923/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7396.6875 - val_loss: 18456.0031\n",
      "Epoch 2924/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7798.6783 - val_loss: 18725.6035\n",
      "Epoch 2925/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6984.8242 - val_loss: 18907.3096\n",
      "Epoch 2926/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7207.5450 - val_loss: 18114.7008\n",
      "Epoch 2927/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7144.9177 - val_loss: 18818.8606\n",
      "Epoch 2928/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7538.6055 - val_loss: 18019.8129\n",
      "Epoch 2929/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7355.9947 - val_loss: 18413.3608\n",
      "Epoch 2930/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7938.0179 - val_loss: 18522.9379\n",
      "Epoch 2931/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7334.2978 - val_loss: 18474.8458\n",
      "Epoch 2932/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7100.5171 - val_loss: 18904.9794\n",
      "Epoch 2933/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7998.5010 - val_loss: 18241.7335\n",
      "Epoch 2934/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 6961.7412 - val_loss: 18434.9870\n",
      "Epoch 2935/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7257.9486 - val_loss: 18689.6998\n",
      "Epoch 2936/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7676.5482 - val_loss: 19331.7807\n",
      "Epoch 2937/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9347.3696 - val_loss: 18165.2224\n",
      "Epoch 2938/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7675.2419 - val_loss: 18651.0877\n",
      "Epoch 2939/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7053.1255 - val_loss: 18542.2014\n",
      "Epoch 2940/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7587.3759 - val_loss: 18907.4408\n",
      "Epoch 2941/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7254.7452 - val_loss: 18283.5525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2942/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7449.4010 - val_loss: 18189.8793\n",
      "Epoch 2943/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7135.8913 - val_loss: 18399.9569\n",
      "Epoch 2944/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7197.3976 - val_loss: 18142.0772\n",
      "Epoch 2945/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7551.8850 - val_loss: 18948.6685\n",
      "Epoch 2946/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7486.5030 - val_loss: 18529.8792\n",
      "Epoch 2947/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 8161.0692 - val_loss: 19257.9413\n",
      "Epoch 2948/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 8414.1001 - val_loss: 18202.0720\n",
      "Epoch 2949/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7499.3146 - val_loss: 18271.0135\n",
      "Epoch 2950/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 6734.3619 - val_loss: 18839.8507\n",
      "Epoch 2951/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7507.7661 - val_loss: 18718.2349\n",
      "Epoch 2952/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 6988.9986 - val_loss: 18374.0413\n",
      "Epoch 2953/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7098.7780 - val_loss: 18178.3282\n",
      "Epoch 2954/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7929.5375 - val_loss: 18730.7637\n",
      "Epoch 2955/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7448.5450 - val_loss: 18201.7589\n",
      "Epoch 2956/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 6947.4549 - val_loss: 18375.1442\n",
      "Epoch 2957/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 7485.9161 - val_loss: 18113.4260\n",
      "Epoch 2958/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 6935.9438 - val_loss: 18373.2072\n",
      "Epoch 2959/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 6897.5784 - val_loss: 18423.2237\n",
      "Epoch 2960/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 6959.5014 - val_loss: 18063.3589\n",
      "Epoch 2961/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7493.8768 - val_loss: 18622.1488\n",
      "Epoch 2962/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 6777.6892 - val_loss: 18635.3127\n",
      "Epoch 2963/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 8070.4256 - val_loss: 18185.0480\n",
      "Epoch 2964/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 6864.1260 - val_loss: 19645.1831\n",
      "Epoch 2965/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 9076.0767 - val_loss: 18164.9302\n",
      "Epoch 2966/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 8335.0116 - val_loss: 18525.1632\n",
      "Epoch 2967/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 6861.1181 - val_loss: 18789.7904\n",
      "Epoch 2968/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7985.6201 - val_loss: 18704.8317\n",
      "Epoch 2969/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7861.6256 - val_loss: 18634.6714\n",
      "Epoch 2970/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7582.1821 - val_loss: 18372.0761\n",
      "Epoch 2971/3000\n",
      "995/995 [==============================] - 0s 116us/step - loss: 7990.4794 - val_loss: 18560.8393\n",
      "Epoch 2972/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7710.2443 - val_loss: 19361.1458\n",
      "Epoch 2973/3000\n",
      "995/995 [==============================] - 0s 137us/step - loss: 7993.5135 - val_loss: 19110.9334\n",
      "Epoch 2974/3000\n",
      "995/995 [==============================] - 0s 104us/step - loss: 8188.1543 - val_loss: 18613.2507\n",
      "Epoch 2975/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7832.1386 - val_loss: 19495.0893\n",
      "Epoch 2976/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 7932.0070 - val_loss: 19857.2486\n",
      "Epoch 2977/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 10057.5754 - val_loss: 19094.7366\n",
      "Epoch 2978/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 8425.8252 - val_loss: 18702.1059\n",
      "Epoch 2979/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 6730.1403 - val_loss: 19021.1311\n",
      "Epoch 2980/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 7174.2570 - val_loss: 18366.1859\n",
      "Epoch 2981/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 6928.6451 - val_loss: 18226.0720\n",
      "Epoch 2982/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7286.5432 - val_loss: 18050.5704\n",
      "Epoch 2983/3000\n",
      "995/995 [==============================] - 0s 128us/step - loss: 6980.6177 - val_loss: 20023.0372\n",
      "Epoch 2984/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7409.3645 - val_loss: 18398.2117\n",
      "Epoch 2985/3000\n",
      "995/995 [==============================] - 0s 120us/step - loss: 6639.3423 - val_loss: 18300.4316\n",
      "Epoch 2986/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 8533.5095 - val_loss: 18781.9840\n",
      "Epoch 2987/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 7051.5650 - val_loss: 18146.8486\n",
      "Epoch 2988/3000\n",
      "995/995 [==============================] - 0s 145us/step - loss: 6973.9345 - val_loss: 19076.0012\n",
      "Epoch 2989/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 8066.7834 - val_loss: 18164.0241\n",
      "Epoch 2990/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7478.3960 - val_loss: 18554.6740\n",
      "Epoch 2991/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 7223.1503 - val_loss: 19783.3106\n",
      "Epoch 2992/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 9164.7502 - val_loss: 18571.4628\n",
      "Epoch 2993/3000\n",
      "995/995 [==============================] - 0s 141us/step - loss: 9760.2429 - val_loss: 18963.0017\n",
      "Epoch 2994/3000\n",
      "995/995 [==============================] - ETA: 0s - loss: 7586.13 - 0s 141us/step - loss: 7417.2487 - val_loss: 20605.0164\n",
      "Epoch 2995/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7595.9556 - val_loss: 18741.1233\n",
      "Epoch 2996/3000\n",
      "995/995 [==============================] - 0s 149us/step - loss: 7168.5455 - val_loss: 18247.5136\n",
      "Epoch 2997/3000\n",
      "995/995 [==============================] - 0s 132us/step - loss: 7738.1223 - val_loss: 20529.2300\n",
      "Epoch 2998/3000\n",
      "995/995 [==============================] - 0s 96us/step - loss: 7656.1723 - val_loss: 18405.1403\n",
      "Epoch 2999/3000\n",
      "995/995 [==============================] - 0s 153us/step - loss: 8741.4147 - val_loss: 18495.2832\n",
      "Epoch 3000/3000\n",
      "995/995 [==============================] - 0s 124us/step - loss: 7231.2296 - val_loss: 18412.5755\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 40, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 15, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 20, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the forth hidden layer\n",
    "classifier.add(Dense(output_dim = 20, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the fifth hidden layer\n",
    "classifier.add(Dense(output_dim = 20, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "\n",
    "# Adding the sixth hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "#keras.optimizers.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "#adam = optimizers.Adam(lr=0.01, beta_1=0.9,)\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss='mean_absolute_error', optimizer='Adam')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.30, batch_size = 30, nb_epoch = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('final_work_is_done.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
